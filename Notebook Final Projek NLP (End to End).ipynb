{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["DePdlNW7sx97","yAEDagSVniKR","SrAWNR3Cs7n_","_zFtkoIZ48vd","YCA1ZUXotOS8","UYf2IphAtULs"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# KELOMPOK 4\n","## Muhammad Farhan Arya Wicaksono (5054231011)\n","## Fadhil zaky Budianto (5054231001)\n","## Efan Ramdhani (5054231017)"],"metadata":{"id":"39ZPOapYjp_H"}},{"cell_type":"markdown","source":["# Download Dataset ( Medical QA Indonesia ) ðŸ“•\n","---\n","\n","Dataset yang digunakan dalam penelitian ini adalah Medical QA Indonesia, yang diperoleh dari repository publik di Mendeley Data . Dataset ini berisi 497.974 data mentah hasil pengumpulan dari platform alodokter.com, sebuah situs web konsultasi kesehatan daring gratis di Indonesia, yang mencakup data dari 8 Desember 2014 hingga 28 Februari 2021. Data ini terdiri dari teks-teks konsultasi kesehatan dalam bahasa Indonesia dan digunakan sebagai dasar pengetahuan (knowledge base) bagi sistem chatbot medis.\n","\n","[ Medical QA Indonesia Mendeley data](https://data.mendeley.com/datasets/p8d5bynh3m/1)"],"metadata":{"id":"YggGHTZBlJvZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"URT0beJ_0U9j","outputId":"b7e28929-15ff-4c85-d53e-87929d93cdda"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-06-29 07:23:00--  https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/p8d5bynh3m-1.zip\n","Resolving prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)... 3.5.70.120, 3.5.65.46, 52.218.61.152, ...\n","Connecting to prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com (prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com)|3.5.70.120|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 290368216 (277M) [application/zip]\n","Saving to: â€˜p8d5bynh3m-1.zipâ€™\n","\n","p8d5bynh3m-1.zip    100%[===================>] 276.92M  14.9MB/s    in 21s     \n","\n","2025-06-29 07:23:22 (13.2 MB/s) - â€˜p8d5bynh3m-1.zipâ€™ saved [290368216/290368216]\n","\n"]}],"source":["! wget https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/p8d5bynh3m-1.zip"]},{"cell_type":"markdown","source":["# Subsetting Data ðŸ“š\n","\n","---\n","\n","### Pemilihan dan Pemfilteran Data\n","\n","Dataset yang digunakan merupakan kumpulan *Medical QA* berbahasa Indonesia. Dari dataset tersebut, dipilih kolom-kolom yang relevan untuk pelatihan model, yaitu:\n","\n","* `title`\n","* `question`\n","* `answer`\n","* `topic_set`\n","\n","Proses pemfilteran difokuskan pada **domain kesehatan pencernaan**. Kolom `topic_set` menjadi acuan utama dalam menyeleksi data yang relevan. Setiap entri dalam dataset akan dipilih jika nilai pada kolom `topic_set` mengandung salah satu dari kata kunci berikut:\n","\n","* *gangguan-pencernaan*\n","* *asam-lambung*\n","* *tukak-lambung*\n","* *sakit-maag*\n","* *gastritis*\n","* *mual*\n","* *perut-kembung*\n","* *radang-usus*\n","* *diare*\n","* *konstipasi*\n","* *wasir*\n","* *sakit-perut*\n","\n","Dengan menerapkan pemfilteran berdasarkan kata kunci tersebut, diperoleh subkorpus yang hanya terdiri dari data dengan topik kesehatan pencernaan. Hasil akhir dari proses ini menghasilkan sebanyak **21.376 baris data** yang siap digunakan untuk pelatihan model.\n"],"metadata":{"id":"TJS3YnT7nOUo"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os"],"metadata":{"id":"wVew1ZaG0w_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pd.set_option('display.max_columns', 200)\n","pd.set_option('display.max_colwidth', 200)\n","pd.set_option('display.width', 1000)"],"metadata":{"id":"omKBU0EM87XW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir( 'Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SIzV2MeI1DUN","outputId":"ad8d0bc6-1c26-4b4b-fed6-9ba8b89cdafa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Indo-Online Health Consultation-Medical Interview-Clean.csv',\n"," 'Indo-Online Health Consultation-Medical Interview-Label.csv',\n"," 'Indo-Online Health Consultation-Multilabel-Raw.csv',\n"," 'README.txt']"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["raw_data = pd.read_csv( '/content/Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns/Indo-Online Health Consultation-Multilabel-Raw.csv')"],"metadata":{"id":"nSiUNy2w1Fu7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_data.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ch5ddKVi1cP8","outputId":"55990e23-41d2-4d91-f742-52cbcb6abba6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(497974, 10)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["raw_data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIf-HpoX1LTI","outputId":"bc3282a8-69ea-4184-c3a4-d10bd9bed234"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 497974 entries, 0 to 497973\n","Data columns (total 10 columns):\n"," #   Column          Non-Null Count   Dtype  \n","---  ------          --------------   -----  \n"," 0   title           497974 non-null  object \n"," 1   question        497974 non-null  object \n"," 2   question_date   497974 non-null  object \n"," 3   answer          497974 non-null  object \n"," 4   answer_date     497974 non-null  object \n"," 5   topics          497974 non-null  object \n"," 6   topic_set       497974 non-null  object \n"," 7   risk            497974 non-null  object \n"," 8   year            497974 non-null  int64  \n"," 9   time_to_answer  497974 non-null  float64\n","dtypes: float64(1), int64(1), object(8)\n","memory usage: 38.0+ MB\n"]}]},{"cell_type":"code","source":["raw_data.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4sfrSnHw1VHE","outputId":"b07e6df6-400e-4a8d-a074-9957c20dc6bd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                title                                                                                                                                                                                                 question            question_date                                                                                                                                                                                                   answer              answer_date                                     topics        topic_set risk  year  time_to_answer\n","328129                                 mengatasi jerawat dan bekasnya  Siang dok.. Beberapa minggu yg lalu saya memiliki jerawat jumbo (hampir seperti bisul) di pipi kiri saya dok. Skrg jerawat jumbo tadi sudah hilang, tetapi masih ada bekasnya di kulit dok, dan kalo...   16 January 2018, 14:52  Haloo Sdr. Niken, Jerawat  (acne vulgaris) merupakan salah satu masalah yang sering dihadapi oleh wanita saat ini. Jerawat muncul karena peradangan kronis yang terjadi akibat adanya penumpukan min...   17 January 2018, 22:22                                    jerawat          jerawat  low  2018             1.0\n","461500              Penyebab benjolan lipoma di area panggul belakang  Salam,Halo, Dok.Saya perempuan berusia 24 tahun ini. Saat SD kepala 5 atau umur 11 th saya memiliki benjolan di dalam daging, di panggul belakang atau sejajar dengan cekungan belakang dekat tulang...      20 July 2020, 16:12  Alo, terimakasih atas pertanyaannya. Lipoma  adalah salah satu jenis tumor jinak berupa gumpalan berlemak yang terletak di antara kulit dan juga otot. Lipoma ini seringnya tidak berbahaya. Namun m...      20 July 2020, 18:10                            benjolan lipoma           lipoma  low  2020             0.0\n","399944                        Batasan konsumsi obat pereda sakit gigi                Dok, saya mau tnya, apakah minum obat pereda nyeri sakit gigi musti rutin? Atau hnya ketika sedang merasakan sakitnya? Obat yg sama minum, Asam Mefenamat dan Dexamethason.. Terima kasih  6 September 2018, 07:40  Terimakasih telah bertanya di Alodokter.  Kedua obat yang Anda sebutkan merupakan obat anti radang, yang sekaligus juga penggunaannya dapat mengurangi rasa nyeri. Umumnya, penggunaan obat ini hany...  6 September 2018, 10:17                            sakit-gigi gigi             gigi  low  2018             0.0\n","142134         Cara mengatasi payudara bengkak dan keras pasca aborsi  Hallo dok. Saya mau tanyak. Setelah aborsi payudara terasa bengkak dan keras. Bagaimana cara mengatasinya?Apakah itu ASI nya harus di keluar kan. Kalau harus di keluarkan, Bagaimana cara mengeluar...    4 October 2019, 10:52  Alo Putri, Sebelumnya perlu diketahui dulu bahwa  aborsi  tanpa indikasi medis dan hukum merupakan tindakan ilegal yang bisa dikenai sanksi hukum berupa penjara 10 tahun dan denda 1 milyar rupiah....    4 October 2019, 12:52                         payudara keguguran        keguguran  low  2019             0.0\n","182467  Makanan untuk penderita diabetes, jantung dan gangguan ginjal  Hallo dokter, saya ingin bertanya. Ayah saya penderita diabetes awalnya, belum lama ini luka basahnya baru sembuh selama perawatan sekitar 1 tahun. Kemudian ayah saya mendapat serangan jantung, se...        3 May 2018, 19:20  Halo NJ,  Disarankan konsultasikan jenis diet sesui kondisi medis pasien ke dokter ahli gizi dengan membawa hasil laboratorium.  Dokter ahli gizi akan menghitung kebutuhan kalori pasien dalam seha...        4 May 2018, 00:21                                    nutrisi          nutrisi  low  2018             0.0\n","207234              Haid berkepanjangan setelah menggunakan KM implan                                                                                   Dokk saya haid hampir 2bln lebih Saya menggunakan kb implan dan saya setres juga dok Bahaya ngga dok Sya lagi menyusui   5 February 2018, 21:26  Halo, Penggunaan  alat kontrasepsi  tentunya memiliki kekurangan dan kelebihannya masing-masing. Penggunaan  KB implan  dapat berdampak kepada siklus menstruasi dan tentunya hal ini berbeda-beda p...   6 February 2018, 20:25                     menstruasi kontrasepsi      kontrasepsi  low  2018             0.0\n","219708                   Penyebab belum hamil setelah 3 tahun menikah  Hai dokter,,saya sudah 3 tahun menikah dan sudah melakukan banyak usaha untuk berhasil hamil. Salah satunya sudah sering ke dokter kandungan juga. Pertanyaan saya:1. Apakah kira2 penyebab hamil ta...      12 July 2020, 18:26  Alo Nur, Terima kasih atas pertanyaannya. Apakah dokter kandungan menyampaikan adanya gangguan pada organ reproduksi Anda? Apakah Anda masih teratur kontrol ke dokter kandungan? Pemeriksaan apa sa...      12 July 2020, 20:23  merencanakan-kehamilan endometriosis pcos             pcos  low  2020             0.0\n","320911                        Penyebab posisi mata yang tidak sejajar                                                                                   dok kenapa mata saya ga sejajar saat saya bengong/melamun dok? tapi saat tidak bengong/melamun mata saya sejajar dok       6 August 2020, 20:17  Alo, terimakasih atas pertanyaannya. Posisi mata yang tidak sejajar, baik disadari ataupun tidak (termasuk saat melamun), bisa disebabkan oleh  strabismus . Kondisi ini bisa muncul karena beragam ...     7 August 2020, 07:04                        katarak sakit-saraf      sakit-saraf  low  2020             0.0\n","59902                                    Terbangun tengah malam sesak  Halo Dok saya aggy, saya mau tanya, belakangan ini ketika saya tidur biasa saya suka terbangun tengah malam sekitar pukul 2 atau 3 pagi lalu dengan keadaan dada yang sesak seperti susah bernafas, ...  30 November 2015, 20:40  salam,Keluhan yang Anda alami kemungkinan disebabkan kekambuhan asma yang sebelumnya, namun, perlu juga dilakukan evaluasi, apakah ada kondisi lain yang menyebabkan keluhan yang Anda rasakan selai...   2 December 2015, 08:09              asma asam-lambung sesak-napas      sesak-napas  low  2015             1.0\n","392115       Apakah Penyebab dari kadar Eosinofil dalam darah Rendah?  Dear, Alodokter.   Saya ingin bertanya bila eosinofil rendah, kurang daripada yang seharusnya. Apakah penyebabnya? Dan bagaimana cara mengatasinya? Penyakit apakah yang menjadi indikasi dari eosin...   2 November 2018, 16:33  Selamat pagi, terimakasih atas pertanyaannya Eosinofil merupakan salah satu jenis sel darah putih yang berguna sebagai pertahanan dari invasi mikroorganisme seperti bakteri, virus, dan parasit dal...   3 November 2018, 05:35                  hasil-lab sindrom-cushing  sindrom-cushing  low  2018             0.0"],"text/html":["\n","  <div id=\"df-e707b675-86a5-44f3-b544-f6fda6600854\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>question_date</th>\n","      <th>answer</th>\n","      <th>answer_date</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>risk</th>\n","      <th>year</th>\n","      <th>time_to_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>328129</th>\n","      <td>mengatasi jerawat dan bekasnya</td>\n","      <td>Siang dok.. Beberapa minggu yg lalu saya memiliki jerawat jumbo (hampir seperti bisul) di pipi kiri saya dok. Skrg jerawat jumbo tadi sudah hilang, tetapi masih ada bekasnya di kulit dok, dan kalo...</td>\n","      <td>16 January 2018, 14:52</td>\n","      <td>Haloo Sdr. Niken, Jerawat  (acne vulgaris) merupakan salah satu masalah yang sering dihadapi oleh wanita saat ini. Jerawat muncul karena peradangan kronis yang terjadi akibat adanya penumpukan min...</td>\n","      <td>17 January 2018, 22:22</td>\n","      <td>jerawat</td>\n","      <td>jerawat</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>461500</th>\n","      <td>Penyebab benjolan lipoma di area panggul belakang</td>\n","      <td>Salam,Halo, Dok.Saya perempuan berusia 24 tahun ini. Saat SD kepala 5 atau umur 11 th saya memiliki benjolan di dalam daging, di panggul belakang atau sejajar dengan cekungan belakang dekat tulang...</td>\n","      <td>20 July 2020, 16:12</td>\n","      <td>Alo, terimakasih atas pertanyaannya. Lipoma  adalah salah satu jenis tumor jinak berupa gumpalan berlemak yang terletak di antara kulit dan juga otot. Lipoma ini seringnya tidak berbahaya. Namun m...</td>\n","      <td>20 July 2020, 18:10</td>\n","      <td>benjolan lipoma</td>\n","      <td>lipoma</td>\n","      <td>low</td>\n","      <td>2020</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>399944</th>\n","      <td>Batasan konsumsi obat pereda sakit gigi</td>\n","      <td>Dok, saya mau tnya, apakah minum obat pereda nyeri sakit gigi musti rutin? Atau hnya ketika sedang merasakan sakitnya? Obat yg sama minum, Asam Mefenamat dan Dexamethason.. Terima kasih</td>\n","      <td>6 September 2018, 07:40</td>\n","      <td>Terimakasih telah bertanya di Alodokter.  Kedua obat yang Anda sebutkan merupakan obat anti radang, yang sekaligus juga penggunaannya dapat mengurangi rasa nyeri. Umumnya, penggunaan obat ini hany...</td>\n","      <td>6 September 2018, 10:17</td>\n","      <td>sakit-gigi gigi</td>\n","      <td>gigi</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>142134</th>\n","      <td>Cara mengatasi payudara bengkak dan keras pasca aborsi</td>\n","      <td>Hallo dok. Saya mau tanyak. Setelah aborsi payudara terasa bengkak dan keras. Bagaimana cara mengatasinya?Apakah itu ASI nya harus di keluar kan. Kalau harus di keluarkan, Bagaimana cara mengeluar...</td>\n","      <td>4 October 2019, 10:52</td>\n","      <td>Alo Putri, Sebelumnya perlu diketahui dulu bahwa  aborsi  tanpa indikasi medis dan hukum merupakan tindakan ilegal yang bisa dikenai sanksi hukum berupa penjara 10 tahun dan denda 1 milyar rupiah....</td>\n","      <td>4 October 2019, 12:52</td>\n","      <td>payudara keguguran</td>\n","      <td>keguguran</td>\n","      <td>low</td>\n","      <td>2019</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>182467</th>\n","      <td>Makanan untuk penderita diabetes, jantung dan gangguan ginjal</td>\n","      <td>Hallo dokter, saya ingin bertanya. Ayah saya penderita diabetes awalnya, belum lama ini luka basahnya baru sembuh selama perawatan sekitar 1 tahun. Kemudian ayah saya mendapat serangan jantung, se...</td>\n","      <td>3 May 2018, 19:20</td>\n","      <td>Halo NJ,  Disarankan konsultasikan jenis diet sesui kondisi medis pasien ke dokter ahli gizi dengan membawa hasil laboratorium.  Dokter ahli gizi akan menghitung kebutuhan kalori pasien dalam seha...</td>\n","      <td>4 May 2018, 00:21</td>\n","      <td>nutrisi</td>\n","      <td>nutrisi</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>207234</th>\n","      <td>Haid berkepanjangan setelah menggunakan KM implan</td>\n","      <td>Dokk saya haid hampir 2bln lebih Saya menggunakan kb implan dan saya setres juga dok Bahaya ngga dok Sya lagi menyusui</td>\n","      <td>5 February 2018, 21:26</td>\n","      <td>Halo, Penggunaan  alat kontrasepsi  tentunya memiliki kekurangan dan kelebihannya masing-masing. Penggunaan  KB implan  dapat berdampak kepada siklus menstruasi dan tentunya hal ini berbeda-beda p...</td>\n","      <td>6 February 2018, 20:25</td>\n","      <td>menstruasi kontrasepsi</td>\n","      <td>kontrasepsi</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>219708</th>\n","      <td>Penyebab belum hamil setelah 3 tahun menikah</td>\n","      <td>Hai dokter,,saya sudah 3 tahun menikah dan sudah melakukan banyak usaha untuk berhasil hamil. Salah satunya sudah sering ke dokter kandungan juga. Pertanyaan saya:1. Apakah kira2 penyebab hamil ta...</td>\n","      <td>12 July 2020, 18:26</td>\n","      <td>Alo Nur, Terima kasih atas pertanyaannya. Apakah dokter kandungan menyampaikan adanya gangguan pada organ reproduksi Anda? Apakah Anda masih teratur kontrol ke dokter kandungan? Pemeriksaan apa sa...</td>\n","      <td>12 July 2020, 20:23</td>\n","      <td>merencanakan-kehamilan endometriosis pcos</td>\n","      <td>pcos</td>\n","      <td>low</td>\n","      <td>2020</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>320911</th>\n","      <td>Penyebab posisi mata yang tidak sejajar</td>\n","      <td>dok kenapa mata saya ga sejajar saat saya bengong/melamun dok? tapi saat tidak bengong/melamun mata saya sejajar dok</td>\n","      <td>6 August 2020, 20:17</td>\n","      <td>Alo, terimakasih atas pertanyaannya. Posisi mata yang tidak sejajar, baik disadari ataupun tidak (termasuk saat melamun), bisa disebabkan oleh  strabismus . Kondisi ini bisa muncul karena beragam ...</td>\n","      <td>7 August 2020, 07:04</td>\n","      <td>katarak sakit-saraf</td>\n","      <td>sakit-saraf</td>\n","      <td>low</td>\n","      <td>2020</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>59902</th>\n","      <td>Terbangun tengah malam sesak</td>\n","      <td>Halo Dok saya aggy, saya mau tanya, belakangan ini ketika saya tidur biasa saya suka terbangun tengah malam sekitar pukul 2 atau 3 pagi lalu dengan keadaan dada yang sesak seperti susah bernafas, ...</td>\n","      <td>30 November 2015, 20:40</td>\n","      <td>salam,Keluhan yang Anda alami kemungkinan disebabkan kekambuhan asma yang sebelumnya, namun, perlu juga dilakukan evaluasi, apakah ada kondisi lain yang menyebabkan keluhan yang Anda rasakan selai...</td>\n","      <td>2 December 2015, 08:09</td>\n","      <td>asma asam-lambung sesak-napas</td>\n","      <td>sesak-napas</td>\n","      <td>low</td>\n","      <td>2015</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>392115</th>\n","      <td>Apakah Penyebab dari kadar Eosinofil dalam darah Rendah?</td>\n","      <td>Dear, Alodokter.   Saya ingin bertanya bila eosinofil rendah, kurang daripada yang seharusnya. Apakah penyebabnya? Dan bagaimana cara mengatasinya? Penyakit apakah yang menjadi indikasi dari eosin...</td>\n","      <td>2 November 2018, 16:33</td>\n","      <td>Selamat pagi, terimakasih atas pertanyaannya Eosinofil merupakan salah satu jenis sel darah putih yang berguna sebagai pertahanan dari invasi mikroorganisme seperti bakteri, virus, dan parasit dal...</td>\n","      <td>3 November 2018, 05:35</td>\n","      <td>hasil-lab sindrom-cushing</td>\n","      <td>sindrom-cushing</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e707b675-86a5-44f3-b544-f6fda6600854')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e707b675-86a5-44f3-b544-f6fda6600854 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e707b675-86a5-44f3-b544-f6fda6600854');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0e1bc42d-c96c-459b-9739-29c7c4727446\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0e1bc42d-c96c-459b-9739-29c7c4727446')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0e1bc42d-c96c-459b-9739-29c7c4727446 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["raw_data.nunique()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"st5QujUk31IL","outputId":"587ed126-a262-41d7-f3e4-8ef085f320e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["title             328303\n","question          357848\n","question_date     326650\n","answer            359672\n","answer_date       327795\n","topics             58153\n","topic_set           1541\n","risk                   2\n","year                   8\n","time_to_answer       128\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>title</th>\n","      <td>328303</td>\n","    </tr>\n","    <tr>\n","      <th>question</th>\n","      <td>357848</td>\n","    </tr>\n","    <tr>\n","      <th>question_date</th>\n","      <td>326650</td>\n","    </tr>\n","    <tr>\n","      <th>answer</th>\n","      <td>359672</td>\n","    </tr>\n","    <tr>\n","      <th>answer_date</th>\n","      <td>327795</td>\n","    </tr>\n","    <tr>\n","      <th>topics</th>\n","      <td>58153</td>\n","    </tr>\n","    <tr>\n","      <th>topic_set</th>\n","      <td>1541</td>\n","    </tr>\n","    <tr>\n","      <th>risk</th>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>year</th>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>time_to_answer</th>\n","      <td>128</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Digestive Health Topics with counts\n","digestive_health_topics = [\n","    \"gangguan-pencernaan\",       # 7083\n","    \"asam-lambung\",              # 5891\n","    \"tukak-lambung\",             # 2952\n","    \"sakit-maag\",                # 2858\n","    \"gastritis\",                 # 2117\n","    \"mual\",                      # 1489\n","    \"perut-kembung\",             # 1279\n","    \"radang-usus\",               # 1291\n","    \"diare\",                     # 1302\n","    \"konstipasi\",                # 830\n","    \"wasir\",                     # 1851\n","    \"sakit-perut\",               # 763\n","]\n","\n","# Total count: ~26,706"],"metadata":{"id":"Ng3U08bKIDED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["digestive_data = raw_data[raw_data['topic_set'].isin(digestive_health_topics)]"],"metadata":{"id":"TnCyHTYzJgh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["digestive_data = digestive_data.drop_duplicates()\n","digestive_data = digestive_data.reset_index(drop=True)\n","digestive_data.to_csv('digestive_data.csv', index=False)"],"metadata":{"id":"sJH44iIRJo-X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dihasilkan data sebanyak 21.376"],"metadata":{"id":"vPmEbjNmnwC6"}},{"cell_type":"code","source":["digestive_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"8-Q2JBPoJqPj","outputId":"67ba25ad-f99b-4e2f-a4c9-dfde63c81e7a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                            title                                                                                                                                                                                                 question            question_date                                                                                                                                                                                                   answer              answer_date                                topics            topic_set risk  year  time_to_answer\n","0                                        Penyebab dan cara mengatasi BAB berdarah  Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja dara...   4 February 2021, 14:27  Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu ...   4 February 2021, 15:35             wasir gangguan-pencernaan  gangguan-pencernaan  low  2021             0.0\n","1                                    Susah BAB setelah operasi wasir 3 bulan lalu  Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi s...   9 February 2021, 11:09  Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (n...   9 February 2021, 13:32                      konstipasi wasir                wasir  low  2021             0.0\n","2      Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir                                Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?    9 January 2021, 02:17  Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munc...    9 January 2021, 10:34                      konstipasi wasir                wasir  low  2021             0.0\n","3      Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang  Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang ...   10 January 2021, 20:03  Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercam...   10 January 2021, 23:58                  kulit benjolan wasir                wasir  low  2021             0.0\n","4                               Penaganan susah BAB dan muncul benjolan pada anus  Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi ti...   21 January 2021, 10:48  Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan ka...   21 January 2021, 16:05  konstipasi wasir gangguan-pencernaan  gangguan-pencernaan  low  2021             0.0\n","...                                                                           ...                                                                                                                                                                                                      ...                      ...                                                                                                                                                                                                      ...                      ...                                   ...                  ...  ...   ...             ...\n","21371                                                tanda penurunan asam lambung  Dok, saya mau tanya lima hari yg lalu periksa kedokter katanya asam lambung saya naik. Gejala nya sih sesak napas, dikerongkongan kayak ada lendir diludahkan gak bisa keluar .tapi selama 6 hari in...  23 December 2014, 19:55  Hello,Asam lambung merupakan cairan yang diproduksi oleh sel-sel lambung yang berfungsi untuk mencerna protein, membunuh kuman yang masuk lambung dan sebagainya. Pada normalnya jumlah asam lambung...  31 December 2014, 14:58                          asam-lambung         asam-lambung  low  2014             7.0\n","21372                                              mengatasi naiknya asam lambung                                                                                                                Dokter bagaimana cara mengatasi naikx asam lambumg sperti nyeri Ulu hati dan sesak dimana   6 February 2015, 12:54  Hai,Asam lambung merupakan cairan yang akan dikeluarkan secara otomatis oleh sel sel pada lambung untuk mencerna makanan, membunuh kuman dll.Peningkatan cairan asam lambung biasa terjadi saat :   ...   6 February 2015, 13:28                          asam-lambung         asam-lambung  low  2015             0.0\n","21373                                                sering kembung dan buang gas                                                                    dok mau tanya, perut saya sering kembung dan sering buang gas (kebanyakan di malam hari) apakah saya termasuk menderita asam lambung?  15 February 2015, 18:34  Hai,Perut kembung dapat disebabkan oleh penyakit asam lambung (Info lengkap mengenai penyakit asam lambung dapat Anda buka pada halaman berikut : http://www.alodokter.com/penyakit-asam-lambung/) n...  16 February 2015, 14:46                          asam-lambung         asam-lambung  low  2015             0.0\n","21374                                     Sesak nafas terasa lelah di bagian dada  Nafas berat,kepala berat,penglihatan rabun,sering sendawa,dan serasa mudah lelah terjadi di bagian dada,apa benar gejala gerd dok? Saya tidak merasa adanya panas d belakang tulang dada, ini sudah ...      23 July 2018, 13:02  Halo, selamat pagi Ferdinan.  Keluhan-keluhan yang anda alami dapat merupakan gejala dari berbagai macam kemungkinan penyakit yakni: gangguan lambung berupa peningkatan asam lambung ( GERD ). Pada...      24 July 2018, 11:19   anemia-defisiensi-besi asam-lambung         asam-lambung  low  2018             0.0\n","21375                                            cara mengatasi kembung pada bayi      Malam dok, saya mau tanya, anak saya usia 3 bln 20 hari, saat ini mengalami kembung di sertai buang air besar \\u0026amp; muntah, gimana cara mengatasi nya? Terimakasih sebelumnya atas jawabannya.     30 April 2016, 05:18  Hai sumi.......Terimakasih atas pertanyaan Anda.Sebenarnya perlu Anda ketahui bahwa perut kembung pada bayi usai 3 - 4 bulan merupakan hal yang wajar, karena memang saluran pencernaannya belum ber...        2 May 2016, 13:08                    anak perut-kembung        perut-kembung  low  2016             2.0\n","\n","[21376 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-2ec2eeaa-907a-4a43-8ef9-a82e49577bc5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>question_date</th>\n","      <th>answer</th>\n","      <th>answer_date</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>risk</th>\n","      <th>year</th>\n","      <th>time_to_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Penyebab dan cara mengatasi BAB berdarah</td>\n","      <td>Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja dara...</td>\n","      <td>4 February 2021, 14:27</td>\n","      <td>Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu ...</td>\n","      <td>4 February 2021, 15:35</td>\n","      <td>wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Susah BAB setelah operasi wasir 3 bulan lalu</td>\n","      <td>Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi s...</td>\n","      <td>9 February 2021, 11:09</td>\n","      <td>Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (n...</td>\n","      <td>9 February 2021, 13:32</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir</td>\n","      <td>Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?</td>\n","      <td>9 January 2021, 02:17</td>\n","      <td>Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munc...</td>\n","      <td>9 January 2021, 10:34</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang</td>\n","      <td>Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang ...</td>\n","      <td>10 January 2021, 20:03</td>\n","      <td>Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercam...</td>\n","      <td>10 January 2021, 23:58</td>\n","      <td>kulit benjolan wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penaganan susah BAB dan muncul benjolan pada anus</td>\n","      <td>Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi ti...</td>\n","      <td>21 January 2021, 10:48</td>\n","      <td>Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan ka...</td>\n","      <td>21 January 2021, 16:05</td>\n","      <td>konstipasi wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21371</th>\n","      <td>tanda penurunan asam lambung</td>\n","      <td>Dok, saya mau tanya lima hari yg lalu periksa kedokter katanya asam lambung saya naik. Gejala nya sih sesak napas, dikerongkongan kayak ada lendir diludahkan gak bisa keluar .tapi selama 6 hari in...</td>\n","      <td>23 December 2014, 19:55</td>\n","      <td>Hello,Asam lambung merupakan cairan yang diproduksi oleh sel-sel lambung yang berfungsi untuk mencerna protein, membunuh kuman yang masuk lambung dan sebagainya. Pada normalnya jumlah asam lambung...</td>\n","      <td>31 December 2014, 14:58</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>low</td>\n","      <td>2014</td>\n","      <td>7.0</td>\n","    </tr>\n","    <tr>\n","      <th>21372</th>\n","      <td>mengatasi naiknya asam lambung</td>\n","      <td>Dokter bagaimana cara mengatasi naikx asam lambumg sperti nyeri Ulu hati dan sesak dimana</td>\n","      <td>6 February 2015, 12:54</td>\n","      <td>Hai,Asam lambung merupakan cairan yang akan dikeluarkan secara otomatis oleh sel sel pada lambung untuk mencerna makanan, membunuh kuman dll.Peningkatan cairan asam lambung biasa terjadi saat :   ...</td>\n","      <td>6 February 2015, 13:28</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>low</td>\n","      <td>2015</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>21373</th>\n","      <td>sering kembung dan buang gas</td>\n","      <td>dok mau tanya, perut saya sering kembung dan sering buang gas (kebanyakan di malam hari) apakah saya termasuk menderita asam lambung?</td>\n","      <td>15 February 2015, 18:34</td>\n","      <td>Hai,Perut kembung dapat disebabkan oleh penyakit asam lambung (Info lengkap mengenai penyakit asam lambung dapat Anda buka pada halaman berikut : http://www.alodokter.com/penyakit-asam-lambung/) n...</td>\n","      <td>16 February 2015, 14:46</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>low</td>\n","      <td>2015</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>21374</th>\n","      <td>Sesak nafas terasa lelah di bagian dada</td>\n","      <td>Nafas berat,kepala berat,penglihatan rabun,sering sendawa,dan serasa mudah lelah terjadi di bagian dada,apa benar gejala gerd dok? Saya tidak merasa adanya panas d belakang tulang dada, ini sudah ...</td>\n","      <td>23 July 2018, 13:02</td>\n","      <td>Halo, selamat pagi Ferdinan.  Keluhan-keluhan yang anda alami dapat merupakan gejala dari berbagai macam kemungkinan penyakit yakni: gangguan lambung berupa peningkatan asam lambung ( GERD ). Pada...</td>\n","      <td>24 July 2018, 11:19</td>\n","      <td>anemia-defisiensi-besi asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>low</td>\n","      <td>2018</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>21375</th>\n","      <td>cara mengatasi kembung pada bayi</td>\n","      <td>Malam dok, saya mau tanya, anak saya usia 3 bln 20 hari, saat ini mengalami kembung di sertai buang air besar \\u0026amp; muntah, gimana cara mengatasi nya? Terimakasih sebelumnya atas jawabannya.</td>\n","      <td>30 April 2016, 05:18</td>\n","      <td>Hai sumi.......Terimakasih atas pertanyaan Anda.Sebenarnya perlu Anda ketahui bahwa perut kembung pada bayi usai 3 - 4 bulan merupakan hal yang wajar, karena memang saluran pencernaannya belum ber...</td>\n","      <td>2 May 2016, 13:08</td>\n","      <td>anak perut-kembung</td>\n","      <td>perut-kembung</td>\n","      <td>low</td>\n","      <td>2016</td>\n","      <td>2.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21376 rows Ã— 10 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ec2eeaa-907a-4a43-8ef9-a82e49577bc5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2ec2eeaa-907a-4a43-8ef9-a82e49577bc5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2ec2eeaa-907a-4a43-8ef9-a82e49577bc5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-58e0ed9f-6edd-4983-b000-04fb133e853f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-58e0ed9f-6edd-4983-b000-04fb133e853f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-58e0ed9f-6edd-4983-b000-04fb133e853f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_a70bdb8d-3696-4a34-9a75-e8b2c2014192\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('digestive_data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_a70bdb8d-3696-4a34-9a75-e8b2c2014192 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('digestive_data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"digestive_data","summary":"{\n  \"name\": \"digestive_data\",\n  \"rows\": 21376,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19750,\n        \"samples\": [\n          \"Nyeri perut sebelah kanan saat disentuh disertai demam dan sering BAB\",\n          \"tidak nyaman di perut dan feses kehitaman\",\n          \"Penyebab cemas dan jantung berdebar setiap malam hari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21187,\n        \"samples\": [\n          \"Dok saya mau tanya,ibu saya sering merasa sesak di dada,sehingga dia tidak kuat terkena angin ,hingga dirumah pun memakai baju berlapis lapis kata beliau itu biar hangat katanya kalau gak pake baju berlapis lapis beliau merasa dingin dan sesak padahal cuaca itu saat bersuhu hangatTerus ibu ku sering pake korset gitu biar badannya ke teken gitu,kalau gak sering pake samping di ikat perutnya katanya sih nyaman kalau di giniin Setiap diperiksa sama dokter katanya itu biasa Tapi setiap di beri obat malah makin parah mamah aku dokTerus di bola matanya kata mamah aku gak jelas katanya seperti ada darah gitu jadi melihatnya kurang jelasSering banget pusing dokTerus tangannya sering kebas gak kerasa apa apa saat terkena air dinginAku juga seperti itu dok ,aku sering tangan ku kebas saat dan sesudah terkena air dingin Kira kira itu sakit apa ya dok?\",\n          \"Dok saya baru saja selesai haid sekitar pada hari ke 4 setelah haid saya melakukan dengan suami, dan sekarang tepat 9 hari setelah haid saya merasa mual, perut kembung, serta kentut dan bersendawa, apakah itu hamil atau maag ? Bisa tolong dijelaskan perbedaannya ?\",\n          \"Slmt mlm dok. Sy telah menjalani operasi wasir dgn metode HAR \\\\u0026amp; RAR..sekitar 2 mgg lalu..kondisi skrng saat BAB ada darah bercampur dgn feses sy..dan juga sering kali ada cairan spt nanah sering keluar di dubur sy..hal ini terlihat klo sy gunakan tissue utk membersihkannya...obat antibiotik sudah habis dan dokter sdh tdk memberikan obat antiobiotiknya. Sy khawatir..saat BAB msh sj keluat darah..apalagi klo stlh bab encer anus terasa perih..sampai 8 jam hilang. Mhn informasinya apakah ini kondisi normal atau bagaimana?. krn menurut dokter itu tidak apa2.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21101,\n        \"samples\": [\n          \"18 February 2018, 21:31\",\n          \"20 August 2016, 14:36\",\n          \"9 May 2016, 05:34\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21344,\n        \"samples\": [\n          \"Hai,Keluhan tersebut dapat disebabkan oleh:   infeksi atau batu saluran kemih   radang usus besar   cedera   tinja yang mengeras Usahakan untuk memiliki pola makan teratur. Perbanyak minum air mineral dan tidak menahan rasa saat ingin BAK maupun BAB. Batasi kafein/ alkohol. Tidak merokok. Sebaiknya tidak mengangkat benda-benda yang berat.Jika gejala belum membaik, disarankan agar Anda periksa ke dokter. Pemeriksaan fisik dan tes penunjang seperti tes urin atau USG, dapat membantu mengetahui penyebabnya. Sehingga dapat segera diberikan penanganan yang tepat.Anda dapat membaca halaman  Sakit perut kiri  Semoga bermanfaat,dr. Jessica\",\n          \"Halo Vharida Vitriyaa, Sakit perut  merupakan sakit yang dapat dialami semua orang, dan pada umumnya tidak memiliki penyebab yang serius. Jika Anda mengalami sakit perut, yang perlu diketahui pertama kali adalah bagian mana perut yang sakit. Dalam hal ini Anda sudah menyebutkan bagian bawah, maka dari itu berikut saya jabarkan penyebab  sakit perut bagian bawah  pada wanita:   Sakit perut akibat menstruasi   Ovulasi   Hamil di luar kandungan   Keguguran   Penyakit radang panggul   Kista ovarium   Endometriosis   Fibroid   Gangguan serviks seperti infeksi atau kanker   Radang saluran tuba   Penyakit menular seksual   Masalah ginjal   Radang usus Ada baiknya Anda memeriksakan diri ke dokter spesialis penyakit dalam untuk mendapat pemeriksaan lebih lanjut selain USG. Jika tidak ditemukan masalah serius pada bagian bawah perut Anda, kemungkinan yang paling besar adalah Anda memiliki masalah lambung seperti:   Tukak lambung   Penyakit asam lambung   Gastritis Berikut beberapa tips untuk Anda:   Minum air mineral minimal 2 liter setiap hari   Utamakan makanan berserat untuk mencegah konstipasi   Kurangi konsumsi makanan berlemak   Hindari minuman berkafein seperti kopi dan teh, hindari juga soda dan minuman beralkohol   Konsumsi yoghurt   Konsumsi obat maag yang dijual bebas   Kurangi stres   Rutin berolah raga Semoga bermanfaat,Dr. Yosephine \",\n          \"Defar Fitri, Kram perut bisa diakibatkan oleh: nyeri otot perut gastritis tukak lambung gastroenteritis radang usus buntu infeksi ginjal  batu ginjal radang panggul endometriosis Sebaiknya Anda berkonsultasi dengan dokter kandungan di mana dokter akan menganalisis gejala dan melakukan pemeriksaan fisik. Tes penunjang seperti tes darah dan USG dapat dokter anjurkan. Terapi yang tepat akan dokter berikan. Tips berikut ini dapat Anda lakukan: hindari mengurut atau menekan bagian yang sakit konsumsi makanan bergizi seimbang secara teratur kelola stres dengan bijak minum air putih dalam jumlah cukup miliki waktu tidur yang cukup hindari merokok dan minum minuman keras hindari langsung berbaring sesudah makan kurangi minum minuman berkafein dan bersoda Artikel yang bisa Anda baca: Sakit perut Semoga bermanfaat dan salam, dr. Rony Wijaya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21132,\n        \"samples\": [\n          \"21 March 2018, 20:06\",\n          \"20 January 2016, 09:00\",\n          \"15 September 2017, 21:16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2770,\n        \"samples\": [\n          \"sakit-maag sakit-perut infeksi-saluran-kemih konstipasi asam-lambung gastritis\",\n          \"keringat-dingin sakit-maag\",\n          \"anak herba konstipasi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"konstipasi\",\n          \"diare\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"high\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2014,\n        \"max\": 2021,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2020,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_to_answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.350610612701875,\n        \"min\": 0.0,\n        \"max\": 880.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["!curl -F \"reqtype=fileupload\" -F \"fileToUpload=@/content/digestive_data.csv\" https://catbox.moe/user/api.php"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JGnyay7vKVpY","outputId":"fce37d29-6a4a-439b-d301-415c8533b567"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://files.catbox.moe/dyw9xs.csv"]}]},{"cell_type":"markdown","source":["#Preprocessing Data ðŸ§¹\n","---"],"metadata":{"id":"SBwes_KbrBiN"}},{"cell_type":"code","source":["! wget https://files.catbox.moe/dyw9xs.csv"],"metadata":{"id":"IugGwIn9MSkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["! unzip p8d5bynh3m-1.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4tWBXv7v0eGS","outputId":"dec0d30e-c02f-4660-c590-ba020212d64a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  p8d5bynh3m-1.zip\n","  inflating: Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns/Indo-Online Health Consultation-Multilabel-Raw.csv  \n","  inflating: Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns/Indo-Online Health Consultation-Medical Interview-Label.csv  \n","  inflating: Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns/Indo-Online Health Consultation-Medical Interview-Clean.csv  \n","  inflating: Doctors Answer Text Dataset in Indonesian Contains Information on Medical Interview Patterns/README.txt  \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lmbtzF4elVM","outputId":"fcf983b7-3686-4af4-9c28-a9af2c786dc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-05-11 13:36:12--  https://files.catbox.moe/dyw9xs.csv\n","Resolving files.catbox.moe (files.catbox.moe)... 108.181.20.35, 2604:6600:5:1::3\n","Connecting to files.catbox.moe (files.catbox.moe)|108.181.20.35|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 43562843 (42M) [application/octet-stream]\n","Saving to: â€˜dyw9xs.csvâ€™\n","\n","dyw9xs.csv          100%[===================>]  41.54M  29.0MB/s    in 1.4s    \n","\n","2025-05-11 13:36:14 (29.0 MB/s) - â€˜dyw9xs.csvâ€™ saved [43562843/43562843]\n","\n"]}],"source":["! wget https://files.catbox.moe/dyw9xs.csv"]},{"cell_type":"code","source":["! pip install indoNLP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42cWr0UYesrW","outputId":"f130954c-7252-4ce8-d80b-852af7477a57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting indoNLP\n","  Downloading indoNLP-0.3.4-py3-none-any.whl.metadata (3.4 kB)\n","Downloading indoNLP-0.3.4-py3-none-any.whl (121 kB)\n","\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/121.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: indoNLP\n","Successfully installed indoNLP-0.3.4\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from wordcloud import WordCloud\n","import indoNLP\n","\n","from nltk.tokenize import sent_tokenize\n","import nltk\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xnd3mkLIeynt","outputId":"cc3eb7d5-0eb9-4056-87c1-bae8fb6294fb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_colwidth', 1000)"],"metadata":{"id":"iVhlztX6fR3M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('dyw9xs.csv')\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fMY-x7kTe2PZ","outputId":"f32fc8ef-751b-49d1-c480-f4a3a1f6c305"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                        title  \\\n","0                                    Penyebab dan cara mengatasi BAB berdarah   \n","1                                Susah BAB setelah operasi wasir 3 bulan lalu   \n","2  Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir   \n","3  Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang   \n","4                           Penaganan susah BAB dan muncul benjolan pada anus   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                question  \\\n","0                                                                                                                                                                                                                                                                                                                                       Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih   \n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?   \n","3                                                                                                                                                     Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.   \n","4  Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.   \n","\n","            question_date  \\\n","0  4 February 2021, 14:27   \n","1  9 February 2021, 11:09   \n","2   9 January 2021, 02:17   \n","3  10 January 2021, 20:03   \n","4  21 January 2021, 10:48   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    answer  \\\n","0  Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...   \n","1  Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...   \n","2  Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...   \n","3  Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...   \n","4  Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...   \n","\n","              answer_date                                topics  \\\n","0  4 February 2021, 15:35             wasir gangguan-pencernaan   \n","1  9 February 2021, 13:32                      konstipasi wasir   \n","2   9 January 2021, 10:34                      konstipasi wasir   \n","3  10 January 2021, 23:58                  kulit benjolan wasir   \n","4  21 January 2021, 16:05  konstipasi wasir gangguan-pencernaan   \n","\n","             topic_set risk  year  time_to_answer  \n","0  gangguan-pencernaan  low  2021             0.0  \n","1                wasir  low  2021             0.0  \n","2                wasir  low  2021             0.0  \n","3                wasir  low  2021             0.0  \n","4  gangguan-pencernaan  low  2021             0.0  "],"text/html":["\n","  <div id=\"df-2804fcb3-b55b-43d5-a3bb-2624efe6163a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>question_date</th>\n","      <th>answer</th>\n","      <th>answer_date</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>risk</th>\n","      <th>year</th>\n","      <th>time_to_answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Penyebab dan cara mengatasi BAB berdarah</td>\n","      <td>Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih</td>\n","      <td>4 February 2021, 14:27</td>\n","      <td>Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...</td>\n","      <td>4 February 2021, 15:35</td>\n","      <td>wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Susah BAB setelah operasi wasir 3 bulan lalu</td>\n","      <td>Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?</td>\n","      <td>9 February 2021, 11:09</td>\n","      <td>Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...</td>\n","      <td>9 February 2021, 13:32</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir</td>\n","      <td>Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?</td>\n","      <td>9 January 2021, 02:17</td>\n","      <td>Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...</td>\n","      <td>9 January 2021, 10:34</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang</td>\n","      <td>Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.</td>\n","      <td>10 January 2021, 20:03</td>\n","      <td>Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...</td>\n","      <td>10 January 2021, 23:58</td>\n","      <td>kulit benjolan wasir</td>\n","      <td>wasir</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penaganan susah BAB dan muncul benjolan pada anus</td>\n","      <td>Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.</td>\n","      <td>21 January 2021, 10:48</td>\n","      <td>Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...</td>\n","      <td>21 January 2021, 16:05</td>\n","      <td>konstipasi wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>low</td>\n","      <td>2021</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2804fcb3-b55b-43d5-a3bb-2624efe6163a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2804fcb3-b55b-43d5-a3bb-2624efe6163a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2804fcb3-b55b-43d5-a3bb-2624efe6163a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-d2106bdf-4505-4549-9a40-bd4026807201\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2106bdf-4505-4549-9a40-bd4026807201')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-d2106bdf-4505-4549-9a40-bd4026807201 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 21376,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19750,\n        \"samples\": [\n          \"Nyeri perut sebelah kanan saat disentuh disertai demam dan sering BAB\",\n          \"tidak nyaman di perut dan feses kehitaman\",\n          \"Penyebab cemas dan jantung berdebar setiap malam hari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21187,\n        \"samples\": [\n          \"Dok saya mau tanya,ibu saya sering merasa sesak di dada,sehingga dia tidak kuat terkena angin ,hingga dirumah pun memakai baju berlapis lapis kata beliau itu biar hangat katanya kalau gak pake baju berlapis lapis beliau merasa dingin dan sesak padahal cuaca itu saat bersuhu hangatTerus ibu ku sering pake korset gitu biar badannya ke teken gitu,kalau gak sering pake samping di ikat perutnya katanya sih nyaman kalau di giniin Setiap diperiksa sama dokter katanya itu biasa Tapi setiap di beri obat malah makin parah mamah aku dokTerus di bola matanya kata mamah aku gak jelas katanya seperti ada darah gitu jadi melihatnya kurang jelasSering banget pusing dokTerus tangannya sering kebas gak kerasa apa apa saat terkena air dinginAku juga seperti itu dok ,aku sering tangan ku kebas saat dan sesudah terkena air dingin Kira kira itu sakit apa ya dok?\",\n          \"Dok saya baru saja selesai haid sekitar pada hari ke 4 setelah haid saya melakukan dengan suami, dan sekarang tepat 9 hari setelah haid saya merasa mual, perut kembung, serta kentut dan bersendawa, apakah itu hamil atau maag ? Bisa tolong dijelaskan perbedaannya ?\",\n          \"Slmt mlm dok. Sy telah menjalani operasi wasir dgn metode HAR \\\\u0026amp; RAR..sekitar 2 mgg lalu..kondisi skrng saat BAB ada darah bercampur dgn feses sy..dan juga sering kali ada cairan spt nanah sering keluar di dubur sy..hal ini terlihat klo sy gunakan tissue utk membersihkannya...obat antibiotik sudah habis dan dokter sdh tdk memberikan obat antiobiotiknya. Sy khawatir..saat BAB msh sj keluat darah..apalagi klo stlh bab encer anus terasa perih..sampai 8 jam hilang. Mhn informasinya apakah ini kondisi normal atau bagaimana?. krn menurut dokter itu tidak apa2.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21101,\n        \"samples\": [\n          \"18 February 2018, 21:31\",\n          \"20 August 2016, 14:36\",\n          \"9 May 2016, 05:34\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21344,\n        \"samples\": [\n          \"Hai,Keluhan tersebut dapat disebabkan oleh:   infeksi atau batu saluran kemih   radang usus besar   cedera   tinja yang mengeras Usahakan untuk memiliki pola makan teratur. Perbanyak minum air mineral dan tidak menahan rasa saat ingin BAK maupun BAB. Batasi kafein/ alkohol. Tidak merokok. Sebaiknya tidak mengangkat benda-benda yang berat.Jika gejala belum membaik, disarankan agar Anda periksa ke dokter. Pemeriksaan fisik dan tes penunjang seperti tes urin atau USG, dapat membantu mengetahui penyebabnya. Sehingga dapat segera diberikan penanganan yang tepat.Anda dapat membaca halaman  Sakit perut kiri  Semoga bermanfaat,dr. Jessica\",\n          \"Halo Vharida Vitriyaa, Sakit perut  merupakan sakit yang dapat dialami semua orang, dan pada umumnya tidak memiliki penyebab yang serius. Jika Anda mengalami sakit perut, yang perlu diketahui pertama kali adalah bagian mana perut yang sakit. Dalam hal ini Anda sudah menyebutkan bagian bawah, maka dari itu berikut saya jabarkan penyebab  sakit perut bagian bawah  pada wanita:   Sakit perut akibat menstruasi   Ovulasi   Hamil di luar kandungan   Keguguran   Penyakit radang panggul   Kista ovarium   Endometriosis   Fibroid   Gangguan serviks seperti infeksi atau kanker   Radang saluran tuba   Penyakit menular seksual   Masalah ginjal   Radang usus Ada baiknya Anda memeriksakan diri ke dokter spesialis penyakit dalam untuk mendapat pemeriksaan lebih lanjut selain USG. Jika tidak ditemukan masalah serius pada bagian bawah perut Anda, kemungkinan yang paling besar adalah Anda memiliki masalah lambung seperti:   Tukak lambung   Penyakit asam lambung   Gastritis Berikut beberapa tips untuk Anda:   Minum air mineral minimal 2 liter setiap hari   Utamakan makanan berserat untuk mencegah konstipasi   Kurangi konsumsi makanan berlemak   Hindari minuman berkafein seperti kopi dan teh, hindari juga soda dan minuman beralkohol   Konsumsi yoghurt   Konsumsi obat maag yang dijual bebas   Kurangi stres   Rutin berolah raga Semoga bermanfaat,Dr. Yosephine \",\n          \"Defar Fitri, Kram perut bisa diakibatkan oleh: nyeri otot perut gastritis tukak lambung gastroenteritis radang usus buntu infeksi ginjal  batu ginjal radang panggul endometriosis Sebaiknya Anda berkonsultasi dengan dokter kandungan di mana dokter akan menganalisis gejala dan melakukan pemeriksaan fisik. Tes penunjang seperti tes darah dan USG dapat dokter anjurkan. Terapi yang tepat akan dokter berikan. Tips berikut ini dapat Anda lakukan: hindari mengurut atau menekan bagian yang sakit konsumsi makanan bergizi seimbang secara teratur kelola stres dengan bijak minum air putih dalam jumlah cukup miliki waktu tidur yang cukup hindari merokok dan minum minuman keras hindari langsung berbaring sesudah makan kurangi minum minuman berkafein dan bersoda Artikel yang bisa Anda baca: Sakit perut Semoga bermanfaat dan salam, dr. Rony Wijaya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21132,\n        \"samples\": [\n          \"21 March 2018, 20:06\",\n          \"20 January 2016, 09:00\",\n          \"15 September 2017, 21:16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2770,\n        \"samples\": [\n          \"sakit-maag sakit-perut infeksi-saluran-kemih konstipasi asam-lambung gastritis\",\n          \"keringat-dingin sakit-maag\",\n          \"anak herba konstipasi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"konstipasi\",\n          \"diare\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"risk\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"high\",\n          \"low\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2014,\n        \"max\": 2021,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2020,\n          2015\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_to_answer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.350610612701875,\n        \"min\": 0.0,\n        \"max\": 880.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["### drop kolom yang tidak dipakai"],"metadata":{"id":"2wqngjgzrI74"}},{"cell_type":"code","source":["df.drop(columns=['question_date', 'answer_date', 'time_to_answer', 'risk', 'year' ], inplace=True)\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AkEa_Bzre4BD","outputId":"f436f286-0dc1-4547-c68e-70284d3e6d7f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                        title  \\\n","0                                    Penyebab dan cara mengatasi BAB berdarah   \n","1                                Susah BAB setelah operasi wasir 3 bulan lalu   \n","2  Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir   \n","3  Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang   \n","4                           Penaganan susah BAB dan muncul benjolan pada anus   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                question  \\\n","0                                                                                                                                                                                                                                                                                                                                       Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih   \n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?   \n","3                                                                                                                                                     Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.   \n","4  Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    answer  \\\n","0  Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...   \n","1  Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...   \n","2  Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...   \n","3  Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...   \n","4  Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...   \n","\n","                                 topics            topic_set  \n","0             wasir gangguan-pencernaan  gangguan-pencernaan  \n","1                      konstipasi wasir                wasir  \n","2                      konstipasi wasir                wasir  \n","3                  kulit benjolan wasir                wasir  \n","4  konstipasi wasir gangguan-pencernaan  gangguan-pencernaan  "],"text/html":["\n","  <div id=\"df-e3d38304-78c5-4ea8-8e65-9853f9251f0c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Penyebab dan cara mengatasi BAB berdarah</td>\n","      <td>Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih</td>\n","      <td>Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...</td>\n","      <td>wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Susah BAB setelah operasi wasir 3 bulan lalu</td>\n","      <td>Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?</td>\n","      <td>Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir</td>\n","      <td>Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?</td>\n","      <td>Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang</td>\n","      <td>Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.</td>\n","      <td>Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...</td>\n","      <td>kulit benjolan wasir</td>\n","      <td>wasir</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penaganan susah BAB dan muncul benjolan pada anus</td>\n","      <td>Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.</td>\n","      <td>Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...</td>\n","      <td>konstipasi wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3d38304-78c5-4ea8-8e65-9853f9251f0c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e3d38304-78c5-4ea8-8e65-9853f9251f0c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e3d38304-78c5-4ea8-8e65-9853f9251f0c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-7c48f103-da3f-4fbc-aab0-cf8064cd9de0\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c48f103-da3f-4fbc-aab0-cf8064cd9de0')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-7c48f103-da3f-4fbc-aab0-cf8064cd9de0 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 21376,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19750,\n        \"samples\": [\n          \"Nyeri perut sebelah kanan saat disentuh disertai demam dan sering BAB\",\n          \"tidak nyaman di perut dan feses kehitaman\",\n          \"Penyebab cemas dan jantung berdebar setiap malam hari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21187,\n        \"samples\": [\n          \"Dok saya mau tanya,ibu saya sering merasa sesak di dada,sehingga dia tidak kuat terkena angin ,hingga dirumah pun memakai baju berlapis lapis kata beliau itu biar hangat katanya kalau gak pake baju berlapis lapis beliau merasa dingin dan sesak padahal cuaca itu saat bersuhu hangatTerus ibu ku sering pake korset gitu biar badannya ke teken gitu,kalau gak sering pake samping di ikat perutnya katanya sih nyaman kalau di giniin Setiap diperiksa sama dokter katanya itu biasa Tapi setiap di beri obat malah makin parah mamah aku dokTerus di bola matanya kata mamah aku gak jelas katanya seperti ada darah gitu jadi melihatnya kurang jelasSering banget pusing dokTerus tangannya sering kebas gak kerasa apa apa saat terkena air dinginAku juga seperti itu dok ,aku sering tangan ku kebas saat dan sesudah terkena air dingin Kira kira itu sakit apa ya dok?\",\n          \"Dok saya baru saja selesai haid sekitar pada hari ke 4 setelah haid saya melakukan dengan suami, dan sekarang tepat 9 hari setelah haid saya merasa mual, perut kembung, serta kentut dan bersendawa, apakah itu hamil atau maag ? Bisa tolong dijelaskan perbedaannya ?\",\n          \"Slmt mlm dok. Sy telah menjalani operasi wasir dgn metode HAR \\\\u0026amp; RAR..sekitar 2 mgg lalu..kondisi skrng saat BAB ada darah bercampur dgn feses sy..dan juga sering kali ada cairan spt nanah sering keluar di dubur sy..hal ini terlihat klo sy gunakan tissue utk membersihkannya...obat antibiotik sudah habis dan dokter sdh tdk memberikan obat antiobiotiknya. Sy khawatir..saat BAB msh sj keluat darah..apalagi klo stlh bab encer anus terasa perih..sampai 8 jam hilang. Mhn informasinya apakah ini kondisi normal atau bagaimana?. krn menurut dokter itu tidak apa2.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21344,\n        \"samples\": [\n          \"Hai,Keluhan tersebut dapat disebabkan oleh:   infeksi atau batu saluran kemih   radang usus besar   cedera   tinja yang mengeras Usahakan untuk memiliki pola makan teratur. Perbanyak minum air mineral dan tidak menahan rasa saat ingin BAK maupun BAB. Batasi kafein/ alkohol. Tidak merokok. Sebaiknya tidak mengangkat benda-benda yang berat.Jika gejala belum membaik, disarankan agar Anda periksa ke dokter. Pemeriksaan fisik dan tes penunjang seperti tes urin atau USG, dapat membantu mengetahui penyebabnya. Sehingga dapat segera diberikan penanganan yang tepat.Anda dapat membaca halaman  Sakit perut kiri  Semoga bermanfaat,dr. Jessica\",\n          \"Halo Vharida Vitriyaa, Sakit perut  merupakan sakit yang dapat dialami semua orang, dan pada umumnya tidak memiliki penyebab yang serius. Jika Anda mengalami sakit perut, yang perlu diketahui pertama kali adalah bagian mana perut yang sakit. Dalam hal ini Anda sudah menyebutkan bagian bawah, maka dari itu berikut saya jabarkan penyebab  sakit perut bagian bawah  pada wanita:   Sakit perut akibat menstruasi   Ovulasi   Hamil di luar kandungan   Keguguran   Penyakit radang panggul   Kista ovarium   Endometriosis   Fibroid   Gangguan serviks seperti infeksi atau kanker   Radang saluran tuba   Penyakit menular seksual   Masalah ginjal   Radang usus Ada baiknya Anda memeriksakan diri ke dokter spesialis penyakit dalam untuk mendapat pemeriksaan lebih lanjut selain USG. Jika tidak ditemukan masalah serius pada bagian bawah perut Anda, kemungkinan yang paling besar adalah Anda memiliki masalah lambung seperti:   Tukak lambung   Penyakit asam lambung   Gastritis Berikut beberapa tips untuk Anda:   Minum air mineral minimal 2 liter setiap hari   Utamakan makanan berserat untuk mencegah konstipasi   Kurangi konsumsi makanan berlemak   Hindari minuman berkafein seperti kopi dan teh, hindari juga soda dan minuman beralkohol   Konsumsi yoghurt   Konsumsi obat maag yang dijual bebas   Kurangi stres   Rutin berolah raga Semoga bermanfaat,Dr. Yosephine \",\n          \"Defar Fitri, Kram perut bisa diakibatkan oleh: nyeri otot perut gastritis tukak lambung gastroenteritis radang usus buntu infeksi ginjal  batu ginjal radang panggul endometriosis Sebaiknya Anda berkonsultasi dengan dokter kandungan di mana dokter akan menganalisis gejala dan melakukan pemeriksaan fisik. Tes penunjang seperti tes darah dan USG dapat dokter anjurkan. Terapi yang tepat akan dokter berikan. Tips berikut ini dapat Anda lakukan: hindari mengurut atau menekan bagian yang sakit konsumsi makanan bergizi seimbang secara teratur kelola stres dengan bijak minum air putih dalam jumlah cukup miliki waktu tidur yang cukup hindari merokok dan minum minuman keras hindari langsung berbaring sesudah makan kurangi minum minuman berkafein dan bersoda Artikel yang bisa Anda baca: Sakit perut Semoga bermanfaat dan salam, dr. Rony Wijaya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2770,\n        \"samples\": [\n          \"sakit-maag sakit-perut infeksi-saluran-kemih konstipasi asam-lambung gastritis\",\n          \"keringat-dingin sakit-maag\",\n          \"anak herba konstipasi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"konstipasi\",\n          \"diare\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### Pola nama"],"metadata":{"id":"JmDYtQ2NsTop"}},{"cell_type":"markdown","source":["Pada answer maupun question. terdapat nama yang mana harus di hapus. terutama pada awal kalimat pada suatu paragraf"],"metadata":{"id":"6J_iAC_FfoQd"}},{"cell_type":"markdown","source":["Jika kita mengambil sample 200 data kemudain kita cek untuk kalimat pertamanya. Bisa dilihat kalo ada beberapa pola untuk mempermudah prepocessing"],"metadata":{"id":"m_N9bxDRgiG9"}},{"cell_type":"markdown","source":["1. **Sapaan Umum (tanpa nama)**:\n","   - Contoh:\n","     - \"Halo,\"\n","     - \"Hai,\"\n","     - \"Salam,\"\n","     - \"Alo,\"\n","     - \"Selamat [waktu],\"\n","   - Variasi: Beberapa sapaan diikuti langsung dengan isi atau penjelasan.\n","\n","2. **Sapaan dengan Nama**:\n","   - Contoh:\n","     - \"Halo [Nama],\"\n","     - \"Hai [Nama],\"\n","     - \"Alo [Nama],\"\n","     - \"Dear [Nama],\"\n","     - \"[Nama] yang baik,\"\n","   - Variasi: Nama bisa berupa nama lengkap, nama panggilan, atau nama identitas.\n","\n","3. **Sapaan dengan Terima Kasih**:\n","   - Contoh:\n","     - \"Halo, terima kasih atas pertanyaannya.\"\n","     - \"Halo [Nama], terimakasih atas pertanyaan Anda.\"\n","     - \"Alo [Nama], terima kasih sudah bertanya.\"\n","     - \"Hai, terimakasih telah bertanya di Alodokter.\"\n","   - Variasi: Ungkapan terima kasih sering muncul setelah sapaan.\n","\n","4. **Sapaan dengan Pendahuluan Informasi**:\n","   - Contoh:\n","     - \"Halo [Nama], keluhan yang Anda sampaikan...\"\n","     - \"Hai [Nama], dari keluhan yang Anda jabarkan...\"\n","     - \"Halo, nyeri perut yang Anda alami...\"\n","     - \"Dear [Nama], gejala yang Anda alami...\"\n","   - Variasi: Langsung menuju pokok pembahasan setelah sapaan.\n","\n","5. **Sapaan dengan Format Salam Islami**:\n","   - Contoh:\n","     - \"Wa'alaikumsalam [Nama],\"\n","     - \"Wa'alaikumsalam wr wb, Halo [Nama],\"\n","   - Variasi: Digunakan salam Islami untuk pembuka.\n","\n","6. **Sapaan Singkat atau Cepat**:\n","   - Contoh:\n","     - \"Hai.\"\n","     - \"Halo.\"\n","     - \"Alo!\"\n","     - \"Salam.\""],"metadata":{"id":"bvD4_cSar0lI"}},{"cell_type":"markdown","source":["- Halo  [person name],\n","- Dear [Person name],\n","- Hai [Person name],\n","- Hallo  [person name],\n","- Dear [person name],\n","- Alo [person name],\n","- hello [person name],\n","- salam [person name],\n","- hay ['person name']\n","\n","---\n","- Halo  [person name].\n","- Dear [Person name].\n","- Hai [Person name].\n","- Hallo  [person name].\n","- Dear [person name]\n","---\n","- Hai,\n","- Halo,\n","- hello,\n","---\n","\n","- Selamat pagi/siang/malam [person name].\n","- Selamat pagi/siang/malam [person name],\n","- Selamat pagi/siang/malam [person name]\n","\n","---\n","\n","- Hai.\n","- Halo.\n","- Alo.\n","---\n","- Halo [person name]..........\n","- Hai [person name]...........\n","- Halo [person name]..... Terimakasih atas pertanyaan Anda.\n","---\n","- Alo, terimakasih atas pertanyaannya.\n","- Halo terima kasih atas pertanyaannya untuk Alodokter.\n","\n","---\n","-  Terima kasih [person name] atas pertanyaannya\n","\n","- Terima kasih [person name] atas pertanyaannya.\n","\n","- Terima kasih telah bertanya di Alodokter.com\n","\n","- terimakasih atas pertanyaannya"],"metadata":{"id":"bPVX0q5thEoj"}},{"cell_type":"code","source":["first_sentences = df['answer'].sample(200, random_state=42).apply(lambda x: sent_tokenize(x)[0] if x else \"\")\n","for idx, i in enumerate(first_sentences.values):\n","  print(f'{idx+1}. {i}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bav3TYO4fKNo","outputId":"eb4b628d-e6e4-4de7-cff9-9019bb2a7496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Halo,Terimakasih atas pertanyaan yang Anda ajukan.Sebaiknya disebutkan kembali usia bayi Anda saat ini.\n","2. Halo Desriana......Terimakasih atas pertanyaan Anda.Nyeri pada daerah lambung biasanya disebut juga sebagai nyeri ulu hati atau dalam bahasa medis disebut sebagai nyeri epigastrium.\n","3. hai Anisnuri,terimakasih telah bertanya di alodokter.\n","4. Halo AiraniBatuk sebenernya adalah suatu reflek normal untuk membersihkan saluran nafas dari hal-hal yang tidak seharusnya ada di sana, seperti lendir, benda asing, atau kuman yang masuk.\n","5. Halo Febby, terima kasih atas pertanyaannya.\n","6. Alo, terimakasih atas pertanyaannya.\n","7. Halo Karuniadi, Terima kasih atas pertanyaannya.\n","8. HaloDari keluhan yang dipaparkan kemungkinan penyebabnya adalah karena ada luka di lambung Anda.\n","9. Virginia yang baik, keluhan yang Anda kemukakan belum mengarah pada satu penyakit yang spesifik.\n","10. ALo, Terimakasih atas pertanyaan anda di Alodokter Seseorang mengalami atau merasakan sesuatu yang mengganjal di tenggorokannya disebabkan karena kemungkinan adanya sumbatan.\n","11. Halo, Keluhan  nyeri pinggang kanan bawah , disertai nyeri perut, dapat disebabkan berbagai hal seperti : Ã˜  Tegang otot akibat aktivitas fisik, batuk yang produktif, atau melakukan olahraga dengan intensitas berat, tidak didahului dengan pemanasan, peregangan dan pendinginan yang cukup.\n","12. Alo Dharmaa, Terimakasih telah bertanya ke Alodokter.\n","13. AloNi Made Sumantariani terima kasih telah bertanya di Alodokter.\n","14. Terimakasih telah bertanya di Alodokter   Maag adalah gangguan lambung yang disebabkan produksi asam lambung yang meningkat.\n","15. Halo Guntur,  Terima kasih atas pertanyannya,    Kebiasaan atau pola buang air besar pada bayi tergantung dari kebiasaan dan pola makan bayi.\n","16. Alo, terima kasih sudah bertanya di Alodokter.\n","17. Halo, Terima kasih atas pertanyaannya.\n","18. Hai Dhea,Keluhan nyeri dada kiri disertai mual yang seringkali terjadi kemungkinan berkaitan dengan riwayat dispepsia/ maag  yang Anda alami sebelumnya.\n","19. Selamat malam.\n","20. Halo Akhmad, terimakasih atas pertanyaan Anda Cabe rawit dan makanan pedas lainnya sering dipercaya sebagai pencetus ambeien/ wasir/hemoroid.\n","21. Hai,Keluhan perut tersebut dapat disebabkan oleh gangguan lambung, seperti  penyakit asam lambung , yang dapat menimbulkan gejala seperti nyeri ulu hati, rasa terbakar atau panas di dada, atau mual muntah.Gangguan pada hidung yang dialami, diantaranya dapat diakibatkan oleh:   polip hidung   sinusitis Usahakan untuk tetap memiliki pola makan teratur.\n","22. Alo RIka, Terimakasih telah bertanya ke Alodokter.\n","23. Wa'alaikumsalam wr wb Halo Tika,  Terima kasih telah bertanya ke Alodokter.\n","24. Hai Adistika, Terimakasih telah bertanya ke Alodokter.\n","25. Halo, Penyakit asam lambung  atau disebut juga dengan Gastroesophageal Reflux Disease, merupakan suatu kondisi dimana terjadi gangguan pada katup yang membatasi lambung dengan kerongkongan.\n","26. Halo Lulu, Perut dan kaki yang bengkak harus diwaspadai.\n","27. Dear Aenur,Mual dan muntah dapat disebabkan oleh:   gastroenteritis   keracunan makanan   radang usus buntu   kadar gula yang terlalu tinggi atau rendah   hernia   batu empedu   penyakit asam lambung   hepatitis   dsb.\n","28. Hai May Wulandari,Terimakasih telah bertanya ke Alodokter.Sistem pencernaan bayi yang belum sempurna membuat bayi rentan mengalami  perut kembung .\n","29. Alo Muhammad Nurkolis, Sedikit berbeda dengan colostomy, ileostomy adalah pembentukan stoma menggunakan bagian dari ileus yang menjadi keluarannya di permukaan perut.\n","30. Salam,Keluhan yang Anda rasakan kemungkinan disebabkan oleh serapan makanan yang tidak optimal pada saluran cerna.\n","31. Hai Divaa, Sakit maag  merupakan istilah yang menggambarkan nyeri yang berasal dari lambung, usus halus, atau bahkan kerongkongan akibat sejumlah kondisi.\n","32. Halo Ibu/Bapak Hesma,  Kejang  disebabkan oleh aktivitas listrik di otak yang tidak normal.\n","33. Alo Desi, terimakasih sudah bertanya di Alodokter.\n","34. Hai,Gejala yang dialami teman anda adalah gejala yang umum terjadi terutama jika keluhan-keluhan sakit kepala, mual dan muntah memang dialami saat teman anda terlambat makan.Disaat seseorang terlambat makan maka akan terjadi kekurangan kadar gula di tubuh sehingga menyebabkan sakit kepala.\n","35. Dear Augustine, Gejala-gejala yang Anda alami dapat disebabkan oleh: tukak lambung penyakit asam lambung gastritis hepatitis pankreatitis radang saluran empedu batu empedu sindrom iritasi usus tumor Anda bisa datang berkonsultasi dengan dokter spesialis penyakit dalam penelisikan lebih dalam gejala yang Anda alami dan pemeriksaan fisik.\n","36. Halo Ida,Nyeri perut sebelah kiri atas disertai dengan mual dan muntah kemungkinan disebabkan oleh peradangan pada lapisan lambung atau gastritis.\n","37. Halo Andriansyah......Terimakasih atas pertanyaan Anda.Keluhan yang Anda utarakan dengan gejala utama berupa Muntah darah merupakan sauatu hal yang dapat dianggap serius dan perlu segera ditindak lanjuti dengan mengunjungi Dokter.Kondisi ini dapat disebabkan oleh berbagai macam hal, diantaranya sebagai berikut ini :   Iritasi di kerongkongan   varises di kerongkongan   Luka pada lambung   Sirosis hati   Kanker   dll.\n","38. Halo Merryangga, Terima kasih sudah menghubungi Alodokter,  Penyakit asam lambung  atau dikenal sebagai GERD, merupakan kondisi dimana terjadi naiknya kembali asam lambung ke atas kerongkongan.\n","39. Halo Torik, terima kasih telah bertanya dengan Alodokter.\n","40. Hai Andri,Sakit perut sebelah kiri atas pada dasarnya dapat diakibatkan oleh berbagai kemungkinan penyebab berikut ini:   Dispepsia/maag   Penyakit asam lambung   Pankreatitis  (peradangan pankreas)   Infeksi ginjal   Batu ginjal   Gangguan usus besar   dan sebagainya Untuk memastikan penyebab keluhan yang Anda alami tentunya diperlukan pemeriksaan lebih lanjut oleh dokter, baik melalui pemeriksaan fisik maupun tes penunjang jika diperlukan (tes darah, X-Ray, USG, endoskopi dan sebagainya).\n","41. Halo Jhon.....Terimakasih atas pertanyaan Anda.Jika kita lebih fokuskan kepada sakit perut yang Anda alami sebagai keluhan utama dan kembung sebagai keluhan penyerta, maka kondisi yang Anda alami dapat disebabkan oleh :   Gastroenteritis   Kram perut karena masuk angin   radang usus buntu   batu ginjal   Tukak peptik   Divertikulitis   batu empedu   panyakit crohn   Sindrom iritasi usus   dll.\n","42. Alo Selfia, Terimakasih atas pertanyaannya.\n","43. Hai ArsaGejala pusing dan mual yang Anda alami kemungkinan disebabkan oleh hormon, dimana terjadi perubahan saat menstruasi.\n","44. halo Ismi,  Jika anda mengalami sakit maag,pada dasarnya sakit maag dapat disebabkan oleh berbagai macam hal.\n","45. Alo Fakhrurozi, Terima kasih atas pertanyaannya.\n","46. Hai Zamzami, Masalah lambung merupakan kondisi yang cukup umum terjadi,  penyakit asam lambung  adalah salah satu masalah yang sering muncul.\n","47. Hai Lisa, Mual dan masalah yang Anda alami berkaitan dengan kondisi di lambung Anda.\n","48. Halo Aris,Sakit dada cenderung membuat khawatir penderitanya karena sering dikaitkan dengan masalah jantung.\n","49. Selamat malam, terima kasih telah bertanya di Alodokter.\n","50. Hai.\n","51. Salam Alodokter, Terima kasih sudah bertanya di Alodokter.\n","52. Halo Lully...... Terimakasih atas pertanyaan Anda.\n","53. Hallo Putri, terima kasih telah bertanya di Alodokter :') Sebelumnya yang ingin saya tanyakan, apakah selama 2 bulan ini anda belum pernah memeriksakan diri ke dokter ?\n","54. Hai, Kembung  dan nyeri perut bisa disebabkan oleh: Gangguan lambung, mis.\n","55. Hallo Alyvian, terima kasih telah bertanya di Alodokter :') Benjolan yang terdapat di anus dapat disebabkan oleh beberapa hal : Skin tag (pertumbuhan kulit berlebih sehingga membentuk benjolan) Wasir / hemorroid (pelebaran pembuluh darah anus) Fistula ani (benjolan yang terdapat daluran di dalamnya) Abses perianal (benjolan yang muncul akibat penumpukan nanah) Kista ani (benjolan yang berisi kantung cairan) Kutil Tumor dan lain sebagainya Sebelumnya yang ingin saya tanyakan, apakah anda memiliki riwayat konstipasi atau sulit BAB?\n","56. Hyeiin yang baik, meriang adalah tanda tidak spesifik bahwa tubuh orang sedang dalam kondisi yang tidak fit.\n","57. Hai insifa, Terimakasih telah bertanya ke Alodokter.\n","58. Hallo Muhammad Anwar Terimakasih atas pertanyaan anda Penyakit  asam urat atau gout  merupakan penyakit yang terjadi karena adanya peningkatan kadar asam urat dalam tubuh.\n","59. Halo Rizal atau Neng Balap,Gangguan pada lambung dapat disebabkan oleh penyakit seperti:   Tukak lambung   Penyakit asam lambung   Gastritis Jika Anda mengalami gangguan lambung, maka gejala yang dialami bisa berbagai macam, dan bisa mirip dengan masalah pada jantung atau paru.\n","60. Hai,Nyeri perut yang terjadi tidak berhubungan dengan kehamilan, karena kehamilan tidak menimbulkan gejala nyeri perut.\n","61. Dear Dian, Keluhan Anda dapat disebabkan oleh penyakit asam lambung.\n","62. Alo Rizal, Terima kasih atas pertanyaannya.\n","63. Hai Israq.\n","64. Dear Evy,Konstipasi adalah buang air besar dengan konsistensi padat lebih dari 3 hari sekali.\n","65. Halo Samsu,Saya akan mencoba menjawab pertanyaan anda:   Efek operasi?\n","66. Alo, Apakah darahnya cenderung berwarna terang atau gelap?\n","67. Halo Yonsasmaita, terimakasih atas pertanyaannya untuk Alodokter   Berhentinya menstruasi di usia anda saat ini menandakan anda sudah mengalami menopause.\n","68. Alo, terimakasih atas pertanyaannya.\n","69. Alo Norayzura, Penyebab nyeri dada kiri  yang perlu diwaspadai adalah serangan jantung.\n","70. Hai Raskita Perut yang membesar normal dapat disebabkan oleh: Penumpukan lemak perut akibat kegemukan.\n","71. Selamat siang, terimakasih atas pertanyaannya Kurang tidur menyebabkan hormon stress di dalam tubuh meningkat.\n","72. Halo Muntah pada anak merupakan salah satu hal yang tidak bisa dianggap remeh.\n","73. Dear Anjou, Diare merupakan buang air besar cair atau setengah cair lebih dari 3 kali sehari.\n","74. Halo, febriani.\n","75. Halo terimakasih sudah bertanya di website alodokter.\n","76. Halo Aya,Diare adalah kondisi sering buang air besar (BAB) lebih dari 3x sehari dengan konsistensi tinja lebih encer / lebih cair.\n","77. Salam, Dari info yang Anda sampaikan, saya tidak menemukan keluhan atau pertanyaan yang Anda ingin sampaikan.\n","78. Halo Dadang, Penyakit asam lambung adalah suatu kondisi naiknya asam lambung ke kerongkongan sehingga menimbulkan keluhan nyeri ulu hati dan rasa terbakar di dada.\n","79. Salam,Keluhan gangguan BAB merupakan keluhan yang timbul disebabkan oleh kebiasaan makan dan minum yang kurang tepat.\n","80. Alo, terima kasih sudah bertanya di Alodokter.\n","81. Shiella yang baik, muntah ialah keluarnya isi perut yang kebanyakan di dahului dengan rasa mual.\n","82. Halo Ibu,BAB keras dapat menyebabkan beberapa masalah, di antaranya adalah   Hemoroid/ ambeien.\n","83. \\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;Halo Vebe,\\u0026lt;/span\\u0026gt;\\u0026lt;/p\\u0026gt;\\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;Mengalami BAB berdarah pasti mencemaskan apalagi jika sudah berlangsung beberapa hari.\\u0026lt;/span\\u0026gt;\\u0026lt;/p\\u0026gt;\\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;BAB berdarah dapat disebabkan oleh beberapa hal tergantung dengan apakah darah yang keluar bersama tinja merupakan darah segar atau kehitaman.\\u0026lt;/span\\u0026gt;\\u0026lt;/p\\u0026gt;\\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;BAB berdarah segar biasanya disebabkan oleh  perdarahan pada saluran pencernaan bagian bawah  sedangkan BAB kehitaman biasa disebabkan oleh perdarahan saluran pencernaan bagian atas.\\u0026lt;/span\\u0026gt;\\u0026lt;/p\\u0026gt;\\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;BAB berdarah segar disebabkan oleh hal-hal berikut:\\u0026lt;/span\\u0026gt;\\u0026lt;/p\\u0026gt;\\u0026lt;ul type=\\disc\\\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;wasir\\u0026lt;/span\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;disentri, disebabkan oleh infeksi\\u0026lt;/span\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;peradangan usus besar: penyakit Crohn's, kolitis ulseratif\\u0026lt;/span\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;polip usus besar\\u0026lt;/span\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;divertikulitis, atau peradangan kantung abnormal dinding usus\\u0026lt;/span\\u0026gt; \\u0026lt;li class=\\MsoNormal\\ style=\\line-height: 19pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: 'Georgia','serif'; mso-fareast-font-family: 'Times New Roman'; mso-bidi-font-family: 'Times New Roman'; mso-fareast-language: IN;\\\\u0026gt;kanker usus \\u0026lt;/span\\u0026gt;\\u0026lt;p class=\\MsoNormal\\ style=\\mso-margin-top-alt: auto; mso-margin-bottom-alt: auto; line-height: 19.0pt;\\\\u0026gt;\\u0026lt;span style=\\font-size: 12.5pt; font-family: Georgia, serif;\\\\u0026gt;Apabila setelah diperiksa Anda tidak memiliki wasir, sebaiknya Anda berkonsultasi kembali dengan dokter apalagi gejala Anda masih menetap.\n","84. Hai Ktmurtini,Sakit perut merupakan keadaan yang seing terjadi di masyarakat dan bisa dialami oleh siapa saja.\n","85. Halo,   Apa anak Anda memiliki keluhan?\n","86. Halo Fitria,Mual adalah perasaan ingin muntah.\n","87. Dear Triesdha, Sakit perut sebalah kanan atas dapat disebabkan oleh: - cedera otot -  hepatitis -  pankreatitis - radang saluran empedu -  batu empedu -  infeksi ginjal -  batu ginjal -  pneumonia - dan sebagainya.\n","88. Alo Retro, Terimakasih atas pertanyaannya.\n","89. Salam Alodokter, Terima kasih sudah bertanya di Alodokter.\n","90. Hai Ardi, Terimakasih telah bertanya ke Alodokter.\n","91. Halo,Keluhan yang Anda alami dapat disebabkan oleh hal-hal di bawah ini :   Sakit maag   Penyakit asam lambung   Gastritis   Tukak lambung   Mengkonsumsi air yang terlalu banyak Hal-hal yang tertulis di atas menyebabkan keluhan yang hampir serupa seperti :   Nyeri pada perut bagian atas   Mual   Kembung   Nafsu makan menurun   Dll Untuk mengetahui secara pasti apa penyebab keluhan yang Anda alami, sebaiknya Anda memeriksakan diri ke dokter.\n","92. Hai,Sakit perut pada sebelah kiri dapat disebabkan oleh berbagai macam hal, dari mulai hal yang sederhana hingga perlu penanganan secepatnya.Sakit perut pada bagian kiri atas dapat terjadi karena hal-hal berikut :   Cedera   Adanya batu ginjal atau infeksi pada ginjal   gastritis - peradangan pada lapisan dalam dinding lambung   kanker lambung   pankreatitis - peradangan pankreas   divertikulitis - adanya iritasi pada kantung-kantung yang terbentuk pada dinding usus   obstruksi usus   serangan jantung   dan lainnya Untuk membaca lebih lanjut mengenai nyeri perut pada bagian kiri bawah Anda dapat membuka laman diskusi berikut :  diskusi nyeri perut kiri bawah Agar penyebab dari keluhan yang Anda alami dapat diketahui secara pasti sebaiknya periksakan secara langsung kondisi Anda ke dokter.\n","93. Hai Raka, Terimakasih telah bertanya ke Alodokter.\n","94. Hallo Zahra Aslamia, terima kasih telah bertanya di Alodokter :') Berdasarkan rentetan keluhan yang anda miliki kemungkinan besar keluhan yang anda alami tersebut masih dapat berhubungan dengan gangguan lambung yang dapat berupa : maag gastritis gerd tukak lambung kanker lambung Mengetahui bahwa anda pun masih memiliki pola kebiasaan, pola makan dan pola hidup yang buruk, tentunya kondisi inilah yang dapat menyebabkan timbul berulangnya keluhan - keluhan yang anda alami, ataubahkan dapat menyebabkan kondisi yang jauh lebih buruk lagi.\n","95. Halo Kaeka,  Makanan yang terlalu pedas, terlalu berminyak, minuman berkafein, dapat menyebabkan  stomach upset , dispepsia atau bahasa yang umum digunakan adalah sakit maag.\n","96. Halo,Terimakasih atas pertanyaannya ke alodokter.comWasir ( Hemoroid ) adalah pembengkakan yang berisi pembuluh darah yang membesar di dalam atau sekitar anus.\n","97. Selamat siang,Diare atau buang air besar yang lebih sering dan dengan konsistensi tinja yang lebih encer bisa disebabkan oleh beberapa penyebab, pada anak penyebab tersering adalah  rotavirus .\n","98. Waalaikumsalam.\n","99. Hallo RezaKeluhan yang Anda alami dicurigai penyakit yang beridiri sendiri-sendiri, yaitu  penyakit akit asam lambung  dan juga penyakit penyebab keliyengan dan pandangan gelap disertai rasa berdenyutKelihan yang Anda alami berdasarkan hasil pemeriksaan sebelumnya menggambarkan bahwa Anda mengalami hipotensi (perlu dikonfirmasi dengan usia Anda saat ini) dan juga Anemia ( normalnya HB pria sekitar 13-16 sedangkan wanita sekitar 12-14, namun harus dikonfirmasi kepada laboratorium tempat Anda memeriksakan darah, karena nilai normalnya berbeda-beda setiap laboratorium)Anemia sendiri adalah keadaan dimana jumlah hemoglobin (HB) dibawah normal, sehingga suplai oksigen keseluruh tubuh terutama otak menjadi tidak cukup memenuhi kebutuhan organ tersebut.\n","100. Halo, Rasa nyeri yang dialami perut dapat dirasa perih, tertusuk-tusuk, sakit yang menjalar, terasa panas.\n","101. Hai, Nyeri perut  bisa disebabkan oleh: Ketegangan otot Gangguan lambung, mis.\n","102. Hai Kiyanara, Bronkitis  adalah infeksi pada bronkus/saluran nafas utama yang dapat menimbulkan gejala pada saluran nafas seperti batuk, sakit tenggorokan, hingga sesak nafas.\n","103. Selamat malam, terima kasih telah bertanya di Alodokter.\n","104. Halo,Nyeri dada sering diidentikkan dengan penyakit jantung, padahal banyak penyebab lain yang menimbulkan keluhan menyerupai nyeri dada.\n","105. Halo Armita123 Terimakasih telah menggunakan layanan konsultasi Alodokter Asam lambung  memiliki fungsi yang penting bagi kesehatan pencernaan kita.\n","106. Hai Mafu.. Terimakasih untuk pertanyaan yang diberikan.\n","107. Halo Aprilia, terimakasih atas pertanyaan Anda Pada dasarnya, penyakit atau kondisi medis tertentu bersumber dari pola hidup yang kurang baik oleh diri sendiri.\n","108. Halo,  Sakit perut hebat bagian pusar membuat mulas lalu mencret atau diare, terjadi sewaktu waktu sebeluma atau sesudah makan kemungkinan dapat disebabkan seperti :  Sakit Maag  dengan gejala perut rasa perih, nyeri ulu hati, kembung, bila sedang kambuh menjadi diare isi cairan kekuningan.\n","109. Alo Dahlia, terima kasih ya sudah bertanya di Alodokter.\n","110. Halo Dadung, Perut kembung  sering dihubungkan dengan menu makanan dan minuman tertentu, serta cara mengonsumsinya.\n","111. Salam, Dari info yang Anda sampaikan, adanya keluhan pencernaan dan kondisi fisik yang tidak nyaman kemungkinan dapat disebabkan oleh gangguan lambung.\n","112. Halo Nur....... Terimakasih atas pertanyaan Anda.\n","113. Halo, Ambeien atau sering disebut wasir dalam istilah medis dikenal dengan nama  hemoroid .\n","114. Hai Veren, Gastritis , merupakan peradangan pada dinding bagian dalam dari lambung, dapat berlangsung akut, maupun kronis.\n","115. Hai Nithalian, Sakit perut dapat bersumber dari berbagai penyebab, baik karena kelainan pada dinding perut (kulit, otot, jaringan ikat) maupun akibat gangguan pada organ di dalam perut.\n","116. Selamat siang Edy Nugroho,   Pertama-tama perlu Anda pahami terlebih dahulu mengenai BAB sehat ya.\n","117. Alo Ferina, terima kasih sudah bertanya.\n","118. Halo, pertanyaan serupa baru saja saya bahas dalam tautan berikut ini : https://www.alodokter.com/komunitas/topic/wasir-internal Silahkan klik dan selamat membaca, apabila ada yang masih belum jelas dan ingin ditanyakan, silahkan membalas pada topik ini.\n","119. Halo, Sakit  maag  merupakan kondisi nyeri yang timbul yang dapat dipicu oleh beberapa hal seperti: Makan tidak teratur tukak lambung Efek samping obat Penyakit asam lambung Makan terlalu banyak dan terlalu cepat Merokok Konsumsi kafein, alkohol atau minuman berkarbonisasi atau soda Konsumsi makanan berminyak, berlemak, dan pedas Cemas dan stres Untuk itu pencetus-pencetus tadi harus dihindari agar maag tidak kembali timbul.\n","120. Alo Halimah, Terima kasih atas pertanyaannya.\n","121. Alo!\n","122. Hai Desy Sibrani.\n","123. Alo, Untuk saat ini berapa kali frekuensi BAB bayi Anda dalam sehari?\n","124. Hallo Abdul Rasa tenggorokan kering dan haus disertai mulas dan perih bisa disebabkan oleh berbagai macam, salah satunya adalah kondisi  sakit maag .\n","125. Halo El Roy, terima kasih ya sudah bertanya di alodokter.\n","126. Selamat siang, terima kasih telah bertanya di Alodokter.\n","127. Hai,Demam merupakan keadaan dimana suhu tubuh melebihi suhu tubuh normal yaitu 37.5 derajat celcius.\n","128. Alo Vina, terima kasih sudah bertanya.\n","129. Hai Harii, Mual  merupakan perasaan tidak nyaman pada bagian perut yang muncul sebelum muntah.\n","130. Halo, Sakit perut  adalah keluhan yang hampir pernah dirasakan oleh setiap orang.\n","131. Hai, terimakasih sudah bertanya di alodokter.com Banyak penyakit yang dapat terjadi berkaitan dengan keluhan nyeri perut kiri.\n","132. Selamat malam, terima kasih telah bertanya di Alodokter.\n","133. Hai,  Nyeri perut  yang Anda rasakan bisa disebabkan karena :   Keracunan makanan.\n","134. Hai Bani.\n","135. Alo Aisyah, Nanas  merupakan salah satu buah yang cukup banyak disukai.\n","136. Hai moms, Terimakasih telah bertanya ke Alodokter.\n","137. Hai Mega, terimakasih sudah bertanya di alodokter.\n","138. Halo, terimakasih atas pertanyaannya untuk Alodokter Pada umumnya bila ada makanan atau benda asing (seperti lalat) yang masuk dan tersangkut di kerongkongan (saluran makan), tindakan operasi sangat-sangat jarang dilakukan kecuali memang terdapat indikasi yang kuat (makanan atau benda asing tersebut tetap tersangkut meskipun sudah dicoba diambil oleh dokter atau terdapat sobekan yang berdarah dan sulit dihentikan pada esofagus/kerongkongan).\n","139. Halo Eliana,Kondisi susah BAB disebut dengan konstipasi.\n","140. Alo Nandi, terima kasih ya sudah bertanya di Alodokter.\n","141. Hai Reista Vistanie Hermansyah, Terimakasih telah bertanya ke Alodokter.\n","142. Alo Shilla!\n","143. Alo Rei, Benjolan di dubur  memang bisa disebabkan karena ambeien / wasir / hemoroid.\n","144. Halo Ayu Lukmana, terima kasih sudah bertanya di Alodokter.\n","145. Hai Bunda Novi,Sakit perut sebelah kanan seperti yang Anda alami pada dasarnya dapat diakibatkan oleh berbagai kemungkinan penyebab seperti:   Hepatitis  (peradangan hati)   Batu empedu   Radang usus buntu   Gastroenteritis  (peradangan usus dan lambung)   Infeksi saluran kemih/ISK   Batu ginjal  atau  infeksi ginjal   Kista ovarium   Endometriosis   dan sebagainya Mengingat terdapat berbagai macam kemungkinan penyebabnya, untuk memastikannya tentunya diperlukan pemeriksaan lebih lanjut oleh dokter.\n","146. Hai Aniss, Terimakasih telah bertanya ke Alodokter.\n","147. Halo zahra16,   Beberapa gangguan yang dapat terjadi pada lambung sehingga memberikan gejala nyeri pada perut sebelah kiri diantaranya : Dispepsia Dispepsia merupakan gangguan asam lambung yang paling umum terjadi atau biasa dikenal dengan sakit maag.\n","148. Hai.\n","149. Alo, terimakasih atas pertanyaannya.\n","150. Halo Christine......Terimakasih atas pertanyaan Anda.Keluhan yang Anda alami dengan gejala utama berupa sakit perut sebelah kanan bagian bawah dapat disebabkan oleh berbagai macam hal, diantaranya sebagai berikut ini :   cedera   Gangguan leher rahim   endometriosis   Batu ginjal   Hernia   Gastroenteritis   radang usus buntu   Kista ovarium   kehamilan ektopik   dll.\n","151. Halo Youd21, terimakasih sudah bertanya di Alodokter.com Madu  memiliki banyak manfaat untuk kesehatan karena memiliki banyak kandungan yang bermanfaat, di antaranya air, karbohidrat, vitamin seperti vitamin B dan C, mineral seperti kalsium, zat besi, dan sodium.\n","152. Halo Fitrea........ Terimakasih atas pertanyaan Anda.\n","153. Alo Ita, Terimakasih atas pertanyaannya.\n","154. Hai Deni, Maag  adalah gangguan yang ditandai dengan munculnya rasa nyeri dan perih pada lambung.\n","155. Alo Novita terimakasih telah bertanya dengan Alodokter.\n","156. Dear Saudara/i.\n","157. Hai Restripradika.\n","158. Dear Fitria, Sakit perut bagian atas dapat disebabkan oleh: -  gastritis -  tukak lambung - sindrom iritasi usus -  pankreatitis -  batu empedu -  hepatitis -  kanker lambung - dan sebagainya Sebaiknya Anda berkonsultasi dengan dokter spesialis penyakit dalam.\n","159. Alo deajavvu, Terimakasih atas pertanyaannya.\n","160. Hai,Keluhan yang Anda alami kemungkinan merupakan suatu gastritis, yaitu kondisi peradangan pada dinding lambung.\n","161. Hallo Nadyamhrni,Terimakasih sudah bertanya ke AlodokterDari keluhan yang dijabarkan, saya simpulkan yang ingin Anda tanyakan adalah mengenai buang air besar Anda yang disertai dengan darah ya Nadyamhrni.Kondisi buang air besar disertai dengan darah merupakan kondisi yang tidak normal, dan dapat disebabkan oleh berbagai kondisi, antara lain :   Infeksi saluran pencernaan  (disentri)   Perlukaan pada usus dan saluran cerna lainnya   Fissura ani   Wasir atau hemmoroid   dan lainnya Sulit memastikan penyebab dari keluhan yang Anda alami, tanpa dilakukan anamnesis dan pemeriksaan fisik secara langsung.\n","162. Salam, Keluhan yang Anda rasakan kemungkinan disebabkan oleh gangguan pencernaan yang dapat menyebabkan keluhan kolik perut atau rasa nyeri terpelintir pada pencernaan atau rongga perut.\n","163. Selamat malam Deasy Junavia Deanra, terimakasih telah bertanya kepada Alodokter.com Maag  adalah istilah yang menggambarkan nyeri yang berasal dari lambung, usus atau saluran pencernaan lain.\n","164. Halo Linbrill...... Terimakasih atas pertanyaan Anda.\n","165. Alo!\n","166. Halo,Sakit perut kiri bawah terlebih pada wanita dapat disebabkan berbagai penyakit.\n","167. Halo Muhammad...... Terimakasih atas pertanyaan Anda.\n","168. Dear Reskiani, Keluhan Anda daapt ditimbulkan oleh penyakit asam lambung.\n","169. Alo Garena, Terimakasih atas pertanyaannya.\n","170. Hai Jeane, terima kasih untuk pertanyaannya.\n","171. Dear Muhammad,Pengobatan penyakit paru-paru selama 6 bulan sangat mungkin adalah TBC (tuberkulosis).\n","172. Halo Tommy,Terima kasih atas pertanyaannya.\n","173. Hai Kurnia, Perut yang membesar dan terasa keras paska  keguguran , dapat diakibatkan oleh: Perdarahan di dalam perut.\n","174. Halo,  Sakit perut  bisa ditimbulkan oleh hal hal seperti :   Maag.\n","175. Halo Elisha Penyebab nyeri pinggang  dan  perut bagian bawah  pada perempuan itu ada bermacam-macam, berikut beberapa diantaranya:   Appendisitis atau radang usus buntu   Endometritis atau radang pada rahim   Pelvic Inflammatory Disease  atau penyakit radang panggul   Infeksi saluran kemih   Pengaruh haid   Kolitis atau radang usus besar   Kista ovarium   Kelainan serviks   Tumor   dll Keputihan  sendiri sebenarnya merupakan mekanisme normal tubuh untuk melindungi vagina, serviks, dan rahim dari infeksi kuman.\n","176. Hai aleey, Terimakasih telah bertanya ke Alodokter.\n","177. Hai Anna, Timbulnya sakit perut sebelah kanan seperti yang Anda alami pada dasarnya dapat diakibatkan oleh berbagai kemungkinan penyebab seperti: Gangguan pada organ pencernaan ( penyakit usus buntu ,  hepatitis ,  batu empedu , radang saluran empedu,  gastroenteritis ,  sindrom iritasi usus ,  radang usus ) Kelainan pada sistem saluran kemih ( infeksi saluran kemih ,  infeksi ginjal ,  batu ginjal ) Masalah pada organ reproduksi ( kista ovarium ,  endometriosis ,  radang panggul ) Sebelum dapat menentukan pengobatan yang tepat bagi Anda tentunya terlebih dahulu harus diketahui penyebabnya.\n","178. Hai Amos, Terimakasih telah bertanya ke Alodokter.\n","179. Hai Dyah,Sakit asam lambung atau disebut dengan GAstroesofageal Reflux Disease (GERD) dalam bahasa kedokteran merupakan keadaan diaman asam lambung yang seharusnya berada di lambung mengalami refluks atau aliran balik ke saluran cerna bagian atas yaitu esofagus dan mulut.\n","180. Hai,Nyeri perut sebelah kiri dapat diakibatkan oleh beberapa kemungkinan penyebab berikut ini:   Gastrititis  (peradangan dinding lambung)   Peradangan pankreas ( pankreatitis )   Sindrom iritasi usus   Divertikulitis (peradangan divertikula pada usus besar)   Impaksi tinja/tinja yang mengeras   Penyakit Crohn   Infeksi ginjal   Batu ginjal   dan sebagainya Untuk memastikan penyebabnya tentunya diperlukan pemeriksaan lebih lanjut, baik melalui pemeriksaan fisik maupun tes penunjang jika diperlukan seperti USG, X-Ray, endoskopi dan sebagainya.\n","181. Alo Azqiya, Terimakasih telah bertanya ke Alodokter.\n","182. Halo Yosua....... Terimakasih atas pertanyaan Anda.\n","183. HaloNyeri daerah ulu hati dapat disebabkan oleh beberapa kondisi, di antaranya yaitu:   Gastritis atau  maag   Tukak lambung   Penyakit asam lambung naik (GERD)   Sindrom iritasi usus (IBS)   Pankreatitis   Nyeri saat preeklampsia (pada wanita hamil dengan tekanan darah tinggi)   Gangguan pada kandung empedu (radang atau batu)   Ruptur aneurisma aorta   Penjalaran nyeri dari serangan jantung Umumnya masing-masing dari kondisi di atas keluhannya mirip.\n","184. Alo, terimakasih atas pertanyaannya.\n","185. Halo Abisai Jeremia, Keluhan  bab hitam  yang Anda alami ini dapat disebabkan oleh : Perdarahan pada saluran cerna : umumnya kasus perdarahan saluran cerna terjadi pada dinding bagian saluran cerna yaitu di bagian lambung Konsumsi jenis obat-obatan tertentu : obat penambah darah  Konsumsi jenis makanan tertentu seperti : blueberry Penyakit sirosis pada tingkat yang sudah parah dimana pembuluh darah internal yang sudah pecah Dari keluhan dan riwayat obat yang Anda sampaikan, kemungkinan konsumsi jenis obat penambah darah dapat menjadi penyebanya.\n","186. Terima kasih Enry Nurfatirnajih Wulan atas pertanyaannya.Keluhan yang Anda rasakan dapat disebabkan oleh berbagai hal, seperti:1.\n","187. Halo Adhetio,  Terima kasih sudah bertanya ke Alodokter.\n","188. Alo, terimakasih atas pertanyaannya.\n","189. Halo, terima kasih telah bertanya dengan Alodokter.\n","190. Halo,Ambeien merupakan pelebaran pembuluh darah vena pada daerah anus.\n","191. Hallo Romi, Terimakasih sudah bertanya di alodokter Diare  merupakan kondisi yang ditandai dengan encernya tinja yang dikeluarkan dengan frekuensi BAB yang lebih sering dari biasanya.\n","192. Hai,Operasi hemorrhoid yang sering dilakukan oleh dokter bedah di Indonesia umumnya menggunakan 2 teknik :   Hemorrhoidectomy - vena di dalam wasir diikat, kemudian wasir dipotong   Stapling - dengan suatu alat 'staple' yang digunakan untuk menghilangkan jaringan wasir dan menutup lukanya.\n","193. Hallo Erna86, terima kasih telah bertanya di Alodokter :') Sebelumnya yang ingin saya tanyakan, sudah berapa hari kah anda mengalami demam ?\n","194. Halo Aditya........Terimakasih atas pertanyaan Anda.Perlu Anda ketahui bahwa obat - obatan yang Anda dapat dari rumah sakit lebih mengarah ke gangguan pada organ perut yang kemungkinan gejalanya berupa rasa nyeri pada ulu hati / sakit perut bagian atas, disertai dengan timbulnya mual --- muntah, penurunan nafsu makan, dll.Penyebab dari sakit ulu hati atau dalam bahasa medis disebut sebagai nyeri epigastrium paling banyak disebabkan oleh karena Tukak peptikum, dimana kondisi ini merupakan terjadinya luka pada lapisan dinding lambung atau usus kecil.Selain dari tukak peptikum, kondisi yang Anda alami dapat juga disebabkan oleh karena : penyakit asam lambung / GERD, Radang pada pankreas / pankreatitis, penyakit kantong empedu, kanker lambung, dll.kami sangat menyarankan kepada anda untuk Cobalah kembali mendiskusikan masalah ini dengan Dokter yang telah memberikan obat tersebut kepada Anda agar segala sesuatunya terang dan jelas.Tips untuk anda : ikutilah saran dan pengobatan dari Dokter yang Anda temui, makan makanan sehat dan bergizi tepat waktu, Hindari makan asam-pedas-berlemak-digoreng, perbanyak minum air putih, kelola stress psikologis, STOP MEROKOK dan jangan minum alkohol.Klik artikel di bawah ini untuk lebih jelasnya : TUKAK PEPTIK ATAU TUKAK LAMBUNG Demikian penjelasan yang dapat kami sampaikan, semoga bermanfaat.Salam,Dr.\n","195. Halo,  Mual  bisa disebabkan karena beragam faktor seperti :   Keracunan makanan.\n","196. Dear Dian, Mual merupakan salah satu gejala saluran cerna yang kerap dirasakan dan dapat disebabkan oleh berbagai penyebab.\n","197. Halo Oman, Sesak napas  dapat disebabkan oleh beberapa hal yang tidak semuanya disebabkan oleh adanya penyakit atau masalah pada paru-paru.Beberapa hal yang dapat menyebabkan sesak napas adalah:   alergi   asma   sinusitis   infeksi paru: tuberkulosis (TBC), pneumonia   penyakit paru obstruktif kronik (PPOK), biasanya disebabkan oleh merokok   bronkitis   kanker paru-paru   penyakit jantung seperti gagal jantung, serangan jantung, aritimia jantung   penyakit asam lambung /  gastroesophageal reflux disease  (GERD)   gangguan cemas Untuk memastikan penyebabnya, sebaiknya Anda memeriksakan diri ke dokter spesialis penyaki dalam.\n","198. Hallo Maharani, Terimakasih sudah bertanya pada Alodokter Hampir semua sayuran sangat baik untuk pencernaan, tetapi memang ada beberapa sayuran yang dapat memicu meningkatnya asam lambung, diantaranya kol, kembang kol, dan brokoli.\n","199. Alo Janilyani Sakit maag dan GERD adalah kondisi medis yang berbeda namun keduanya saling berhubungan satu dengan yang lainnya,  sakit maag  sendiri adalah suatu kondisi yang menunjuk pada istilah medis dyspepsia, yaitu suatu kondisi nyeri dan panas pada lambung yang bisa diakibatkan oleh berbagai macam faktor seperti misalnya efek dari penggunaan beberapa obat nyeri, stres pikiran, adanya infeksi bakteri Helicobacter pylori, ataupun akibat adanya perlukaan pada permukaan dalam lambung (tukak lambung).\n","200. Halo,  Nyeri perut  hilang timbul bisa disebabkan karena:   Kolik usus/ kram usus.\n"]}]},{"cell_type":"markdown","source":["### Pola Lengkap:\n","1. **Sapaan**:\n","   - \"Halo [Nama],\"\n","   - \"Hai [Nama],\"\n","   - \"Alo [Nama],\"\n","   - \"[Nama] yang baik,\"\n","   - \"Wa'alaikumsalam [Nama],\"\n","2. **Ucapan Terima Kasih (opsional)**:\n","   - \"Terima kasih atas pertanyaannya.\"\n","   - \"Terimakasih telah bertanya di Alodokter.\"\n","3. **Pendahuluan Informasi (opsional)**:\n","   - \"Keluhan yang Anda sampaikan...\"\n","   - \"Gejala yang Anda alami...\"\n","   - \"Dari keluhan yang dijabarkan...\"\n","\n","### Kombinasi:\n","- \"Halo [Nama], terima kasih atas pertanyaannya.\"\n","- \"[Nama] yang baik, keluhan yang Anda sampaikan...\"\n","- \"Alo [Nama], terimakasih telah bertanya di Alodokter.\"\n","- \"Wa'alaikumsalam [Nama], gejala yang Anda alami...\""],"metadata":{"id":"xVsyoyq1nQ6P"}},{"cell_type":"markdown","source":["Tantangan nya yaitu ketika data seperti Halo/helo/hai [person name] tapi tidak ada pemisah seperti titik dan koma\n"],"metadata":{"id":"RoDMAPtKiPFY"}},{"cell_type":"markdown","source":["Untuk pembuktian perlu dilakukan pengecekan dan perhitungan"],"metadata":{"id":"b2WTg6Rei5ao"}},{"cell_type":"code","source":["import re\n","\n","def hitung_sapaan(teks):\n","    variants = r'(Hai|Hallo|Halo|Helo|Hello|Alo|Dear|Salam|Hay)'\n","    pola = rf'\\b{variants}(?:\\s+\\w+){{0,5}}[,.!?]'\n","    hasil = re.findall(pola, teks, flags=re.IGNORECASE)\n","    return 1 if hasil else 0\n"],"metadata":{"id":"5egriXSjhE5R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['pola 1'] = df['answer'].apply(hitung_sapaan)"],"metadata":{"id":"ZTZmdZa9jQK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['pola 1'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"6s5K7QqfkhBL","outputId":"2cb40c99-b52a-485e-ad92-43d3455a95e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pola 1\n","1    17706\n","0     3670\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>pola 1</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>17706</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>3670</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["df['pola 1'].value_counts(normalize = True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"QMOopRHCoCET","outputId":"6b8fc3d3-b45c-4237-afa5-64e844875b85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pola 1\n","1    0.828312\n","0    0.171688\n","Name: proportion, dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>proportion</th>\n","    </tr>\n","    <tr>\n","      <th>pola 1</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0.828312</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>0.171688</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":95}]},{"cell_type":"markdown","source":["### Pola kalimat awal di data"],"metadata":{"id":"DePdlNW7sx97"}},{"cell_type":"markdown","source":["Dari pola yang diberikan, berikut adalah pola umum untuk semua kalimat awal di data :\n","\n","1. **[Person] yang baik**:\n","   - Contoh: \"Nita yang baik\", \"Putrii yang baik\", \"Ainul yang baik\", \"Cindy Agustin yang baik\".\n","\n","2. **Selamat [waktu] [Person]**:\n","   - Contoh: \"Selamat pagi pak Budi\", \"Selamat malam Najah Najmia Halim\", \"Selamat siang\".\n","\n","3. **Waalaikumsalam [Person]**:\n","   - Contoh: \"Waalaikumsalam Afidah\", \"Waalaikumsalam wr wb\".\n","\n","4. **Terima kasih [Person] atas pertanyaannya**:\n","   - Contoh: \"Terima kasih Furqon Indrayono atas pertanyaannya\", \"Terima kasih Jeehan Fatiha Yeoja Kpopers atas pertanyaannya\".\n","\n","5. **Hay [Person], terimakasih atas pertanyaannya**:\n","   - Contoh: \"hay okta, terimakasih atas pertanyaannya\".\n","\n","6. **Sapaan umum tanpa menyebut nama**:\n","   - Contoh: \"Selamat pagi\", \"Selamat malam\", \"Selamat sore\".\n","\n","Pola yang dapat dirumuskan:\n","1. **Sapaan + Nama atau Identitas**:\n","   - \"[Person] yang baik,\"\n","   - \"Selamat [waktu] [Person]\"\n","   - \"Waalaikumsalam [Person]\"\n","   - \"Terima kasih [Person] atas pertanyaannya\"\n","   - \"Hay [Person], terimakasih atas pertanyaannya\"\n","\n","2. **Sapaan umum tanpa nama**:\n","   - \"Selamat [waktu]\""],"metadata":{"id":"4O_swXh8mczZ"}},{"cell_type":"markdown","source":["### Pola check pola [person name] yang baik"],"metadata":{"id":"yAEDagSVniKR"}},{"cell_type":"code","source":["def namaYangBaik(teks):\n","    # Pola untuk menangkap nama diikuti oleh \"yang baik\"\n","    pola = r'\\b([A-Z][a-z]+)\\s+yang baik'\n","\n","    # Mencocokkan pola dalam teks\n","    hasil = re.search(pola, teks)\n","\n","    # Jika pola ditemukan, kembalikan nama (group pertama), jika tidak kembalikan None\n","    return 1 if hasil else 0"],"metadata":{"id":"gkQhn14HmdD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['pola 2'] = df['answer'].apply(namaYangBaik)"],"metadata":{"id":"tDq1s0j4nmWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['pola 2'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"id":"drBKh5J3nvaz","outputId":"5c0e12a1-c408-4a99-cd8a-552f7ec9e3ca"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["pola 2\n","0    20937\n","1      439\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>pola 2</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>20937</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>439</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":[" ada 400 an"],"metadata":{"id":"2DKwuUJan0wT"}},{"cell_type":"code","source":["df[df['pola 2'] == 1].sample(30, random_state=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"O-_ROrr6nzL_","outputId":"50d64e57-8773-4983-e53f-ad5fc81efceb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                  title  \\\n","16618                     Penyebab perut bagian kiri bawah terasa nyeri   \n","15496                    Sakir maag disertai muntah dan demam menggigil   \n","19536                                   Mengatasi penyakit asam lambung   \n","19310             Rasa mengganjal di tenggorokan penderita asam lambung   \n","11504                                        Bayi usia 2bulan susah bab   \n","20372  Mual dan muntah saat telat makan disertai jantung berdebar-debar   \n","15612                               Nyeri pada perut bagian tengah atas   \n","16383                                  Penyebab BAB sering tidak tuntas   \n","20201                                 mulut pahit disertai sakit kepala   \n","17266               Perut tidak nyaman, mual dan tenggorokan mengganjal   \n","18155                                   Penyebab anak BAB terus menerus   \n","14898       Penyebab perut terasa nyeri setelah sahur disertai BAB cair   \n","611                                            Benjolan di sekitar anus   \n","12235                         Sakit perut disertai buang air besar cair   \n","9261                                Masalah perut kembung dan susah BAB   \n","21093                   sakit di bagian dada dan punggung sebelah kanan   \n","15997                                  Penyebab adanya kista pada perut   \n","9834                          Sakit di bawah pusar sisi kanan dan demam   \n","19162                       seperti ada yang mengganjal di ternggorokan   \n","15173                                    Sakit perut hingga ke pinggang   \n","6343               Nyeri perut atas bagian tengah seperti ditusuk-tusuk   \n","10710                                            mual saat bangun tidur   \n","19306                  Tenggorokan terasa mengganjal dan sulit bernapas   \n","1588                                        Pengobatan wasir yang tepat   \n","19203                      hubungan antara sakit lambung dan sakit haid   \n","6511                                 sesak napas disertai perut kembung   \n","16122            Selalu buang air besar setelah sarapan, apakah normal?   \n","6844                                penyebab nyeri ulu hati pada lansia   \n","9691                             Penyebab Sakit Pada Punggung dan Perut   \n","16132                                Penyebab sakit perut saat bergerak   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      question  \\\n","16618                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Pagi Dok....   saya mau bertanya,,kenapa yah perut bag kiri bawah saya agak sakit ??    \n","15496                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               asslamualaikum dok sy muklis 26 th mau tanya dok saya sudah seminggu sakit awal nya saya magh dok muntah-muntah sampai muntah kuning dok sampai demam menggil trus sy minum obat promagh dan paracetamol dok sdh baikan tp setelahx itu bsoknya saya malah sering kepla sakit dok badan nyeri-nyeri leher tegang dan di ikuti demam dok di jam\\ tertentu..   \n","19536                                                                                                                                                Hallo Dok..aku setiap minggu sering bgt diare, mual2 disertai muntah2, perut serasa seperti diperas2, mulut rasa nya mati rasa, tiap makan sesuatu ga berasa apa2 cuma asam dan mual, dan bagian belikat/punggung kiri atas sakit sekali seperti ada gelembungan angin menekan2 sampai saya angkat tangan kiri saja nyeri2 gitu..jujur saja, saya memang sering telat makan, krn kondisi kerja saya yg ga tentu ini, juga saya ini ngerokok tp bukan perokok besar, cuma kalo tiap plg kerja saja 2-3 batang atau kalo lg stress..dan saya pecinta kopi berat..apa lagi ice kopi..so yg ingin saya tanya kan apa sakit saya ini dok..kata orang2 itu asam lambung..kalo memang asam lambung apa ada obat yg manjur untuk mengobati sakit saya ini..dan apa yg harus saya lakukan agar tiap minggu ga sakit2 seperti ini terus dok..so bantu saya ya dok..terima kasih sebelumnya ya dok..   \n","19310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Dok saya terkena sakit asam lambung. Saya sudah menjaga makananan yg dipantang. Dan saat ini hanya mengkonsumsi madu+kayu manis bubuk. Alhamdulillah dada sudah tdk sesak, tdk mual. tapi di tenggorokan msh ada yg mengganjal. Apa itu tanda akan sembuh? Dan apakah saya hrs lanjut mengkonsumsi madu atau ada obat lain dok?   \n","11504                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Selamat sore dok. Saya ingin bertanya, anak saya umur 2bulan sudah 5hari tidak bab. Anak saya asi+sufor dok, tapi sufornya tidak sering, sehari hanya sekali kadang tidak diberi sufor. Apa kalau dikasih microlax aman dok? Sudah saya coba kasih setengah tube tapi tidak bab dok..   \n","20372                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Siang Dok,usia saya 31 thn,setiap hari saya mual-mual dan terkadang muntah,saya sarapan pagi jam 7,makan siang jam 12,dan makan malam jam 7 ,kalo lewat jam itu badan saya keringat dingin,gemetar,lidah pahit,jantung berdebar-debar,malam susah tidur,dan kalo tidur terbangun setiap 2 atau 3 jam dengan mual-mual dan jantung berdebar dan paling risih nya perasaan cemas dan ga enak .di pagi hari sering merasakan ngantuk saat bekerja. kira kira gejala saya apa ya dok,apakah ada hubungan nya ke penyakit jantung dok,mohon pencerahan nya.           \n","15612                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Dok, anak sy mengalami sakit/nyeri perut bagian tengah atas, gejalanya kesakitan, mual, dan jk sdh muntah sedikit lega, hal terjadi kambuhan, sdh beberapa kali ke dokter dan diberi analgetik (as. Mefenamat). Rasa sakit bukan melilit atau perih tp lbh spt diremas2, Jk diberi makanan akan muntah. Hal tjd sejak tahun lalu kemudian diambil tindakan appendectomy krn dr hsl rontgen dan usg terdapat cairan yg diduga ada perforasi. Sbg info anak sy usia 10th bb 49 kg. hal tsb disebabkan apa dan tindakan apa utk menanganinya jk kambuh ya dok? Tks   \n","16383                                                                                                           Selamat pagi, dok. Sejak saya terlalu sering mengonsumsi mie instan melebihi batas wajar waktu saja masih remaja, saya mengalami masalah pada proses buang air besar (bab) hingga saat ini. Kerapkali saya harus menghabiskan waktu hingga 30 menit bahkan 1 jam untuk proses bab, padahal normalnya proses bab dalam batas wajar biasanya 10-15 menit saja. Walaupun 30 menit, tapi tetap saja bab saya tidak bisa tuntas, bahkan waktu keluar kadang feses bercampur dengan sedikit darah merah, kadang juga disertai bau anyir darah ketika bab. Saya sudah mencoba mengatasi gangguan ini mulai dengan minum air putih, makan serat, serta mengurangi mengkonsumsi makanan berkarbohidrat \\u0026amp; minuman2 kafein, namun tetap saja tidak berhasil. Yang ingin saya tanyakan, apakah mungkin kondisi pencernaan saya (terutama usus besar) mengalami gangguan serius?Lalu bagaimana solusinya?Mohon penjelasannya, dok.   \n","20201                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Sore dok,,,   saya mau tanya, mulut berasa pahit dan kepala juga sakit.   kenapa ya dan ada penyakit apa ?   Terimakasih.   \n","17266                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Sore Dok, saya reni. Sebelumnya Maaf dok, saya ingin bertanya mengenai perut atas sebelah kiri terasa tidak enak, sering terasa mual, apa lagi jika di pakai untuk sering bergerak rasanya mau muntah. Tenggorokan juga terasa ada yang mengganjal. Leher, kepala, hingga mata sebelah kiri juga terasa tidak nyaman, rasanya pusing, apalagi jika terkena cahaya atau mendengar suara keras. Kurang lebih seperti itu yang saya rasakan. Jadi bagaimana dok? Obat apa yang sebaiknya saya gunakan? Terima kasih.   \n","18155                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Malam dok saya mau bertanya, anak saya usia 20 bulan masih ASI. Cuman saya heran kok udah beberapa bab terus, tapi badannya gak demam. Banyak yang bilang kalau saya hamil. Apakah benar dok?  Terimakasih   \n","14898                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          dok kenapa ya saya sakit perut dan terasa nyeri setelah sahur pertama? saya sahur memakan telur dan mie goreng. lalu setelah shubuh perut terasa nyeri seperti tanda2 mencret, lalu pas siang badan saya lemas gaenak badan, pas buka puasa pun saya tidak napsu makan sehingga pas isya saya baru keluar mencret dan muntah. sampai skrg perut saya terasa nyeri:'( bagaimana dok, terimakasih   \n","611    Dok.. tahun 2016 kemarin saya ada keluhan, ada benjolan disekitar anus, kalau saya bab juga terkadang mengeluarkan darah segar, setelah saya browsing, ternyata itu wasir/ambeien. wasir kan pantangannya makanan pedas, sedangkan saya suka banget sama makanan pedas. Saya agak bandel tuh dok. Januari 2017 akhirnya saya periksa. Cuma dikasih obat merah gitu yang dimasukin lewat anus. Benjolannya udah masuk lagi. Nah, bulan mei kemarin, selama seminggu berturut2 saya makan pedes terus dok.. waktu saya selesai bab, benjolan keluar lagi dok, kalau sebelumnya benjolan itu masih sedikit empuk. Kemarin itu benjolannya keras banget dok, kenapa ya dok??? Terus saya kasih deh rumput gandum, hasilnya mendingan. Tapi setelah kejadian benjolan keras itu dok, di kerutan anus bagian dalam itu, ada muncul benjolan lagi dok, kalau saya raba sih bentuknya panjang, tajam, kecil gitu dok, gatal banget juga dok. jadinya di anus saya kayak ada 2 benjolan gitu dok. Itu benjolan apa ya dok?? Bahaya kah??. Sol...   \n","12235                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ass dok.....   saya mau tanya dok.kenapa sakit perut saya hilang timbul dan selalu ke wc,,,,,,terkadang sehat total terkadang tiba2 saja kambuh lagi,,,,,apa ada penyakit yang seriuss,mohon petunjuknya dok       \n","9261                                                                                                                                                                                                                                                                                                                                                                                                                                                             Selamat siang dok, saya mau tanya, sejak 3 hari yang lalu perut saya di bagian tengah pelan\\ merasa bergas / kembung disertai dengan masalah kesulitan membuang air besar. Selama 3 hari ini saya merasa mual dan ingin muntah apa mungkin dikarenakan gas di perut dok?  Satu hari yang lalu, saya mencoba mengonsumsi obat pencahar dan hasilnya saya lancar BAB namun bentuknya menjadi cair dan gas di perut saya hanya keluar sedikit, tidak ada perkembangan yang lebih.  Apa yang harus saya lakukan dan makanan apa yang harus dihindari dok?  Terima kasih alodokter   \n","21093                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            assalam dok, saya mau tanya.. kenapa ya dok, tiap bangun tidur dada terasa berat, dada sebelah kanan selalu terasa nyeri dan punggung bagian kanan juga sering sakit, mohon penjelasannya dok, terimakasih :)   \n","15997                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Sudah satu tahun setengah saya di bilangi dokter katanya ada penyakit kista jinak tapi perut saya nggak sakit cuma kadang antara tiap setengah bulan trasa kedutan sekali saja tapi nggak sakit apa benar saya punya penyakit kista jinak apa nggak?   \n","9834                                                                                                                                                                                                                                                                       Assallammualaikum wr wb, Selamat siang dok, saya mahasiswi umur 22 thn selama 4 hari menjelang malam saya trus demam donk. Wajah saya bentol2, kuping gatel tpi agak sakit dan wajah agak membengkak. Kemudian beberpa hri ni mulai sembuh setelah berobat ke klinik keluarga ktanya alergi. Padahal sama sekali saya ga da riwayat alergi apapun . Tpi selama proses hilangnya bengkak saya, muncul rasa nyeri di dada, pusing, perut sakit sempet mual dan muntah , telinga masih sakit agak gatel, sakit di kedua sisi bahu smpai leher, dan yg pling sakit bagian bawah pusar sisi kanan. Dan satu lagi seminggu yg lalu saya menjalani operasi kecil yakni kelenjar tpi sebutan USG nya FAM. Mohon penceramahannya dok.. terima kasih . Waallaikumsalam wr wb.   \n","19162                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   dok kenapa setiap saya suka minum air saat malam ato saat siang seperti ada gumpelan makanan yg banyak sampe susah di telan..apa karna saya makannya kurang di kunyah ato emg ada sesuatu yg menganjal di tenggorokan?   \n","15173                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Selamat siang dok, saya Mau tanya. Saya merasakan Sakit perut hingga ke pinggang. Di saat duduk Dimana pun klo mau berdiri harus di regang atau Di tarik ke belakang baru merasa enak. Kira2 ap ya dok penyakit ny dan bagaimana harus mengatasi ny, soal ny udah cukup lama juga dok. Makasih   \n","6343                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Selamat dok, akhir-akhir ini perut saya sebelah atas tengah sering terasa nyeri seperti ditusuk, di sertai nyeri dada kadang seperti di tusuk / ditekan / panas, dan seperti ada yang mengganjal di tenggorokan, sakitnya tiba-tiba datang dan tiba-tiba hilang, kemudian akhir-akhir ini kepala saya juga sering merasa sakit seperti di tekan, kadang terasa sangat berat, kadang terasa puyeng juga, dan tiba-tiba hilang Itu kira-kira kenapa ya dok? Apa kepala pusing ada hubungannya dengan sakit fi perut ? Mohon arahannya dok, terimakasih   \n","10710                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     DOK SAYA MAU TANYA NIH, KENAPA YA DI SETIAP SAYA BANGUN TIDUR SUKA MUAL MUAL DAN SUKA SAKIT BAGIAN TENGAH PERUT, APAKAH MAGH KRONIS? LAMBUNG SAYA BERMASALAH?   SOLUSINYA GIMANA DOK JIKA INGIN MEMINIMALISIR/ INGIN SEMBUH   APAKAH ADA OBAT HERBAL ATAU OBAT APOTIK?   TERIMAKASIH   \n","19306                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Dok, saya mau tanya. Tiga hari ini tenggorokan saya seperti ada yang mengganjal. Awalnya saya kira itu dahak yang tidak bisa keluar, tapi saya rasa itu bukan dahak karena saya jadi sedikit susah untuk bernafas. Kira kira kenapa ya dok? Terimakasih   \n","1588                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Assalamualaikum malam dok Saya punya masalah bab yg tdak teratur setelah melahirnya malah setiap bab sambil mengeluarkan darah.. Umur anak saya satu tahun dok Beberapa waktu lalu sudah tidak wasir lgi tpi tdi waktu pagi saat bab tinja keras dok dan mengeluarkan darah dan sekarang muncul benjolan bagaimana cara mengobatinya dan obatnya Terima kasih sebelumnya   \n","19203                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Dok, saya mau nanya dong , saya dulu haid ga pernah ngerasa sakit atau apapun dan sedikit pun malah kadang pas haid tu kaya gatau gtu gaada tanda\\ sakit atau apa\\ . Dan pada suatu hari saya terkena sakit lambung yg bisa di blg parah, krna saya sakit Tukak lambung kronis gtu dok, tp skrg kan udh ga sakit lgi tp knpa haid saya sekarang sakit sekali, kadang saat haid saya pucat, dan kaya mau pingsan krna sakit sekali, apa berpengaruh dari sakit lambung dok?   \n","6511                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Assalamu Alaikum dok. Saya wanita brusia 25 thn. TB 150cm BB kurang lbih 60kg. Dua minggu yang lalu saya terkena hipertensi 150/100, prsaan tiba2 sesak Trus hbis mnum obat kmbali normal. Tpi akhir2 ini sesak nafas lgi trus klo brnapas skit tembus belakng. Dan sebulan ini cuma keluar flek coklat bukan haid. Klo mkan juga tidak terasa kenyang sperti tidak nyampe ke perut. Kdang mual klo uluhati terlalu sakit. kira2 ini karna pengaruh obesitas atau gmna dok??? Sblumnya saya prnah konsumsi obat cacing.   \n","16122                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Selamat siang, Dokter.    Saya mau tanya.    Normalnya BAB seseorang adalah 3 hari. Tapi saya selalu BAB setelah sarapan dan itu terjadi setiap pagi di setiap hari.    Apakah itu juga normal?    Ataukah ada yang salah dalam perut saya?   Terima kasih.   \n","6844                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Dok saya mau tanya,nenek saya setiap hari suka merasakan nyeri pada ulu hati,itu sebabnya kenapa ya dok?   \n","9691                                                                                                                                                                                                                                      Selamat sore dok, saya ingin bertanya.    orang tua saya mengalami sakit pada perut dan punggung.. sudah masuk Rumah sakit dan dirawat selama 5 hari dengan hasil radiologi, usg dan diagnosa yang berbeda-beda. mulai dari batu ginjal sampai dengan liver selama 5 hari perawatan RS tidak ada sedikitpun perubahan bahkan semakin sakit.   saya pindahkan ke rumahsakit lain hasil diagnosanya pun berbeda yaitu dikarenakan Infeksi Paru-paru yang sudah lama diderita orang tua saya sejak 2014 sehingga menyebabkan sakit pada perut dan punggungnamun obat tersebut juga tidak ada perubahan.    bisa tolong dijelaskan dok sebetulnya apa yang mempengaruhi sakit pada perut dang punggung orang tua saya, dan apa obat yang dapat meredakan dan menghilangkan rasa sakitnya ?   Terimakasih   \n","16132                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      selamat mlm dok....dok.sy mw tny knp yaa perut saya terasa sakit sekali untuk bergerak sakiy, untuk jalan sakit, terus.sempat demam trus panasnya turun tp perut.msih ttp sakit pdhl sudah minum obat maagh terus klo batuk itu terasa sakit juga..   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        answer  \\\n","16618  Stevani yang baik, sakit perut merupakan salah satu kondisi yang sering ditemukan pada layanan primer. Sakit perut menjadi sedemikian kompleks oleh karena beragamnya organ yang menempati rongga perut yang sangat besar. Pada wanita, hal ini diperumit dengan adanya organ reproduksi yang cukup besar yakni rahim dan komponennya yang bila bermasalah, tentu menimbulkan sakit. Adapun beberapa kondisi nyeri perut pada bagian kiri bawah dapat disebabkan oleh : batu atau infeksi pada sistem ginjal batu atau infeksi pada saluran kemih usus buntu yang tidak khas dapat muncul dari kiri pankreatitis atau radang pada pankreas kista indung telur yang terplintir endometriosis atau adanya jaringan rahim diluar dinding rahim itu sendiri divertikulitis masalah pada leher rahim Adapun nyeri untuk sementara dapat diatasi dengan penahan nyeri yang dijual bebas seperti  paracetamol  atau  ibuprofen  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Perhatikan kondisi lain yang menyertai perut sep...   \n","15496  Muhammad yang baik, dalam mengamati satu penyakit hendaknya Anda tidak berpatokan pada satu gejala saja seperti gejala maag, oleh karena kondisi serupa dapat ditemui pada kondisi lain. Seperti misalnya petunjuk berupa rasa demam, hal ini lebih banyak mencerminkan kondisi infeksi oleh karena Indonesia yang berada pada daerah tropis, apalagi disertai gejala nyeri-nyeri sekujur tubuh yang merupakan gejala umum infeksi. Demam yang disertai dengan gejala maag biasanya mengacu pada infeksi saluran pencernaan seperti misalnya tifus, atau gejala diare. Penanganannya pun harus secara komprehensif agar pemulihan lebih efektif terjadi. Demam yang ada bisa dikurangi dengan penurun panas yang dijual bebas seperti  paracetamol  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Maag yang ada dapat dikurangi dengan gaya hidup ramah lambung seperti mengurangi asupan makanan pedas/bersantan atau minuman berkafein seperti kopi, kemudian memperbaiki pola makan tidak teratur, dan manajemen str...   \n","19536  Lin yang baik, masalah pada pencernaan memang dapat muncul dalam berbagai bentuk, mulai dari rasa mual, penuh di lambung, muntah-muntah, nyeri perut hingga diare. Namun dari kondisi-kondisi tersebut setidaknya dapat diperkirakan penyebab kondisi yang ada, untuk kemudian dilakukan pemeriksaan lebih lanjut untuk menentukan diagnosis serta penanganannya. Adapun diare dan sakit lambung biasanya disebabkan oleh 2 hal yang berbeda dimana diare biasanya lebih mengacu pada masalah di saluran cerna bagian bawah seperti usus besar. Namun demikian ada pula kondisi-kondisi dimana keduanya dapat muncul bersamaan. Beberapa masalah pencernaan yang memiliki gejala-gejala sebagaimana yang Anda kemukakan meliputi : infeksi saluran pencernaan sakit maag GERD atau naiknya asam lambung ke tenggorokan irritable bowel syndrome  yakni kumpulan rasa tidak nyaman di saluran cerna seperti mual, muntah, rasa penuh di lambung, yang juga disertai perubahan pola buang air besar seperti sembelit atau justru mencr...   \n","19310  Evita yang baik, rasa mengganjal yang ada di tenggorokan bisa disebabkan oleh beberapa faktor. Pada mereka yang memiliki riwayat masalah pada lambung sebagaimana yang Anda alami, rasa mengganjal ini bisa disebabkan oleh kondisi GERD atau naiknya asam lambung ke tenggorokan dan mengiritasi dinding tenggorokan sehingga menimbulkan sensasi seperti mengganjal di tenggorokan. Namun tak menutup kemungkinan bahwa ada penyebab lain yang mendasari rasa mengganjal di tenggorokan seperti adanya penumpukan dahak pada mereka yang sedang mengalami batuk atau alergi. Selain itu pembengkakan amandel, adanya abses atau kumpulan nanah, hingga adanya tumor, bisa menjadi faktor yang menyebabkan adanya rasa mengganjal di tenggorokan. Penting untuk tetap menjalani gaya hidup ramah lambung seperti menghindari makanan pedas/bersantan, menghindari kafein seperti pada kopi, manajemen stres psikis, dan usahakan untuk tidak langsung berbaring setidaknya 2 jam pasca makan. Bila kondisi berlanjut jangan ragu me...   \n","11504  Qairani yang baik, Pola buang air besar seseorang dapat menjadi indikator sederhana bagaimana kesehatan saluran cerna. Adanya masalah pada buang air besar seperti sembelit ataupun mencret mengindikasikan sebagian besar masalah pada saluran cerna. Meskipun demikian, ada pula kondisi di luar saluran cerna secara langsung, yang mempengaruhi pola buang air besar. Sembelit pada bayi yang masih berusia sangat dini, adalah hal yang cukup umum terjadi. Bayi dikatakan mengalami sembelit apabila buang air besarnya kurang dari 3 kali dalam 1 minggu. Adapun beberapa penyebab sembelit pada bayi meliputi : kurangnya asupan cairan atau dehidrasi bayi mengalami alergi terhadap susu yang dikonsumsi bayi baru mengganti makanan dengan tekstur yang lebih padat penyakit tiroid kekurangan elektrolit dalam darah Meskipun hal ini umum terjadi, tak berarti sembelit dapat disepelekan pada bayi. Untuk sementara cobalah untuk lebih banyak memberikannya cairan. Pertimbangkan kembali sufor yang dikonsumsinya. P...   \n","20372  Rumeo yang baik, gejala yang timbul seperti keringat dingin, gemetar, berdebar-debar adalah merupakan pertanda kadar gula dalam tubuh Anda rendah sehingga tidak ada energi yang bisa dipakai untuk meneruskan aktivitas dan tubuh merespons dengan serangkaian \\alarm\\ tersebut. Rasa mual yang timbul dapat juga merupakan masalah lambung yang dapat dikurangi dengan pola hidup yang baik seperti : tidak mengkonsumsi kafein (misalnya dalam kopi) tidak mengkonsumsi makanan pedas tidak terlambat makan tidak langsung berbaring sehabis makan tidak mengkonsumsi jamu-jamuan atau obat-obatan tertentu secara rutin tanpa pemantauan dokter manajemen stres yang baik Namun demikian keluhan tersebut dapat pula merupakan manifestasi dari masalah psikis seperti gangguan cemas menyeluruh, serangan panik, maupun depresi. Umumnya masalah psikis ini diiringi dengan rangkaian masalah fisik lainnya seperti sulit tidur, rasa mual, cemas, berdebar-debar dan lain sebagainya. Masalah psikis ini timbul oleh karena ad...   \n","15612  Lia yang baik, nyeri pada perut kanan atas dapat mengindikasikan banyak hal karena beragamnya organ yang terdapat pada daerah tersebut. Adapun beberapa kondisi yang dicirikan dengan timbulnya pada nyeri perut bagian tengat atas atau ulu hati meliputi : sakit maag tukak lambung yakni adanya perlukaan pada lambung masalah pada liver dan sistem empedu seperti adanya batu atau peradangan pleuritis atau radang pada selaput paru pankreatitis atau radang pankreas irritable bowel syndrome  yakni kumpulan rasa tidak nyaman di perut seperti nyeri, mual, rasa penuh, yang disertai perubahan pola BAB, yang disebabkan kebanyakan oleh karena masalah psikis Karena masalah dicurigai berasal dari saluran pencernaan, cobalah untuk merubah gaya hidup menjadi lebih ramah lambung yakni menghindari konsumsi makanan pedas, bersantan, menghindari konsumsi kafein seperti pada kopi, memperbaiki pola makan yang tidak teratur, serta menghindari konsumsi jamu-jamuan atau obat-obat nyeri tanpa indikasi dari dokt...   \n","16383  Fahmi yang baik, hambatan pada buang air besar merupakan kondisi yang cukup mengganggu aktivitas sehari-hari karena rasa ingin buang air besar biasanya cukup mengganggu konsentrasi. Adapun mereka yang buang air besarnya tidak lancar biasanya bisa disebabkan oleh karena kondisi fesesnya yang kurang baik dan hal ini tentu berkaitan pula dengan kondisi saluran cernanya. Adanya darah pada saluran cerna juga ikut mengkontribusikan kemungkinan serius yang terjadi pada Anda. Beberapa kondisi yang dapat mendasari gejala ini meliputi : kurangnya asupan serat sehari-hari kurangnya cairan infeksi saluran cerna irritable bowel syndrome  yakni kondisi gangguan saluran cerna yang ditandai dengan kumpulan rasa kurang nyaman di perut yang disertai perubahan pola buang air besar dan berkaitan dengan kondisi psikis kanker usus besar polip rekti wasir atau ambeien Langkah pertama pada kasus Anda tentunya dengan memperbaiki pola makan sehari-hari. Konsumsilah lebih banyak sayur dan buah-buahan dan jan...   \n","20201  Johana yang baik, mulut yang pahit dapat disebabkan oleh berbagai macam sebab. Kondisi yang secara medis disebut dysgeusia ini dapat tampil dalam berbagai variasi yakni mulut yang terasa masam, pahit, atau terasa seperti mengecap logam. Beberapa kondisi yang dapat menyebabkan gangguan rasa mengecap pada mulut, meliputi : asam lambung yang naik ke kerongkongan efek samping kemoterapi pengaruh pengobatan tertentu seperti kemoterapi akumulasi bakteri akibat kurang menjaga higiene gigi infeksi Kondisi yang kurang menyehatkan seperti kelelahan cenderung dapat menimbulkan infeksi ringan yang mengakibatkan timbulnya rangkaian gejala seperti mulut pahit dan nyeri kepala. Nyeri kepala dapat diatasi sementara dengan penahan nyeri yang dijual bebas seperti  paracetamol  atau  ibuprofen  tentunya dengan memperhatikan petunjuk pemakaian yang berlaku. Mulut yang pahit bisa dikurangi dengan menggosok gigi dan berkumur dengan antiseptik atau larutan garam. Bila keluhan memburuk jangan ragu memerik...   \n","17266  Reni yang baik, gejala perut yang terasa tidak nyaman seperti mual, nyeri, atau serasa muntah, merupakan tanda bahwa terjadi gangguan pada saluran cerna. Gangguan dapat terjadi pada saluran cerna atas maupun bawah. Beberapa kemungkinan penyebabnya meliputi : dispepsia penyakit asam lambung yang naik irritable bowel syndrome masalah pada empedu seperti radang maupun batu empedu Tenggorokan yang terasa tidak nyaman dapat disebabkan oleh pengaruh asam lambung yang naik dan mengiritasi dinding tenggorokan. Beberapa kemungkinan lain seperti gejala radang tenggorokan juga dapat menyebabkan gejala yang serupa. Dan oleh karena kondisi tubuh yang kurang optimal, umumnya gejala lain sering mengikuti seperti nyeri kepala, rasa kurang nyaman pada mata. Pada dasarnya penanganan ditujukan pada penyebab munculnya keluhan utama. Oleh karenanya perlu dilakukan serangkaian pemeriksaan lengkap seperti USG, pemeriksaan darah lengkap, dan rontgen, bila penanganan awal masih belum menunjukkan hasil. Pen...   \n","18155  Joan yang baik, kami mengasumsikan bahwa yang memiliki permasalahan disini ialah Anda, bukan bayi Anda. Mengenai kehamilan seseorang, umumnya wanita selama masa nifas sulit sekali untuk mengalami kehamilan karena tingginya kadar prolaktin yang menghambat produksi hormon yang berfungsi untuk memicu keluarnya sel telur untuk kemudian dibuahi. Masa nifas sendiri sebetulnya hanya berlangsung selama 40 hari pasca melahirkan. Namun demikian setelah masa nifas, kadar prolaktin tidak langsung menurun melainkan tetap tinggi karena merangsang produksi air susu ibu untuk bayi. Kadar yang tetap tinggi inilah yang membuat kehamilan sulit terjadi. Melalui prinsip inilah ditemukan salah satu metode KB alamiah yakni Metode Amenore Laktasi, dimana seorang ibu harus tetap menyusui bayinya sehingga kadar prolaktin tetap tinggi dan mencegah terjadinya kehamilan karena sel telur yang tidak diproduksi. Mengenai BAB terus menerus, terdapat variasi terjadi atau tidak terjadinya demam. Cobalah untuk mengko...   \n","14898  Halo Herawati yang baik,  Perubahan konsistensi tinja menjadi lunak hingga cair yang disertai dengan peningkatan frekuensi buang air besar (3 kali atau lebih dalam sehari) merupakan gejala umum  diare . Tidak jarang diare juga disertai keluhan : nyeri perut mual hingga muntah penurunan nafsu makan demam Sebagian besar diare akut disebabkan oleh konsumsi makanan/minuman yang terkontaminasi bakteri ataupun virus. Biasanya pemulihan berlangsung selama 2-4 hari. Namun bila Anda merasa sangat terganggu dengan kondisi ini, segeralah berkonsultasi secara langsung ke dokter. Penanganan yang bisa Anda lakukan selama di rumah : cukupi kebutuhan cairan tubuh dengan perbanyak minum air, setidaknya 2- 3 liter per hari hindari konsumsi makanan yang terlalu pedas, asam, dan juga berminyak, bila memungkinkan, makanlah makanan lunak seperti bubur konsumsi obat antidiare yang dijual bebas, seperti yang mengandung attapulgit bila terasa nyeri atau demam, Anda bisa mengonsumsi paracetamol untuk mereda...   \n","611    Ratu yang baik, benjolan pada anus memang paling sering disebabkan oleh wasir. Wasir atau ambeien yang secara medis dikenal dengan istilah  hemorrhoid , terjadi oleh karena pembesaran pembuluh darah sekitar anus yang bisa disebabkan oleh karena kebiasaan mengedan, mengangkat beban berat, atau duduk terlalu lama. Pembuluh darah ini kadang terluka ketika dilalui oleh feses yang keras sehingga keluar darah ketika buang air besar.  Pada tahap tertentu, benjolan masih dapat dimasukkan dengan tangan, namun benjolan juga sering tidak bisa lagi dimasukkan ke dalam tangan ketika kondisi lanjut. Selain wasir, benjolan pada anus juga bisa disebabkan oleh : abses perianal yakni adanya kumpulan nanah disekitar anus kutil anus kanker anus polip recti prolaps recti yakni turunnya bagian akhir dari usus besar Penanganan benjolan tentu bergantung pada jenis benjolannya. Ada yang memerlukan tindakan pembedahan untuk bisa mengangkat benjolan tersebut. Oleh karenanya penting bagi Anda untuk terlebih d...   \n","12235  Tarmizi yang baik, mencret atau buang air besar cair merupakan kondisi berubahnya konsistensi kotoran yang seharusnya padat menjadi cair dan kadang bisa disertai dengan peningkatan frekuensi. Sakit perut yang disertai dengan mencret sejatinya mengindikasikan adanya masalah pada sistem pencernaan yang bisa disebabkan oleh beragam faktor. Adapun beberapa penyakit yang memang dicirikan dengan sakit perut disertai dengan mencret meliputi : infeksi saluran pencernaan oleh virus, bakteri, atau parasit keracunan makanan alergi terhadap kandungan makanan tertentu efek samping pengobatan irritable bowel syndrome  yakni kumpulan gejala tidak nyaman di perut yang disertai perubahan pola buang air besar Yang terpenting pada buang air besar cair ialah mengganti cairan yang keluar dengan larutan elektrolit untuk mencegah komplikasi dehidrasi. Beberapa kasus juaga memperoleh pemulihan yang lebih singkat dengan mengonsumsi probiotik. Namun demikian jika kondisi tak kunjung membaik jangan ragu meme...   \n","9261   Michael Lim yang baik, rasa kembung pada perut biasanya disebabkan oleh tumpukan gas dalam rongga pencernaan yang berakumulasi oleh karena satu dan lain hal. Kondisi kembung ini kadang bisa disertai dengan gejala lainnya seperti nyeri ulu hati, gangguan buang air besar, dan lain sebagainya. Kondisi saluran cerna yang baik harusnya terjadi pasase atau pergerakan usus yang baik untuk menghantarkan makanan dan udara, untuk kemudian diproses dan sisanya dibuang melalui lubang pembuangan. Beberapa kondisi yang dapat menimbulkan kembung, dapat berupa : gangguan lambung atau sakit maag dimana pada kondisi ini, perut didominasi oleh rasa nyeri ulu hati, kembung, dan mual gangguan pergerakan usus, misalnya pada ileus karena ada sumbatan pada usus, atau karena pergerakan usus yang melambat karena kekurangan elektrolit gangguan pengosongan lambung, misalnya pada orang gemuk atau wanita hamil makan atau minum terlalu banyak pengaruh hormonal Kondisi perut kembung ini seharusnya dievaluasi lebi...   \n","21093                                                                                                                                  Febra yang baik,Nyeri dada kanan setelah bangun tidur dapat disebabkan beberapa hal, yaitu   GERD: naiknya asam lambung ke kerongkongan   peradangan pada tulang rusuk   cedera otot   ansietas/cemas   trauma pada dada, robekan otot/robekan pada ligamen   gangguan jantung   batu/ infeksi kandung empedu Anda sebaiknya memeriksakan diri ke dokter jika:   Nyeri terus meningkat dan tidak tertahankan   Dada terasa terhimpit atau seperti direas   Sesak napas   Penurunan denyut nadi   Mual, muntah, keringat dingin Tips dari saya:   Anda dapat mencoba memijat ringan bagian dada dan punggung yang nyeri dan memberikan krim analgesik/antinyeri   memberikan kompres pada bagian yang nyeri   lakukan peregangan otot dan olahraga untuk fleksibilitas   istirahat cukup   makan dan minum teratur dan sehat Demikian jawaban dari saya semoga dapat membantu.Salam,dr. Regina Ivanovna    \n","15997  Pinarti yang baik, kista merupakan tumor jinak yang berupa sebuah kantung berisikan cairan. Bila terinfeksi kista akan membentuk sebuah abses dimana cairan di dalamnya berupa nanah. Kista sebenarnya bisa terjadi pada bagian tubuh manapun. Namun pada perempuan secara khusus kista bisa ditemukan pada alat reproduksi yang biasanya berlokasi di ovarium. Kista pada ovarium ini bisa menimbulkan nyeri jika terplintir atau yang disebut dengan torsio kista. Namun demikian, kista juga sering menimbulkan keluhan gangguan menstruasi karena keberadaan kista, mempengaruhi maupun dipengaruhi oleh hormon reproduksi. Kista lebih rentan ditemukan pada mereka yang sering mengonsumsi makanan instan, makanan berpengawet, mereka dengan stress psikis, maupun mereka dengan riwayat kista pada keluarganya. Untuk memastikan keberadaan kista maka diperlukan pemeriksaan penunjang setidaknya menggunakan USG. Oleh karenanya kami menyarankan Anda untuk memeriksakan USG pada saat kunjungan Anda ke dokter kandungan...   \n","9834   Marsella yang baik, gatal-gatal terjadi oleh karena kadar histamin yang beredar dalam darah cukup tinggi. Histamin sendiri merupakan molekul senyawa yang dibentuk dari pecahan sel darah putih yang timbul apabila tubuh terpapar alergen. Dengan demikian keberadaan histamin mengindikasikan adanya suatu proses alergi. Histamin juga dapat menyebabkan rasa sesak di dada karena ada pembengkakan saluran napas, tak jarang kondisi ini juga disertai rasa pusing dan sakit kepala. Sementara nyeri perut yang Anda rasakan bisa berasal dari masalah pada lambung seperti sakit maag, maupun dari usus. Radang usus buntu dapat menyebabkan nyeri pada perut kanan bawah, namun ada pula beberapa kondisi lain yang dapat menimbulkan nyeri serupa seperti kista ovarium yang terplintir atau infeksi/batu pada sistem kemih. FAM sendiri merupakan kependekan dari Fibroadenomamammae yang merupakan tumor jinak payudara yang disinyalir dapat membentuk benjolan ketika kelenjar susu diproduksi terlalu aktif. Sedikit ban...   \n","19162  Bluemermaid yang baik, tenggorokan adalah saluran yang menghubungkan antara rongga mulut, tempat masuknya makanan dan minuman, ke dalam organ cerna seperti lambung dan akhirnya menuju ke usus untuk dilakukan penyerapan. Apabila ada masalah pada daerah tenggorokan, tentunya proses makan dan minum ini akan mengalami masalah. Pada kasus Anda dimana ada rasa mengganjal pada proses makan dan minum, maka penyebab yang mungkin dapat meliputi : GERD atau naiknya asam lambung ke tenggorokan infeksi tenggorokan  adanya abses atau kumpulan nanah pada tenggorokan adanya tumor pada daerah tenggorokan iritasi tenggorokan karena mengonsumsi bahan iritan (pada kasus percobaan bunuh diri) gangguan saraf menelan karena stroke atau tumor Penyebab paling sering rasa tidak nyaman di tenggorokan biasanya oleh karena asam lambung yang naik ke tenggorokan. Kondisi ini bisa dikurangi dengan menjalani gaya hidup ramah lambung dengan menghindari sementara makanan pedas bersantan dan minuman berkafein, serta ...   \n","15173  Gusryandi yang baik, ada banyak faktor yang bisa menyebabkan sakit perut, dan oleh karenanya sakit perut sendiri bermacam jenisnya. Pada wanita tentu kondisi ini menjadi lebih kompleks karena adanya organ-organ reproduksi yang bisa juga menimbulkan nyeri apabila bermasalah. Adapun beberapa faktor yang dapat menyebabkan nyeri perut hingga ke pinggang dapat meliputi : batu ataupun infeksi pada sistem kemih dan ginjal masalah pada sistem empedu infeksi saluran cerna radang pada usus kista ovarium yang terplintir (pada perempuan) adanya keram pada otot sekitar perut dan pinggang Nyeri yang bisa diredakan dengan gerakan meregang umumnya disebabkan oleh masalah pada struktur penunjang daerah yang nyeri, seperti otot, tulang dan sendi. Otot yang tegang karena kesalahan posisi/postur dalam waktu yang cukup lama dapat menimbulkan nyeri pula. Untuk sementara Anda bisa mencoba menggunakan air hangat ketika mandi untuk membantu merilekskan otot. Nyeri juga bisa dikurangi dengan penahan nyeri y...   \n","6343   Laely yang baik, nyeri perut di bagian tengah atas atau daerah ulu hati bisa disebabkan oleh banyak hal. Bahkan pada kelompok usia tertentu, kondisi ini patut dicurigai sebagai serangan jantung. Pada dasarnya nyeri perut bagian tengah atas ini bisa disebabkan oleh beberapa faktor seperti : sakit maag atau GERD atau asam lambung yang naik ke tenggorokan pankreatitis atau radang pankreas nyeri oleh karena infeksi maupun batu pada sistem liver/empedu irritable bowel syndrome  yakni kumpulan keluhan tidak nyaman pada daerah perut baik mual, nyeri, rasa penuh, disertai juga dengan gangguan buang air besar seperti konstipasi atau mencret Ada kemungkinan rasa nyeri ulu hati yang diikuti rasa tidak nyaman di tenggorokan, disebabkan oleh naiknya asam lambung dan mengiritasi daerah tenggorokan sehingga menimbulkan rasa mengganjal. Cobalah untuk menjalani gaya hidup yang ramah bagi lambung dengan menghindari makanan pedas, bersantan, serta minuman berkafein. Usahakan untuk tidak langsung berb...   \n","10710  Aldi yang baik, mual disebabkan adanya masalah pada sistem pencernaan, atau pada pusat mual di otak. Mual sendiri dapat diikuti muntah atau tidak. Beberapa penyebab mual yang sering ditemui ialah : gangguan lambung tumor otak yang berkaitan pada pusat muntah kondisi kehamilan (pada wanita) vertigo masalah metabolisme seperti pada penyakit diabetes efek samping pengobatan tertentu misalnya kemoterapi infeksi bakteri maupun virus Mual utamanya diatasi dengan menciptakan suasana yang tidak menimbulkan muntah seperti menjaga aroma ruangan pasien tidak merangsang muntah. Minuman jahe, wewangian yang aromanya ringan umumnya dapat membantu mengurangi rasa mual. Bila mual disebabkan oleh masalah lambung, cobalah untuk tidak mengonsumsi segala hal yang memicu iritasi lambung seperti makanan pedas, bersantan atau minuman berkafein, serta menjaga stres psikis dan menghilangkan kebiasaan terlambat makan. Selanjutnya jika keluhan masih berlanjut, jangan ragu memeriksakan diri ke dokter. Berikut...   \n","19306  Ika yang baik, rasa mengganjal pada tenggorokan memang sangat mungkin disebabkan oleh menumpuknya dahak. Namun demikian selalu ada kemungkinan penyebab rasa tidak nyaman di tenggorokan. Adapun beberapa kondisi yang menyebabkan seseorang merasakan rasa mengganjal di tenggorokan meliputi : penumpukan dahak di tenggorokan asam lambung yang naik ke tenggorokan atau yang dikenal dengan istilah GERD adanya abses atau kumpulan nanah pada daerah sekitar tenggorokan pembesaran amandel tumor pada daerah tenggorokan Kebanyakan penyebab rasa mengganjal selain dahak ialah asam lambung yang naik hingga ke tenggorokan. Kondisi ini bisa diatasi dengan pola makan yang ramah lambung seperti menghindari makanan pedas dan bersantan, minuman berkafein seperti kopi, memperbaiki pola makan tidak teratur, manajemen stres psikis dan menghindari konsumsi jamu-jamuan atau obat-obatan nyeri tanpa indikasi dokter. Pasca makan, usahakan untuk tidak berbaring setidaknya hingga 2 jam untuk mencegah naiknya asam l...   \n","1588   Desi yang baik, tinja yang bercampur darah secara medis dikenal dengan hematokezia. Kondisi perdarahan saat buang air besar ini memang paling sering disebabkan oleh wasir. Namun penting juga untuk mempertimbangkan kondisi yang lain yang juga memiliki gejala serupa yakni BAB berdarah. Beberapa kondisi tersebut antara lain : infeksi saluran cerna seperti disentri inflammatory bowel disorder  yakni peradangan kronik pada saluran cerna oleh karena proses alergi makanan atau semacamnya perlukaan pada saluran cerna kanker usus polip usus Untuk membuktikan asal perdarahan, maka penting untuk dilakukan pengamatan langsung oleh dokter bedah untuk kemudian ditentukan perlu tidaknya menjalani prosedur pemeriksaan penunjang seperti kolonoskopi, CT Scan, atau lainnya. Cobalah untuk mengonsumsi makanan mengandung serat seperti buah dan sayuran, dan konsumsilah cukup cairan agar kotoran menjadi lunak. Lebih jauh mengenai kondisi ini berikut kami lampirkan artikel luar mengenai  darah pada feses ....   \n","19203  Daniel yang baik, sakit lambung dan sakit haid adalah 2 kondisi yang berbeda karena kedua kondisi ini berbicara mengenai 2 organ dari 2 sistem yang berbeda pula. Sangat kecil kemungkinan masalah dari organ lambung yang berada pada sistem pencernaan, menyebabkan nyeri haid yang notabene merupakan masalah pada sistem reproduksi. Nyeri saat sedang haid sendiri secara medis diistilahkan dengan dismenore. Dismenore terbagi menjadi dismenore primer dan sekunder, dimana dismenore primer merujuk pada nyeri haid ringan yang terjadi sebagai bagian dari proses peluruhan dinding rahim yang menebal selama masa ovulasi. Sementara dismenore sekunder, lebih mengacu pada kondisi abnormal pada sistem reproduksi yang bisa meliputi : endometriosis dimana terdapat jaringan rahim di luar struktur rahim penyakit radang panggul stenosis serviks atau penyempitan leher rahim adanya tumor rahim pemakaian kontrasepsi IUD Nyeri haid yang ringan umumnya efektif diatasi dengan analgesik yang dijual bebas seperti...   \n","6511   Ayu yang baik, sesak seringkali diasosiasikan pada masalah di sistem pernapasan. Namun demikian kondisi rasa tidak nyaman di dada maupun sekitar ulu hati, juga bisa disebabkan oleh masalah pada sistem lain. Adapun beberapa kondisi yang dapat menyebabkan rasa tidak nyaman di ulu hati dan sekitar dada, dapat meliputi : sakit maag atau GERD yakni asam lambung yang naik mengiritasi tenggorokan serangan jantung pneumonia atau infeksi paru asma ataupun PPOK pada perokok masalah pada sistem empedu seperti batu maupun infeksi kegemukan dapat mula menyebabkan masalah bernapas Sesak dapat menjadi tanda dari beragam kondisi. Tekanan darah yang tinggi bisa timbul pula akibat rasa sesak. Namun demikian sesak pun bisa ditimbulkan sebagai komplikasi tekanan darah tinggi misalnya pada penyakit jantung. Oleh karenanya kami menganjurkan Anda untuk memeriksakannya secara langsung pada dokter karena sesak sendiri dapat menjadi kegawatdaruratan apabila penanganannya tidak maksimal. Berikut kami lampirk...   \n","16122  Putrii yang baik, buang air besar sewajarnya terjadi minimal 3 kali dalam 1 minggu. Jika buang air besar terjadi setiap hari, hal itu masih termasuk dalam taraf normal, namun jika seseorang mengalami buang air besar kurang dari 3 kali dalam 1 minggu, maka seseorang dikatakan mengalami konstipasi atau sembelit. Kondisi ini bisa disebabkan oleh kurangnya serat dalam asupan, serta kurang minum cairan, atau bisa juga didasari oleh penyaki tertentu seperti penyakit tiroid. Namun bagi Anda yang mengalami buang air besar setiap hari sekali, dengan konsistensi kotoran yang tidak keras maupun tidak cair, hal ini tidak menjadi masalah. Seseorang bisa mengalami buang air besar ketika ususnya berkontraksi dan dipengaruhi oleh saraf parasimpatis. Saraf ini menjadi lebih dominan ketika seseorang dalam kondisi istirahat atau pasca makan. Sehingga tidak mengherankan bahwa pasca makan, seseorang bisa berkeinginan untuk buang air besar. Bila Anda masih ragu, Anda dapat memeriksakan diri Anda ke dokt...   \n","6844   Aissah yang baik, nyeri ulu hati terutama pada lansia haruslah menjadi perhatian penting. Karena beberapa penyakit yang mengkhawatirkan memiliki gejala yang menyerupai sakit maag yakni nyeri pada ulu hati. Adapun beberapa kondisi pada lansia yang dapat ditandai dengan nyeri ulu hati, meliputi : sakit maag, hingga perlukaan pada lambung atau tukak lambung serangan jantung pankreatitis akut yakni radang pankreas pleuritis atau radang selaput pembungkus paru batu pada saluran empedu kanker lambung irritable bowel syndrome  atau sindrom iritasi usus yang bisa disebabkan oleh masalah psikis Meskipun sebagian besar nyeri ulu hati merupakan pertanda meradangnya lambung oleh iritasi asam lambung, penting untuk terlebih dahulu disingkirkan kemungkinan penyakit jantung yang gejala menyerupai sakit maag. Kemungkinan ini disingkirkan dengan pemeriksaan EKG yang diharapkan normal. Bila ternyata memang disebabkan oleh masalah pada lambung maka ada beberapa poin penting untuk diperhatikan yakni :...   \n","9691   Putri yang baik, daerah perut merupakan bagian yang kompleks karena terisi oleh beragam organ. Adapun terdapat beberapa bagian dari perut yang persarafannya menjadi satu dengan daerah punggung sehingga nyeri yang dirasakan pada beberapa penyakit bisa dirasakan hingga tembus ke punggung belakang. Adapun kondisi seperti ini bisa ditimbulkan oleh : sakit maag atau GERD yakni iritasi asam lambung pada dinding lambung hingga ke tenggorokan infeksi maupun batu pada sistem empedu infeksi pada sistem liver peradangan pada pankreas irritable bowel syndrome  yakni sekumpulan gejala tidak nyaman pada saluran cerna yang berupa mual muntah hingga perubahan pola buang air besar disebabkan kondisi psikis infeksi maupun batu pada sistem ginjal Nyeri biasanya memang masih bisa dikurangi sebagian dengan penahan nyeri yang dijual bebas seperti  paracetamol  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Namun pada kasus Anda dimana masih belum ada perbaikan, Anda berhak untuk mencari  sec...   \n","16132  Hanna yang baik, sakit perut merupakan salah satu keluhan paling umum ditemui banyak orang sehari-hari. Ada banyak sekali faktor yang bisa ikut menyebabkan sakit perut oleh karena besarnya rongga perut dan terisi oleh beragam organ yang jika bermasalah tentu dapat menimbulkan nyeri perut. Pada wanita hal ini menjadi lebih kompleks karena terdapat organ reproduksi yang mengisi sebagian besar rongga perut seorang wanita. Adapun beberapa sakit perut yang bisa timbul meliputi : radang usus buntu, secara khas biasanya dialami sakit perut kanan bawah yang menyebabkan seseorang harus membungkuk untuk mengurangi nyeri. Batuk dapat menambah nyeri, dan biasanya disertai demam sakit maag atau iritasi lambung oleh asam lambung radang usus oleh karena infeksi, baik oleh bakteri, usus, maupun parasit gejala haid endometriosis atau adanya jaringan rahim di luar struktur rahim penyakit radang panggul Nyeri untuk sementara dapat diatasi dengan pemberian obat nyeri yang sekaligus menurunkan demam ya...   \n","\n","                                      topics            topic_set  pola 1  \\\n","16618                    gangguan-pencernaan  gangguan-pencernaan       0   \n","15496                    gangguan-pencernaan  gangguan-pencernaan       0   \n","19536                           asam-lambung         asam-lambung       0   \n","19310                           asam-lambung         asam-lambung       0   \n","11504                             konstipasi           konstipasi       0   \n","20372                           asam-lambung         asam-lambung       0   \n","15612                    gangguan-pencernaan  gangguan-pencernaan       0   \n","16383                    gangguan-pencernaan  gangguan-pencernaan       0   \n","20201                           asam-lambung         asam-lambung       0   \n","17266       asam-lambung gangguan-pencernaan  gangguan-pencernaan       0   \n","18155                                  diare                diare       0   \n","14898              diare gangguan-pencernaan  gangguan-pencernaan       1   \n","611                                    wasir                wasir       0   \n","12235  keracunan-makanan gangguan-pencernaan  gangguan-pencernaan       0   \n","9261                konstipasi perut-kembung        perut-kembung       0   \n","21093                           asam-lambung         asam-lambung       1   \n","15997                    gangguan-pencernaan  gangguan-pencernaan       0   \n","9834    demam nyeri-dada gangguan-pencernaan  gangguan-pencernaan       0   \n","19162                           asam-lambung         asam-lambung       0   \n","15173                    gangguan-pencernaan  gangguan-pencernaan       0   \n","6343                              sakit-maag           sakit-maag       0   \n","10710                                   mual                 mual       0   \n","19306                           asam-lambung         asam-lambung       0   \n","1588                                   wasir                wasir       0   \n","19203                           asam-lambung         asam-lambung       0   \n","6511                              sakit-maag           sakit-maag       0   \n","16122                    gangguan-pencernaan  gangguan-pencernaan       0   \n","6844                              sakit-maag           sakit-maag       0   \n","9691      nyeri-punggung gangguan-pencernaan  gangguan-pencernaan       0   \n","16132                    gangguan-pencernaan  gangguan-pencernaan       0   \n","\n","       pola 2  \n","16618       1  \n","15496       1  \n","19536       1  \n","19310       1  \n","11504       1  \n","20372       1  \n","15612       1  \n","16383       1  \n","20201       1  \n","17266       1  \n","18155       1  \n","14898       1  \n","611         1  \n","12235       1  \n","9261        1  \n","21093       1  \n","15997       1  \n","9834        1  \n","19162       1  \n","15173       1  \n","6343        1  \n","10710       1  \n","19306       1  \n","1588        1  \n","19203       1  \n","6511        1  \n","16122       1  \n","6844        1  \n","9691        1  \n","16132       1  "],"text/html":["\n","  <div id=\"df-f4f863b0-fb2b-45ce-9c5c-289211cf4253\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>pola 1</th>\n","      <th>pola 2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>16618</th>\n","      <td>Penyebab perut bagian kiri bawah terasa nyeri</td>\n","      <td>Pagi Dok....   saya mau bertanya,,kenapa yah perut bag kiri bawah saya agak sakit ??</td>\n","      <td>Stevani yang baik, sakit perut merupakan salah satu kondisi yang sering ditemukan pada layanan primer. Sakit perut menjadi sedemikian kompleks oleh karena beragamnya organ yang menempati rongga perut yang sangat besar. Pada wanita, hal ini diperumit dengan adanya organ reproduksi yang cukup besar yakni rahim dan komponennya yang bila bermasalah, tentu menimbulkan sakit. Adapun beberapa kondisi nyeri perut pada bagian kiri bawah dapat disebabkan oleh : batu atau infeksi pada sistem ginjal batu atau infeksi pada saluran kemih usus buntu yang tidak khas dapat muncul dari kiri pankreatitis atau radang pada pankreas kista indung telur yang terplintir endometriosis atau adanya jaringan rahim diluar dinding rahim itu sendiri divertikulitis masalah pada leher rahim Adapun nyeri untuk sementara dapat diatasi dengan penahan nyeri yang dijual bebas seperti  paracetamol  atau  ibuprofen  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Perhatikan kondisi lain yang menyertai perut sep...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15496</th>\n","      <td>Sakir maag disertai muntah dan demam menggigil</td>\n","      <td>asslamualaikum dok sy muklis 26 th mau tanya dok saya sudah seminggu sakit awal nya saya magh dok muntah-muntah sampai muntah kuning dok sampai demam menggil trus sy minum obat promagh dan paracetamol dok sdh baikan tp setelahx itu bsoknya saya malah sering kepla sakit dok badan nyeri-nyeri leher tegang dan di ikuti demam dok di jam\\ tertentu..</td>\n","      <td>Muhammad yang baik, dalam mengamati satu penyakit hendaknya Anda tidak berpatokan pada satu gejala saja seperti gejala maag, oleh karena kondisi serupa dapat ditemui pada kondisi lain. Seperti misalnya petunjuk berupa rasa demam, hal ini lebih banyak mencerminkan kondisi infeksi oleh karena Indonesia yang berada pada daerah tropis, apalagi disertai gejala nyeri-nyeri sekujur tubuh yang merupakan gejala umum infeksi. Demam yang disertai dengan gejala maag biasanya mengacu pada infeksi saluran pencernaan seperti misalnya tifus, atau gejala diare. Penanganannya pun harus secara komprehensif agar pemulihan lebih efektif terjadi. Demam yang ada bisa dikurangi dengan penurun panas yang dijual bebas seperti  paracetamol  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Maag yang ada dapat dikurangi dengan gaya hidup ramah lambung seperti mengurangi asupan makanan pedas/bersantan atau minuman berkafein seperti kopi, kemudian memperbaiki pola makan tidak teratur, dan manajemen str...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19536</th>\n","      <td>Mengatasi penyakit asam lambung</td>\n","      <td>Hallo Dok..aku setiap minggu sering bgt diare, mual2 disertai muntah2, perut serasa seperti diperas2, mulut rasa nya mati rasa, tiap makan sesuatu ga berasa apa2 cuma asam dan mual, dan bagian belikat/punggung kiri atas sakit sekali seperti ada gelembungan angin menekan2 sampai saya angkat tangan kiri saja nyeri2 gitu..jujur saja, saya memang sering telat makan, krn kondisi kerja saya yg ga tentu ini, juga saya ini ngerokok tp bukan perokok besar, cuma kalo tiap plg kerja saja 2-3 batang atau kalo lg stress..dan saya pecinta kopi berat..apa lagi ice kopi..so yg ingin saya tanya kan apa sakit saya ini dok..kata orang2 itu asam lambung..kalo memang asam lambung apa ada obat yg manjur untuk mengobati sakit saya ini..dan apa yg harus saya lakukan agar tiap minggu ga sakit2 seperti ini terus dok..so bantu saya ya dok..terima kasih sebelumnya ya dok..</td>\n","      <td>Lin yang baik, masalah pada pencernaan memang dapat muncul dalam berbagai bentuk, mulai dari rasa mual, penuh di lambung, muntah-muntah, nyeri perut hingga diare. Namun dari kondisi-kondisi tersebut setidaknya dapat diperkirakan penyebab kondisi yang ada, untuk kemudian dilakukan pemeriksaan lebih lanjut untuk menentukan diagnosis serta penanganannya. Adapun diare dan sakit lambung biasanya disebabkan oleh 2 hal yang berbeda dimana diare biasanya lebih mengacu pada masalah di saluran cerna bagian bawah seperti usus besar. Namun demikian ada pula kondisi-kondisi dimana keduanya dapat muncul bersamaan. Beberapa masalah pencernaan yang memiliki gejala-gejala sebagaimana yang Anda kemukakan meliputi : infeksi saluran pencernaan sakit maag GERD atau naiknya asam lambung ke tenggorokan irritable bowel syndrome  yakni kumpulan rasa tidak nyaman di saluran cerna seperti mual, muntah, rasa penuh di lambung, yang juga disertai perubahan pola buang air besar seperti sembelit atau justru mencr...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19310</th>\n","      <td>Rasa mengganjal di tenggorokan penderita asam lambung</td>\n","      <td>Dok saya terkena sakit asam lambung. Saya sudah menjaga makananan yg dipantang. Dan saat ini hanya mengkonsumsi madu+kayu manis bubuk. Alhamdulillah dada sudah tdk sesak, tdk mual. tapi di tenggorokan msh ada yg mengganjal. Apa itu tanda akan sembuh? Dan apakah saya hrs lanjut mengkonsumsi madu atau ada obat lain dok?</td>\n","      <td>Evita yang baik, rasa mengganjal yang ada di tenggorokan bisa disebabkan oleh beberapa faktor. Pada mereka yang memiliki riwayat masalah pada lambung sebagaimana yang Anda alami, rasa mengganjal ini bisa disebabkan oleh kondisi GERD atau naiknya asam lambung ke tenggorokan dan mengiritasi dinding tenggorokan sehingga menimbulkan sensasi seperti mengganjal di tenggorokan. Namun tak menutup kemungkinan bahwa ada penyebab lain yang mendasari rasa mengganjal di tenggorokan seperti adanya penumpukan dahak pada mereka yang sedang mengalami batuk atau alergi. Selain itu pembengkakan amandel, adanya abses atau kumpulan nanah, hingga adanya tumor, bisa menjadi faktor yang menyebabkan adanya rasa mengganjal di tenggorokan. Penting untuk tetap menjalani gaya hidup ramah lambung seperti menghindari makanan pedas/bersantan, menghindari kafein seperti pada kopi, manajemen stres psikis, dan usahakan untuk tidak langsung berbaring setidaknya 2 jam pasca makan. Bila kondisi berlanjut jangan ragu me...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11504</th>\n","      <td>Bayi usia 2bulan susah bab</td>\n","      <td>Selamat sore dok. Saya ingin bertanya, anak saya umur 2bulan sudah 5hari tidak bab. Anak saya asi+sufor dok, tapi sufornya tidak sering, sehari hanya sekali kadang tidak diberi sufor. Apa kalau dikasih microlax aman dok? Sudah saya coba kasih setengah tube tapi tidak bab dok..</td>\n","      <td>Qairani yang baik, Pola buang air besar seseorang dapat menjadi indikator sederhana bagaimana kesehatan saluran cerna. Adanya masalah pada buang air besar seperti sembelit ataupun mencret mengindikasikan sebagian besar masalah pada saluran cerna. Meskipun demikian, ada pula kondisi di luar saluran cerna secara langsung, yang mempengaruhi pola buang air besar. Sembelit pada bayi yang masih berusia sangat dini, adalah hal yang cukup umum terjadi. Bayi dikatakan mengalami sembelit apabila buang air besarnya kurang dari 3 kali dalam 1 minggu. Adapun beberapa penyebab sembelit pada bayi meliputi : kurangnya asupan cairan atau dehidrasi bayi mengalami alergi terhadap susu yang dikonsumsi bayi baru mengganti makanan dengan tekstur yang lebih padat penyakit tiroid kekurangan elektrolit dalam darah Meskipun hal ini umum terjadi, tak berarti sembelit dapat disepelekan pada bayi. Untuk sementara cobalah untuk lebih banyak memberikannya cairan. Pertimbangkan kembali sufor yang dikonsumsinya. P...</td>\n","      <td>konstipasi</td>\n","      <td>konstipasi</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20372</th>\n","      <td>Mual dan muntah saat telat makan disertai jantung berdebar-debar</td>\n","      <td>Siang Dok,usia saya 31 thn,setiap hari saya mual-mual dan terkadang muntah,saya sarapan pagi jam 7,makan siang jam 12,dan makan malam jam 7 ,kalo lewat jam itu badan saya keringat dingin,gemetar,lidah pahit,jantung berdebar-debar,malam susah tidur,dan kalo tidur terbangun setiap 2 atau 3 jam dengan mual-mual dan jantung berdebar dan paling risih nya perasaan cemas dan ga enak .di pagi hari sering merasakan ngantuk saat bekerja. kira kira gejala saya apa ya dok,apakah ada hubungan nya ke penyakit jantung dok,mohon pencerahan nya.</td>\n","      <td>Rumeo yang baik, gejala yang timbul seperti keringat dingin, gemetar, berdebar-debar adalah merupakan pertanda kadar gula dalam tubuh Anda rendah sehingga tidak ada energi yang bisa dipakai untuk meneruskan aktivitas dan tubuh merespons dengan serangkaian \\alarm\\ tersebut. Rasa mual yang timbul dapat juga merupakan masalah lambung yang dapat dikurangi dengan pola hidup yang baik seperti : tidak mengkonsumsi kafein (misalnya dalam kopi) tidak mengkonsumsi makanan pedas tidak terlambat makan tidak langsung berbaring sehabis makan tidak mengkonsumsi jamu-jamuan atau obat-obatan tertentu secara rutin tanpa pemantauan dokter manajemen stres yang baik Namun demikian keluhan tersebut dapat pula merupakan manifestasi dari masalah psikis seperti gangguan cemas menyeluruh, serangan panik, maupun depresi. Umumnya masalah psikis ini diiringi dengan rangkaian masalah fisik lainnya seperti sulit tidur, rasa mual, cemas, berdebar-debar dan lain sebagainya. Masalah psikis ini timbul oleh karena ad...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15612</th>\n","      <td>Nyeri pada perut bagian tengah atas</td>\n","      <td>Dok, anak sy mengalami sakit/nyeri perut bagian tengah atas, gejalanya kesakitan, mual, dan jk sdh muntah sedikit lega, hal terjadi kambuhan, sdh beberapa kali ke dokter dan diberi analgetik (as. Mefenamat). Rasa sakit bukan melilit atau perih tp lbh spt diremas2, Jk diberi makanan akan muntah. Hal tjd sejak tahun lalu kemudian diambil tindakan appendectomy krn dr hsl rontgen dan usg terdapat cairan yg diduga ada perforasi. Sbg info anak sy usia 10th bb 49 kg. hal tsb disebabkan apa dan tindakan apa utk menanganinya jk kambuh ya dok? Tks</td>\n","      <td>Lia yang baik, nyeri pada perut kanan atas dapat mengindikasikan banyak hal karena beragamnya organ yang terdapat pada daerah tersebut. Adapun beberapa kondisi yang dicirikan dengan timbulnya pada nyeri perut bagian tengat atas atau ulu hati meliputi : sakit maag tukak lambung yakni adanya perlukaan pada lambung masalah pada liver dan sistem empedu seperti adanya batu atau peradangan pleuritis atau radang pada selaput paru pankreatitis atau radang pankreas irritable bowel syndrome  yakni kumpulan rasa tidak nyaman di perut seperti nyeri, mual, rasa penuh, yang disertai perubahan pola BAB, yang disebabkan kebanyakan oleh karena masalah psikis Karena masalah dicurigai berasal dari saluran pencernaan, cobalah untuk merubah gaya hidup menjadi lebih ramah lambung yakni menghindari konsumsi makanan pedas, bersantan, menghindari konsumsi kafein seperti pada kopi, memperbaiki pola makan yang tidak teratur, serta menghindari konsumsi jamu-jamuan atau obat-obat nyeri tanpa indikasi dari dokt...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16383</th>\n","      <td>Penyebab BAB sering tidak tuntas</td>\n","      <td>Selamat pagi, dok. Sejak saya terlalu sering mengonsumsi mie instan melebihi batas wajar waktu saja masih remaja, saya mengalami masalah pada proses buang air besar (bab) hingga saat ini. Kerapkali saya harus menghabiskan waktu hingga 30 menit bahkan 1 jam untuk proses bab, padahal normalnya proses bab dalam batas wajar biasanya 10-15 menit saja. Walaupun 30 menit, tapi tetap saja bab saya tidak bisa tuntas, bahkan waktu keluar kadang feses bercampur dengan sedikit darah merah, kadang juga disertai bau anyir darah ketika bab. Saya sudah mencoba mengatasi gangguan ini mulai dengan minum air putih, makan serat, serta mengurangi mengkonsumsi makanan berkarbohidrat \\u0026amp; minuman2 kafein, namun tetap saja tidak berhasil. Yang ingin saya tanyakan, apakah mungkin kondisi pencernaan saya (terutama usus besar) mengalami gangguan serius?Lalu bagaimana solusinya?Mohon penjelasannya, dok.</td>\n","      <td>Fahmi yang baik, hambatan pada buang air besar merupakan kondisi yang cukup mengganggu aktivitas sehari-hari karena rasa ingin buang air besar biasanya cukup mengganggu konsentrasi. Adapun mereka yang buang air besarnya tidak lancar biasanya bisa disebabkan oleh karena kondisi fesesnya yang kurang baik dan hal ini tentu berkaitan pula dengan kondisi saluran cernanya. Adanya darah pada saluran cerna juga ikut mengkontribusikan kemungkinan serius yang terjadi pada Anda. Beberapa kondisi yang dapat mendasari gejala ini meliputi : kurangnya asupan serat sehari-hari kurangnya cairan infeksi saluran cerna irritable bowel syndrome  yakni kondisi gangguan saluran cerna yang ditandai dengan kumpulan rasa kurang nyaman di perut yang disertai perubahan pola buang air besar dan berkaitan dengan kondisi psikis kanker usus besar polip rekti wasir atau ambeien Langkah pertama pada kasus Anda tentunya dengan memperbaiki pola makan sehari-hari. Konsumsilah lebih banyak sayur dan buah-buahan dan jan...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20201</th>\n","      <td>mulut pahit disertai sakit kepala</td>\n","      <td>Sore dok,,,   saya mau tanya, mulut berasa pahit dan kepala juga sakit.   kenapa ya dan ada penyakit apa ?   Terimakasih.</td>\n","      <td>Johana yang baik, mulut yang pahit dapat disebabkan oleh berbagai macam sebab. Kondisi yang secara medis disebut dysgeusia ini dapat tampil dalam berbagai variasi yakni mulut yang terasa masam, pahit, atau terasa seperti mengecap logam. Beberapa kondisi yang dapat menyebabkan gangguan rasa mengecap pada mulut, meliputi : asam lambung yang naik ke kerongkongan efek samping kemoterapi pengaruh pengobatan tertentu seperti kemoterapi akumulasi bakteri akibat kurang menjaga higiene gigi infeksi Kondisi yang kurang menyehatkan seperti kelelahan cenderung dapat menimbulkan infeksi ringan yang mengakibatkan timbulnya rangkaian gejala seperti mulut pahit dan nyeri kepala. Nyeri kepala dapat diatasi sementara dengan penahan nyeri yang dijual bebas seperti  paracetamol  atau  ibuprofen  tentunya dengan memperhatikan petunjuk pemakaian yang berlaku. Mulut yang pahit bisa dikurangi dengan menggosok gigi dan berkumur dengan antiseptik atau larutan garam. Bila keluhan memburuk jangan ragu memerik...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>17266</th>\n","      <td>Perut tidak nyaman, mual dan tenggorokan mengganjal</td>\n","      <td>Sore Dok, saya reni. Sebelumnya Maaf dok, saya ingin bertanya mengenai perut atas sebelah kiri terasa tidak enak, sering terasa mual, apa lagi jika di pakai untuk sering bergerak rasanya mau muntah. Tenggorokan juga terasa ada yang mengganjal. Leher, kepala, hingga mata sebelah kiri juga terasa tidak nyaman, rasanya pusing, apalagi jika terkena cahaya atau mendengar suara keras. Kurang lebih seperti itu yang saya rasakan. Jadi bagaimana dok? Obat apa yang sebaiknya saya gunakan? Terima kasih.</td>\n","      <td>Reni yang baik, gejala perut yang terasa tidak nyaman seperti mual, nyeri, atau serasa muntah, merupakan tanda bahwa terjadi gangguan pada saluran cerna. Gangguan dapat terjadi pada saluran cerna atas maupun bawah. Beberapa kemungkinan penyebabnya meliputi : dispepsia penyakit asam lambung yang naik irritable bowel syndrome masalah pada empedu seperti radang maupun batu empedu Tenggorokan yang terasa tidak nyaman dapat disebabkan oleh pengaruh asam lambung yang naik dan mengiritasi dinding tenggorokan. Beberapa kemungkinan lain seperti gejala radang tenggorokan juga dapat menyebabkan gejala yang serupa. Dan oleh karena kondisi tubuh yang kurang optimal, umumnya gejala lain sering mengikuti seperti nyeri kepala, rasa kurang nyaman pada mata. Pada dasarnya penanganan ditujukan pada penyebab munculnya keluhan utama. Oleh karenanya perlu dilakukan serangkaian pemeriksaan lengkap seperti USG, pemeriksaan darah lengkap, dan rontgen, bila penanganan awal masih belum menunjukkan hasil. Pen...</td>\n","      <td>asam-lambung gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18155</th>\n","      <td>Penyebab anak BAB terus menerus</td>\n","      <td>Malam dok saya mau bertanya, anak saya usia 20 bulan masih ASI. Cuman saya heran kok udah beberapa bab terus, tapi badannya gak demam. Banyak yang bilang kalau saya hamil. Apakah benar dok?  Terimakasih</td>\n","      <td>Joan yang baik, kami mengasumsikan bahwa yang memiliki permasalahan disini ialah Anda, bukan bayi Anda. Mengenai kehamilan seseorang, umumnya wanita selama masa nifas sulit sekali untuk mengalami kehamilan karena tingginya kadar prolaktin yang menghambat produksi hormon yang berfungsi untuk memicu keluarnya sel telur untuk kemudian dibuahi. Masa nifas sendiri sebetulnya hanya berlangsung selama 40 hari pasca melahirkan. Namun demikian setelah masa nifas, kadar prolaktin tidak langsung menurun melainkan tetap tinggi karena merangsang produksi air susu ibu untuk bayi. Kadar yang tetap tinggi inilah yang membuat kehamilan sulit terjadi. Melalui prinsip inilah ditemukan salah satu metode KB alamiah yakni Metode Amenore Laktasi, dimana seorang ibu harus tetap menyusui bayinya sehingga kadar prolaktin tetap tinggi dan mencegah terjadinya kehamilan karena sel telur yang tidak diproduksi. Mengenai BAB terus menerus, terdapat variasi terjadi atau tidak terjadinya demam. Cobalah untuk mengko...</td>\n","      <td>diare</td>\n","      <td>diare</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14898</th>\n","      <td>Penyebab perut terasa nyeri setelah sahur disertai BAB cair</td>\n","      <td>dok kenapa ya saya sakit perut dan terasa nyeri setelah sahur pertama? saya sahur memakan telur dan mie goreng. lalu setelah shubuh perut terasa nyeri seperti tanda2 mencret, lalu pas siang badan saya lemas gaenak badan, pas buka puasa pun saya tidak napsu makan sehingga pas isya saya baru keluar mencret dan muntah. sampai skrg perut saya terasa nyeri:'( bagaimana dok, terimakasih</td>\n","      <td>Halo Herawati yang baik,  Perubahan konsistensi tinja menjadi lunak hingga cair yang disertai dengan peningkatan frekuensi buang air besar (3 kali atau lebih dalam sehari) merupakan gejala umum  diare . Tidak jarang diare juga disertai keluhan : nyeri perut mual hingga muntah penurunan nafsu makan demam Sebagian besar diare akut disebabkan oleh konsumsi makanan/minuman yang terkontaminasi bakteri ataupun virus. Biasanya pemulihan berlangsung selama 2-4 hari. Namun bila Anda merasa sangat terganggu dengan kondisi ini, segeralah berkonsultasi secara langsung ke dokter. Penanganan yang bisa Anda lakukan selama di rumah : cukupi kebutuhan cairan tubuh dengan perbanyak minum air, setidaknya 2- 3 liter per hari hindari konsumsi makanan yang terlalu pedas, asam, dan juga berminyak, bila memungkinkan, makanlah makanan lunak seperti bubur konsumsi obat antidiare yang dijual bebas, seperti yang mengandung attapulgit bila terasa nyeri atau demam, Anda bisa mengonsumsi paracetamol untuk mereda...</td>\n","      <td>diare gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>611</th>\n","      <td>Benjolan di sekitar anus</td>\n","      <td>Dok.. tahun 2016 kemarin saya ada keluhan, ada benjolan disekitar anus, kalau saya bab juga terkadang mengeluarkan darah segar, setelah saya browsing, ternyata itu wasir/ambeien. wasir kan pantangannya makanan pedas, sedangkan saya suka banget sama makanan pedas. Saya agak bandel tuh dok. Januari 2017 akhirnya saya periksa. Cuma dikasih obat merah gitu yang dimasukin lewat anus. Benjolannya udah masuk lagi. Nah, bulan mei kemarin, selama seminggu berturut2 saya makan pedes terus dok.. waktu saya selesai bab, benjolan keluar lagi dok, kalau sebelumnya benjolan itu masih sedikit empuk. Kemarin itu benjolannya keras banget dok, kenapa ya dok??? Terus saya kasih deh rumput gandum, hasilnya mendingan. Tapi setelah kejadian benjolan keras itu dok, di kerutan anus bagian dalam itu, ada muncul benjolan lagi dok, kalau saya raba sih bentuknya panjang, tajam, kecil gitu dok, gatal banget juga dok. jadinya di anus saya kayak ada 2 benjolan gitu dok. Itu benjolan apa ya dok?? Bahaya kah??. Sol...</td>\n","      <td>Ratu yang baik, benjolan pada anus memang paling sering disebabkan oleh wasir. Wasir atau ambeien yang secara medis dikenal dengan istilah  hemorrhoid , terjadi oleh karena pembesaran pembuluh darah sekitar anus yang bisa disebabkan oleh karena kebiasaan mengedan, mengangkat beban berat, atau duduk terlalu lama. Pembuluh darah ini kadang terluka ketika dilalui oleh feses yang keras sehingga keluar darah ketika buang air besar.  Pada tahap tertentu, benjolan masih dapat dimasukkan dengan tangan, namun benjolan juga sering tidak bisa lagi dimasukkan ke dalam tangan ketika kondisi lanjut. Selain wasir, benjolan pada anus juga bisa disebabkan oleh : abses perianal yakni adanya kumpulan nanah disekitar anus kutil anus kanker anus polip recti prolaps recti yakni turunnya bagian akhir dari usus besar Penanganan benjolan tentu bergantung pada jenis benjolannya. Ada yang memerlukan tindakan pembedahan untuk bisa mengangkat benjolan tersebut. Oleh karenanya penting bagi Anda untuk terlebih d...</td>\n","      <td>wasir</td>\n","      <td>wasir</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>12235</th>\n","      <td>Sakit perut disertai buang air besar cair</td>\n","      <td>ass dok.....   saya mau tanya dok.kenapa sakit perut saya hilang timbul dan selalu ke wc,,,,,,terkadang sehat total terkadang tiba2 saja kambuh lagi,,,,,apa ada penyakit yang seriuss,mohon petunjuknya dok</td>\n","      <td>Tarmizi yang baik, mencret atau buang air besar cair merupakan kondisi berubahnya konsistensi kotoran yang seharusnya padat menjadi cair dan kadang bisa disertai dengan peningkatan frekuensi. Sakit perut yang disertai dengan mencret sejatinya mengindikasikan adanya masalah pada sistem pencernaan yang bisa disebabkan oleh beragam faktor. Adapun beberapa penyakit yang memang dicirikan dengan sakit perut disertai dengan mencret meliputi : infeksi saluran pencernaan oleh virus, bakteri, atau parasit keracunan makanan alergi terhadap kandungan makanan tertentu efek samping pengobatan irritable bowel syndrome  yakni kumpulan gejala tidak nyaman di perut yang disertai perubahan pola buang air besar Yang terpenting pada buang air besar cair ialah mengganti cairan yang keluar dengan larutan elektrolit untuk mencegah komplikasi dehidrasi. Beberapa kasus juaga memperoleh pemulihan yang lebih singkat dengan mengonsumsi probiotik. Namun demikian jika kondisi tak kunjung membaik jangan ragu meme...</td>\n","      <td>keracunan-makanan gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9261</th>\n","      <td>Masalah perut kembung dan susah BAB</td>\n","      <td>Selamat siang dok, saya mau tanya, sejak 3 hari yang lalu perut saya di bagian tengah pelan\\ merasa bergas / kembung disertai dengan masalah kesulitan membuang air besar. Selama 3 hari ini saya merasa mual dan ingin muntah apa mungkin dikarenakan gas di perut dok?  Satu hari yang lalu, saya mencoba mengonsumsi obat pencahar dan hasilnya saya lancar BAB namun bentuknya menjadi cair dan gas di perut saya hanya keluar sedikit, tidak ada perkembangan yang lebih.  Apa yang harus saya lakukan dan makanan apa yang harus dihindari dok?  Terima kasih alodokter</td>\n","      <td>Michael Lim yang baik, rasa kembung pada perut biasanya disebabkan oleh tumpukan gas dalam rongga pencernaan yang berakumulasi oleh karena satu dan lain hal. Kondisi kembung ini kadang bisa disertai dengan gejala lainnya seperti nyeri ulu hati, gangguan buang air besar, dan lain sebagainya. Kondisi saluran cerna yang baik harusnya terjadi pasase atau pergerakan usus yang baik untuk menghantarkan makanan dan udara, untuk kemudian diproses dan sisanya dibuang melalui lubang pembuangan. Beberapa kondisi yang dapat menimbulkan kembung, dapat berupa : gangguan lambung atau sakit maag dimana pada kondisi ini, perut didominasi oleh rasa nyeri ulu hati, kembung, dan mual gangguan pergerakan usus, misalnya pada ileus karena ada sumbatan pada usus, atau karena pergerakan usus yang melambat karena kekurangan elektrolit gangguan pengosongan lambung, misalnya pada orang gemuk atau wanita hamil makan atau minum terlalu banyak pengaruh hormonal Kondisi perut kembung ini seharusnya dievaluasi lebi...</td>\n","      <td>konstipasi perut-kembung</td>\n","      <td>perut-kembung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21093</th>\n","      <td>sakit di bagian dada dan punggung sebelah kanan</td>\n","      <td>assalam dok, saya mau tanya.. kenapa ya dok, tiap bangun tidur dada terasa berat, dada sebelah kanan selalu terasa nyeri dan punggung bagian kanan juga sering sakit, mohon penjelasannya dok, terimakasih :)</td>\n","      <td>Febra yang baik,Nyeri dada kanan setelah bangun tidur dapat disebabkan beberapa hal, yaitu   GERD: naiknya asam lambung ke kerongkongan   peradangan pada tulang rusuk   cedera otot   ansietas/cemas   trauma pada dada, robekan otot/robekan pada ligamen   gangguan jantung   batu/ infeksi kandung empedu Anda sebaiknya memeriksakan diri ke dokter jika:   Nyeri terus meningkat dan tidak tertahankan   Dada terasa terhimpit atau seperti direas   Sesak napas   Penurunan denyut nadi   Mual, muntah, keringat dingin Tips dari saya:   Anda dapat mencoba memijat ringan bagian dada dan punggung yang nyeri dan memberikan krim analgesik/antinyeri   memberikan kompres pada bagian yang nyeri   lakukan peregangan otot dan olahraga untuk fleksibilitas   istirahat cukup   makan dan minum teratur dan sehat Demikian jawaban dari saya semoga dapat membantu.Salam,dr. Regina Ivanovna</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15997</th>\n","      <td>Penyebab adanya kista pada perut</td>\n","      <td>Sudah satu tahun setengah saya di bilangi dokter katanya ada penyakit kista jinak tapi perut saya nggak sakit cuma kadang antara tiap setengah bulan trasa kedutan sekali saja tapi nggak sakit apa benar saya punya penyakit kista jinak apa nggak?</td>\n","      <td>Pinarti yang baik, kista merupakan tumor jinak yang berupa sebuah kantung berisikan cairan. Bila terinfeksi kista akan membentuk sebuah abses dimana cairan di dalamnya berupa nanah. Kista sebenarnya bisa terjadi pada bagian tubuh manapun. Namun pada perempuan secara khusus kista bisa ditemukan pada alat reproduksi yang biasanya berlokasi di ovarium. Kista pada ovarium ini bisa menimbulkan nyeri jika terplintir atau yang disebut dengan torsio kista. Namun demikian, kista juga sering menimbulkan keluhan gangguan menstruasi karena keberadaan kista, mempengaruhi maupun dipengaruhi oleh hormon reproduksi. Kista lebih rentan ditemukan pada mereka yang sering mengonsumsi makanan instan, makanan berpengawet, mereka dengan stress psikis, maupun mereka dengan riwayat kista pada keluarganya. Untuk memastikan keberadaan kista maka diperlukan pemeriksaan penunjang setidaknya menggunakan USG. Oleh karenanya kami menyarankan Anda untuk memeriksakan USG pada saat kunjungan Anda ke dokter kandungan...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9834</th>\n","      <td>Sakit di bawah pusar sisi kanan dan demam</td>\n","      <td>Assallammualaikum wr wb, Selamat siang dok, saya mahasiswi umur 22 thn selama 4 hari menjelang malam saya trus demam donk. Wajah saya bentol2, kuping gatel tpi agak sakit dan wajah agak membengkak. Kemudian beberpa hri ni mulai sembuh setelah berobat ke klinik keluarga ktanya alergi. Padahal sama sekali saya ga da riwayat alergi apapun . Tpi selama proses hilangnya bengkak saya, muncul rasa nyeri di dada, pusing, perut sakit sempet mual dan muntah , telinga masih sakit agak gatel, sakit di kedua sisi bahu smpai leher, dan yg pling sakit bagian bawah pusar sisi kanan. Dan satu lagi seminggu yg lalu saya menjalani operasi kecil yakni kelenjar tpi sebutan USG nya FAM. Mohon penceramahannya dok.. terima kasih . Waallaikumsalam wr wb.</td>\n","      <td>Marsella yang baik, gatal-gatal terjadi oleh karena kadar histamin yang beredar dalam darah cukup tinggi. Histamin sendiri merupakan molekul senyawa yang dibentuk dari pecahan sel darah putih yang timbul apabila tubuh terpapar alergen. Dengan demikian keberadaan histamin mengindikasikan adanya suatu proses alergi. Histamin juga dapat menyebabkan rasa sesak di dada karena ada pembengkakan saluran napas, tak jarang kondisi ini juga disertai rasa pusing dan sakit kepala. Sementara nyeri perut yang Anda rasakan bisa berasal dari masalah pada lambung seperti sakit maag, maupun dari usus. Radang usus buntu dapat menyebabkan nyeri pada perut kanan bawah, namun ada pula beberapa kondisi lain yang dapat menimbulkan nyeri serupa seperti kista ovarium yang terplintir atau infeksi/batu pada sistem kemih. FAM sendiri merupakan kependekan dari Fibroadenomamammae yang merupakan tumor jinak payudara yang disinyalir dapat membentuk benjolan ketika kelenjar susu diproduksi terlalu aktif. Sedikit ban...</td>\n","      <td>demam nyeri-dada gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19162</th>\n","      <td>seperti ada yang mengganjal di ternggorokan</td>\n","      <td>dok kenapa setiap saya suka minum air saat malam ato saat siang seperti ada gumpelan makanan yg banyak sampe susah di telan..apa karna saya makannya kurang di kunyah ato emg ada sesuatu yg menganjal di tenggorokan?</td>\n","      <td>Bluemermaid yang baik, tenggorokan adalah saluran yang menghubungkan antara rongga mulut, tempat masuknya makanan dan minuman, ke dalam organ cerna seperti lambung dan akhirnya menuju ke usus untuk dilakukan penyerapan. Apabila ada masalah pada daerah tenggorokan, tentunya proses makan dan minum ini akan mengalami masalah. Pada kasus Anda dimana ada rasa mengganjal pada proses makan dan minum, maka penyebab yang mungkin dapat meliputi : GERD atau naiknya asam lambung ke tenggorokan infeksi tenggorokan  adanya abses atau kumpulan nanah pada tenggorokan adanya tumor pada daerah tenggorokan iritasi tenggorokan karena mengonsumsi bahan iritan (pada kasus percobaan bunuh diri) gangguan saraf menelan karena stroke atau tumor Penyebab paling sering rasa tidak nyaman di tenggorokan biasanya oleh karena asam lambung yang naik ke tenggorokan. Kondisi ini bisa dikurangi dengan menjalani gaya hidup ramah lambung dengan menghindari sementara makanan pedas bersantan dan minuman berkafein, serta ...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>15173</th>\n","      <td>Sakit perut hingga ke pinggang</td>\n","      <td>Selamat siang dok, saya Mau tanya. Saya merasakan Sakit perut hingga ke pinggang. Di saat duduk Dimana pun klo mau berdiri harus di regang atau Di tarik ke belakang baru merasa enak. Kira2 ap ya dok penyakit ny dan bagaimana harus mengatasi ny, soal ny udah cukup lama juga dok. Makasih</td>\n","      <td>Gusryandi yang baik, ada banyak faktor yang bisa menyebabkan sakit perut, dan oleh karenanya sakit perut sendiri bermacam jenisnya. Pada wanita tentu kondisi ini menjadi lebih kompleks karena adanya organ-organ reproduksi yang bisa juga menimbulkan nyeri apabila bermasalah. Adapun beberapa faktor yang dapat menyebabkan nyeri perut hingga ke pinggang dapat meliputi : batu ataupun infeksi pada sistem kemih dan ginjal masalah pada sistem empedu infeksi saluran cerna radang pada usus kista ovarium yang terplintir (pada perempuan) adanya keram pada otot sekitar perut dan pinggang Nyeri yang bisa diredakan dengan gerakan meregang umumnya disebabkan oleh masalah pada struktur penunjang daerah yang nyeri, seperti otot, tulang dan sendi. Otot yang tegang karena kesalahan posisi/postur dalam waktu yang cukup lama dapat menimbulkan nyeri pula. Untuk sementara Anda bisa mencoba menggunakan air hangat ketika mandi untuk membantu merilekskan otot. Nyeri juga bisa dikurangi dengan penahan nyeri y...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6343</th>\n","      <td>Nyeri perut atas bagian tengah seperti ditusuk-tusuk</td>\n","      <td>Selamat dok, akhir-akhir ini perut saya sebelah atas tengah sering terasa nyeri seperti ditusuk, di sertai nyeri dada kadang seperti di tusuk / ditekan / panas, dan seperti ada yang mengganjal di tenggorokan, sakitnya tiba-tiba datang dan tiba-tiba hilang, kemudian akhir-akhir ini kepala saya juga sering merasa sakit seperti di tekan, kadang terasa sangat berat, kadang terasa puyeng juga, dan tiba-tiba hilang Itu kira-kira kenapa ya dok? Apa kepala pusing ada hubungannya dengan sakit fi perut ? Mohon arahannya dok, terimakasih</td>\n","      <td>Laely yang baik, nyeri perut di bagian tengah atas atau daerah ulu hati bisa disebabkan oleh banyak hal. Bahkan pada kelompok usia tertentu, kondisi ini patut dicurigai sebagai serangan jantung. Pada dasarnya nyeri perut bagian tengah atas ini bisa disebabkan oleh beberapa faktor seperti : sakit maag atau GERD atau asam lambung yang naik ke tenggorokan pankreatitis atau radang pankreas nyeri oleh karena infeksi maupun batu pada sistem liver/empedu irritable bowel syndrome  yakni kumpulan keluhan tidak nyaman pada daerah perut baik mual, nyeri, rasa penuh, disertai juga dengan gangguan buang air besar seperti konstipasi atau mencret Ada kemungkinan rasa nyeri ulu hati yang diikuti rasa tidak nyaman di tenggorokan, disebabkan oleh naiknya asam lambung dan mengiritasi daerah tenggorokan sehingga menimbulkan rasa mengganjal. Cobalah untuk menjalani gaya hidup yang ramah bagi lambung dengan menghindari makanan pedas, bersantan, serta minuman berkafein. Usahakan untuk tidak langsung berb...</td>\n","      <td>sakit-maag</td>\n","      <td>sakit-maag</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10710</th>\n","      <td>mual saat bangun tidur</td>\n","      <td>DOK SAYA MAU TANYA NIH, KENAPA YA DI SETIAP SAYA BANGUN TIDUR SUKA MUAL MUAL DAN SUKA SAKIT BAGIAN TENGAH PERUT, APAKAH MAGH KRONIS? LAMBUNG SAYA BERMASALAH?   SOLUSINYA GIMANA DOK JIKA INGIN MEMINIMALISIR/ INGIN SEMBUH   APAKAH ADA OBAT HERBAL ATAU OBAT APOTIK?   TERIMAKASIH</td>\n","      <td>Aldi yang baik, mual disebabkan adanya masalah pada sistem pencernaan, atau pada pusat mual di otak. Mual sendiri dapat diikuti muntah atau tidak. Beberapa penyebab mual yang sering ditemui ialah : gangguan lambung tumor otak yang berkaitan pada pusat muntah kondisi kehamilan (pada wanita) vertigo masalah metabolisme seperti pada penyakit diabetes efek samping pengobatan tertentu misalnya kemoterapi infeksi bakteri maupun virus Mual utamanya diatasi dengan menciptakan suasana yang tidak menimbulkan muntah seperti menjaga aroma ruangan pasien tidak merangsang muntah. Minuman jahe, wewangian yang aromanya ringan umumnya dapat membantu mengurangi rasa mual. Bila mual disebabkan oleh masalah lambung, cobalah untuk tidak mengonsumsi segala hal yang memicu iritasi lambung seperti makanan pedas, bersantan atau minuman berkafein, serta menjaga stres psikis dan menghilangkan kebiasaan terlambat makan. Selanjutnya jika keluhan masih berlanjut, jangan ragu memeriksakan diri ke dokter. Berikut...</td>\n","      <td>mual</td>\n","      <td>mual</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19306</th>\n","      <td>Tenggorokan terasa mengganjal dan sulit bernapas</td>\n","      <td>Dok, saya mau tanya. Tiga hari ini tenggorokan saya seperti ada yang mengganjal. Awalnya saya kira itu dahak yang tidak bisa keluar, tapi saya rasa itu bukan dahak karena saya jadi sedikit susah untuk bernafas. Kira kira kenapa ya dok? Terimakasih</td>\n","      <td>Ika yang baik, rasa mengganjal pada tenggorokan memang sangat mungkin disebabkan oleh menumpuknya dahak. Namun demikian selalu ada kemungkinan penyebab rasa tidak nyaman di tenggorokan. Adapun beberapa kondisi yang menyebabkan seseorang merasakan rasa mengganjal di tenggorokan meliputi : penumpukan dahak di tenggorokan asam lambung yang naik ke tenggorokan atau yang dikenal dengan istilah GERD adanya abses atau kumpulan nanah pada daerah sekitar tenggorokan pembesaran amandel tumor pada daerah tenggorokan Kebanyakan penyebab rasa mengganjal selain dahak ialah asam lambung yang naik hingga ke tenggorokan. Kondisi ini bisa diatasi dengan pola makan yang ramah lambung seperti menghindari makanan pedas dan bersantan, minuman berkafein seperti kopi, memperbaiki pola makan tidak teratur, manajemen stres psikis dan menghindari konsumsi jamu-jamuan atau obat-obatan nyeri tanpa indikasi dokter. Pasca makan, usahakan untuk tidak berbaring setidaknya hingga 2 jam untuk mencegah naiknya asam l...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1588</th>\n","      <td>Pengobatan wasir yang tepat</td>\n","      <td>Assalamualaikum malam dok Saya punya masalah bab yg tdak teratur setelah melahirnya malah setiap bab sambil mengeluarkan darah.. Umur anak saya satu tahun dok Beberapa waktu lalu sudah tidak wasir lgi tpi tdi waktu pagi saat bab tinja keras dok dan mengeluarkan darah dan sekarang muncul benjolan bagaimana cara mengobatinya dan obatnya Terima kasih sebelumnya</td>\n","      <td>Desi yang baik, tinja yang bercampur darah secara medis dikenal dengan hematokezia. Kondisi perdarahan saat buang air besar ini memang paling sering disebabkan oleh wasir. Namun penting juga untuk mempertimbangkan kondisi yang lain yang juga memiliki gejala serupa yakni BAB berdarah. Beberapa kondisi tersebut antara lain : infeksi saluran cerna seperti disentri inflammatory bowel disorder  yakni peradangan kronik pada saluran cerna oleh karena proses alergi makanan atau semacamnya perlukaan pada saluran cerna kanker usus polip usus Untuk membuktikan asal perdarahan, maka penting untuk dilakukan pengamatan langsung oleh dokter bedah untuk kemudian ditentukan perlu tidaknya menjalani prosedur pemeriksaan penunjang seperti kolonoskopi, CT Scan, atau lainnya. Cobalah untuk mengonsumsi makanan mengandung serat seperti buah dan sayuran, dan konsumsilah cukup cairan agar kotoran menjadi lunak. Lebih jauh mengenai kondisi ini berikut kami lampirkan artikel luar mengenai  darah pada feses ....</td>\n","      <td>wasir</td>\n","      <td>wasir</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19203</th>\n","      <td>hubungan antara sakit lambung dan sakit haid</td>\n","      <td>Dok, saya mau nanya dong , saya dulu haid ga pernah ngerasa sakit atau apapun dan sedikit pun malah kadang pas haid tu kaya gatau gtu gaada tanda\\ sakit atau apa\\ . Dan pada suatu hari saya terkena sakit lambung yg bisa di blg parah, krna saya sakit Tukak lambung kronis gtu dok, tp skrg kan udh ga sakit lgi tp knpa haid saya sekarang sakit sekali, kadang saat haid saya pucat, dan kaya mau pingsan krna sakit sekali, apa berpengaruh dari sakit lambung dok?</td>\n","      <td>Daniel yang baik, sakit lambung dan sakit haid adalah 2 kondisi yang berbeda karena kedua kondisi ini berbicara mengenai 2 organ dari 2 sistem yang berbeda pula. Sangat kecil kemungkinan masalah dari organ lambung yang berada pada sistem pencernaan, menyebabkan nyeri haid yang notabene merupakan masalah pada sistem reproduksi. Nyeri saat sedang haid sendiri secara medis diistilahkan dengan dismenore. Dismenore terbagi menjadi dismenore primer dan sekunder, dimana dismenore primer merujuk pada nyeri haid ringan yang terjadi sebagai bagian dari proses peluruhan dinding rahim yang menebal selama masa ovulasi. Sementara dismenore sekunder, lebih mengacu pada kondisi abnormal pada sistem reproduksi yang bisa meliputi : endometriosis dimana terdapat jaringan rahim di luar struktur rahim penyakit radang panggul stenosis serviks atau penyempitan leher rahim adanya tumor rahim pemakaian kontrasepsi IUD Nyeri haid yang ringan umumnya efektif diatasi dengan analgesik yang dijual bebas seperti...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6511</th>\n","      <td>sesak napas disertai perut kembung</td>\n","      <td>Assalamu Alaikum dok. Saya wanita brusia 25 thn. TB 150cm BB kurang lbih 60kg. Dua minggu yang lalu saya terkena hipertensi 150/100, prsaan tiba2 sesak Trus hbis mnum obat kmbali normal. Tpi akhir2 ini sesak nafas lgi trus klo brnapas skit tembus belakng. Dan sebulan ini cuma keluar flek coklat bukan haid. Klo mkan juga tidak terasa kenyang sperti tidak nyampe ke perut. Kdang mual klo uluhati terlalu sakit. kira2 ini karna pengaruh obesitas atau gmna dok??? Sblumnya saya prnah konsumsi obat cacing.</td>\n","      <td>Ayu yang baik, sesak seringkali diasosiasikan pada masalah di sistem pernapasan. Namun demikian kondisi rasa tidak nyaman di dada maupun sekitar ulu hati, juga bisa disebabkan oleh masalah pada sistem lain. Adapun beberapa kondisi yang dapat menyebabkan rasa tidak nyaman di ulu hati dan sekitar dada, dapat meliputi : sakit maag atau GERD yakni asam lambung yang naik mengiritasi tenggorokan serangan jantung pneumonia atau infeksi paru asma ataupun PPOK pada perokok masalah pada sistem empedu seperti batu maupun infeksi kegemukan dapat mula menyebabkan masalah bernapas Sesak dapat menjadi tanda dari beragam kondisi. Tekanan darah yang tinggi bisa timbul pula akibat rasa sesak. Namun demikian sesak pun bisa ditimbulkan sebagai komplikasi tekanan darah tinggi misalnya pada penyakit jantung. Oleh karenanya kami menganjurkan Anda untuk memeriksakannya secara langsung pada dokter karena sesak sendiri dapat menjadi kegawatdaruratan apabila penanganannya tidak maksimal. Berikut kami lampirk...</td>\n","      <td>sakit-maag</td>\n","      <td>sakit-maag</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16122</th>\n","      <td>Selalu buang air besar setelah sarapan, apakah normal?</td>\n","      <td>Selamat siang, Dokter.    Saya mau tanya.    Normalnya BAB seseorang adalah 3 hari. Tapi saya selalu BAB setelah sarapan dan itu terjadi setiap pagi di setiap hari.    Apakah itu juga normal?    Ataukah ada yang salah dalam perut saya?   Terima kasih.</td>\n","      <td>Putrii yang baik, buang air besar sewajarnya terjadi minimal 3 kali dalam 1 minggu. Jika buang air besar terjadi setiap hari, hal itu masih termasuk dalam taraf normal, namun jika seseorang mengalami buang air besar kurang dari 3 kali dalam 1 minggu, maka seseorang dikatakan mengalami konstipasi atau sembelit. Kondisi ini bisa disebabkan oleh kurangnya serat dalam asupan, serta kurang minum cairan, atau bisa juga didasari oleh penyaki tertentu seperti penyakit tiroid. Namun bagi Anda yang mengalami buang air besar setiap hari sekali, dengan konsistensi kotoran yang tidak keras maupun tidak cair, hal ini tidak menjadi masalah. Seseorang bisa mengalami buang air besar ketika ususnya berkontraksi dan dipengaruhi oleh saraf parasimpatis. Saraf ini menjadi lebih dominan ketika seseorang dalam kondisi istirahat atau pasca makan. Sehingga tidak mengherankan bahwa pasca makan, seseorang bisa berkeinginan untuk buang air besar. Bila Anda masih ragu, Anda dapat memeriksakan diri Anda ke dokt...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6844</th>\n","      <td>penyebab nyeri ulu hati pada lansia</td>\n","      <td>Dok saya mau tanya,nenek saya setiap hari suka merasakan nyeri pada ulu hati,itu sebabnya kenapa ya dok?</td>\n","      <td>Aissah yang baik, nyeri ulu hati terutama pada lansia haruslah menjadi perhatian penting. Karena beberapa penyakit yang mengkhawatirkan memiliki gejala yang menyerupai sakit maag yakni nyeri pada ulu hati. Adapun beberapa kondisi pada lansia yang dapat ditandai dengan nyeri ulu hati, meliputi : sakit maag, hingga perlukaan pada lambung atau tukak lambung serangan jantung pankreatitis akut yakni radang pankreas pleuritis atau radang selaput pembungkus paru batu pada saluran empedu kanker lambung irritable bowel syndrome  atau sindrom iritasi usus yang bisa disebabkan oleh masalah psikis Meskipun sebagian besar nyeri ulu hati merupakan pertanda meradangnya lambung oleh iritasi asam lambung, penting untuk terlebih dahulu disingkirkan kemungkinan penyakit jantung yang gejala menyerupai sakit maag. Kemungkinan ini disingkirkan dengan pemeriksaan EKG yang diharapkan normal. Bila ternyata memang disebabkan oleh masalah pada lambung maka ada beberapa poin penting untuk diperhatikan yakni :...</td>\n","      <td>sakit-maag</td>\n","      <td>sakit-maag</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9691</th>\n","      <td>Penyebab Sakit Pada Punggung dan Perut</td>\n","      <td>Selamat sore dok, saya ingin bertanya.    orang tua saya mengalami sakit pada perut dan punggung.. sudah masuk Rumah sakit dan dirawat selama 5 hari dengan hasil radiologi, usg dan diagnosa yang berbeda-beda. mulai dari batu ginjal sampai dengan liver selama 5 hari perawatan RS tidak ada sedikitpun perubahan bahkan semakin sakit.   saya pindahkan ke rumahsakit lain hasil diagnosanya pun berbeda yaitu dikarenakan Infeksi Paru-paru yang sudah lama diderita orang tua saya sejak 2014 sehingga menyebabkan sakit pada perut dan punggungnamun obat tersebut juga tidak ada perubahan.    bisa tolong dijelaskan dok sebetulnya apa yang mempengaruhi sakit pada perut dang punggung orang tua saya, dan apa obat yang dapat meredakan dan menghilangkan rasa sakitnya ?   Terimakasih</td>\n","      <td>Putri yang baik, daerah perut merupakan bagian yang kompleks karena terisi oleh beragam organ. Adapun terdapat beberapa bagian dari perut yang persarafannya menjadi satu dengan daerah punggung sehingga nyeri yang dirasakan pada beberapa penyakit bisa dirasakan hingga tembus ke punggung belakang. Adapun kondisi seperti ini bisa ditimbulkan oleh : sakit maag atau GERD yakni iritasi asam lambung pada dinding lambung hingga ke tenggorokan infeksi maupun batu pada sistem empedu infeksi pada sistem liver peradangan pada pankreas irritable bowel syndrome  yakni sekumpulan gejala tidak nyaman pada saluran cerna yang berupa mual muntah hingga perubahan pola buang air besar disebabkan kondisi psikis infeksi maupun batu pada sistem ginjal Nyeri biasanya memang masih bisa dikurangi sebagian dengan penahan nyeri yang dijual bebas seperti  paracetamol  tentunya dengan memperhatikan petunjuk pemakaian yang ada. Namun pada kasus Anda dimana masih belum ada perbaikan, Anda berhak untuk mencari  sec...</td>\n","      <td>nyeri-punggung gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>16132</th>\n","      <td>Penyebab sakit perut saat bergerak</td>\n","      <td>selamat mlm dok....dok.sy mw tny knp yaa perut saya terasa sakit sekali untuk bergerak sakiy, untuk jalan sakit, terus.sempat demam trus panasnya turun tp perut.msih ttp sakit pdhl sudah minum obat maagh terus klo batuk itu terasa sakit juga..</td>\n","      <td>Hanna yang baik, sakit perut merupakan salah satu keluhan paling umum ditemui banyak orang sehari-hari. Ada banyak sekali faktor yang bisa ikut menyebabkan sakit perut oleh karena besarnya rongga perut dan terisi oleh beragam organ yang jika bermasalah tentu dapat menimbulkan nyeri perut. Pada wanita hal ini menjadi lebih kompleks karena terdapat organ reproduksi yang mengisi sebagian besar rongga perut seorang wanita. Adapun beberapa sakit perut yang bisa timbul meliputi : radang usus buntu, secara khas biasanya dialami sakit perut kanan bawah yang menyebabkan seseorang harus membungkuk untuk mengurangi nyeri. Batuk dapat menambah nyeri, dan biasanya disertai demam sakit maag atau iritasi lambung oleh asam lambung radang usus oleh karena infeksi, baik oleh bakteri, usus, maupun parasit gejala haid endometriosis atau adanya jaringan rahim di luar struktur rahim penyakit radang panggul Nyeri untuk sementara dapat diatasi dengan pemberian obat nyeri yang sekaligus menurunkan demam ya...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4f863b0-fb2b-45ce-9c5c-289211cf4253')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f4f863b0-fb2b-45ce-9c5c-289211cf4253 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f4f863b0-fb2b-45ce-9c5c-289211cf4253');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-5b1a8ef3-f920-46a6-9c27-3e3bcaf45fce\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b1a8ef3-f920-46a6-9c27-3e3bcaf45fce')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-5b1a8ef3-f920-46a6-9c27-3e3bcaf45fce button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df[df['pola 2'] == 1]\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"penyebab nyeri ulu hati pada lansia\",\n          \"sakit di bagian dada dan punggung sebelah kanan\",\n          \"Pengobatan wasir yang tepat\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Dok saya mau tanya,nenek saya setiap hari suka merasakan nyeri pada ulu hati,itu sebabnya kenapa ya dok?\",\n          \"assalam dok, saya mau tanya.. kenapa ya dok, tiap bangun tidur dada terasa berat, dada sebelah kanan selalu terasa nyeri dan punggung bagian kanan juga sering sakit, mohon penjelasannya dok, terimakasih :)\",\n          \"Assalamualaikum malam dok Saya punya masalah bab yg tdak teratur setelah melahirnya malah setiap bab sambil mengeluarkan darah.. Umur anak saya satu tahun dok Beberapa waktu lalu sudah tidak wasir lgi tpi tdi waktu pagi saat bab tinja keras dok dan mengeluarkan darah dan sekarang muncul benjolan bagaimana cara mengobatinya dan obatnya Terima kasih sebelumnya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"Aissah yang baik, nyeri ulu hati terutama pada lansia haruslah menjadi perhatian penting. Karena beberapa penyakit yang mengkhawatirkan memiliki gejala yang menyerupai sakit maag yakni nyeri pada ulu hati. Adapun beberapa kondisi pada lansia yang dapat ditandai dengan nyeri ulu hati, meliputi : sakit maag, hingga perlukaan pada lambung atau tukak lambung serangan jantung pankreatitis akut yakni radang pankreas pleuritis atau radang selaput pembungkus paru batu pada saluran empedu kanker lambung irritable bowel syndrome  atau sindrom iritasi usus yang bisa disebabkan oleh masalah psikis Meskipun sebagian besar nyeri ulu hati merupakan pertanda meradangnya lambung oleh iritasi asam lambung, penting untuk terlebih dahulu disingkirkan kemungkinan penyakit jantung yang gejala menyerupai sakit maag. Kemungkinan ini disingkirkan dengan pemeriksaan EKG yang diharapkan normal. Bila ternyata memang disebabkan oleh masalah pada lambung maka ada beberapa poin penting untuk diperhatikan yakni : hentikan konsumsi makanan pedas, bersantan hentikan konsumsi minuman berkafein seperti kopi manajemen stres psikis yang baik mengubah kebiasaan pola makan telat hentikan konsumsi jamu-jamuan atau obat penahan nyeri tanpa supervisi dokter Bila kondisi nyeri ulu hati berlanjut, jangan ragu untuk memeriksakan diri ke dokter untuk mendapatkan penanganan yang baik. Berikut kami lampirkan artikel mengenai  nyeri ulu hati.  Semoga bermanfaat.   dr. N. K. Arief\",\n          \"Febra yang baik,Nyeri dada kanan setelah bangun tidur dapat disebabkan beberapa hal, yaitu   GERD: naiknya asam lambung ke kerongkongan   peradangan pada tulang rusuk   cedera otot   ansietas/cemas   trauma pada dada, robekan otot/robekan pada ligamen   gangguan jantung   batu/ infeksi kandung empedu Anda sebaiknya memeriksakan diri ke dokter jika:   Nyeri terus meningkat dan tidak tertahankan   Dada terasa terhimpit atau seperti direas   Sesak napas   Penurunan denyut nadi   Mual, muntah, keringat dingin Tips dari saya:   Anda dapat mencoba memijat ringan bagian dada dan punggung yang nyeri dan memberikan krim analgesik/antinyeri   memberikan kompres pada bagian yang nyeri   lakukan peregangan otot dan olahraga untuk fleksibilitas   istirahat cukup   makan dan minum teratur dan sehat Demikian jawaban dari saya semoga dapat membantu.Salam,dr. Regina Ivanovna \",\n          \"Desi yang baik, tinja yang bercampur darah secara medis dikenal dengan hematokezia. Kondisi perdarahan saat buang air besar ini memang paling sering disebabkan oleh wasir. Namun penting juga untuk mempertimbangkan kondisi yang lain yang juga memiliki gejala serupa yakni BAB berdarah. Beberapa kondisi tersebut antara lain : infeksi saluran cerna seperti disentri inflammatory bowel disorder  yakni peradangan kronik pada saluran cerna oleh karena proses alergi makanan atau semacamnya perlukaan pada saluran cerna kanker usus polip usus Untuk membuktikan asal perdarahan, maka penting untuk dilakukan pengamatan langsung oleh dokter bedah untuk kemudian ditentukan perlu tidaknya menjalani prosedur pemeriksaan penunjang seperti kolonoskopi, CT Scan, atau lainnya. Cobalah untuk mengonsumsi makanan mengandung serat seperti buah dan sayuran, dan konsumsilah cukup cairan agar kotoran menjadi lunak. Lebih jauh mengenai kondisi ini berikut kami lampirkan artikel luar mengenai  darah pada feses . Semoga bermanfaat.   dr. N. K. Arief\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 13,\n        \"samples\": [\n          \"mual\",\n          \"demam nyeri-dada gangguan-pencernaan\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"asam-lambung\",\n          \"perut-kembung\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":197}]},{"cell_type":"markdown","source":["### Prepocessing Membersihkan sapaan\n","Dari hasil observasi sebelumnya didaptkan pola"],"metadata":{"id":"SrAWNR3Cs7n_"}},{"cell_type":"code","source":["import re\n","import html\n","\n","def bersihkan_sapaan(teks):\n","\n","    # Decode \\u0026lt; -> <, \\u0026gt; -> >, dll\n","    teks = teks.replace('\\\\u0026lt;', '<').replace('\\\\u0026gt;', '>').replace('\\\\u0026', '&')\n","    teks = html.unescape(teks)\n","    # Hapus tag HTML beserta atribut (contoh: <span style=\"...\">)\n","    teks = re.sub(r'<[^>]+>', '', teks)\n","\n","    # 1. [Person] yang baik, contoh: \"Nita yang baik,\" \"Cindy Agustin yang baik,\"\n","    teks = re.sub(\n","        r'^\\s*([\\w.]+(?:\\s+[\\w.]+){0,3})\\s+yang\\s+baik[.,:]*\\s*', '', teks, flags=re.IGNORECASE)\n","\n","    # 2. Selamat [waktu] [Person] (dengan/atau tanpa nama)\n","    teks = re.sub(\n","        r'^\\s*Selamat\\s+(pagi|siang|malam|sore)\\s*([\\w.]+(?:\\s+[\\w.]+){0,4})?[.,:]*\\s*',\n","        '', teks, flags=re.IGNORECASE)\n","\n","    # 3. Waalaikumsalam [Person]\n","    teks = re.sub(\n","        r'^\\s*Waalaikumsalam(?:\\s+wr\\s+wb)?\\s*([\\w.]+(?:\\s+[\\w.]+){0,4})?[.,:]*\\s*',\n","        '', teks, flags=re.IGNORECASE)\n","\n","    # 4. Terima kasih [Person] atas pertanyaannya\n","    teks = re.sub(\n","        r'^\\s*Terima\\s+kasih\\s+([\\w.]+(?:\\s+[\\w.]+){0,4})\\s+atas\\s+pertanyaannya[.,:]*\\s*',\n","        '', teks, flags=re.IGNORECASE)\n","\n","    # 5. Hay [Person], terimakasih atas pertanyaannya\n","    teks = re.sub(\n","        r'^\\s*Hay\\s+([\\w.]+(?:\\s+[\\w.]+){0,4}),?\\s*terima[ -]?kasih\\s+atas\\s+pertanyaannya[.,:]*\\s*',\n","        '', teks, flags=re.IGNORECASE)\n","\n","    # 6. Sapaan umum tanpa nama: Selamat [waktu]\n","    teks = re.sub(\n","        r'^\\s*Selamat\\s+(pagi|siang|malam|sore)[.,:]*\\s*', '', teks, flags=re.IGNORECASE)\n","\n","    # 7. Variasi sapaan umum (Hai, Hallo, Halo, Helo, Hello, Alo, salam, Dear)\n","    variants = r'(Hai|Hallo|Halo|Helo|Hello|Alo|salam|Dear)'\n","    teks = re.sub(\n","        rf'^\\s*{variants}(?:\\s+\\w+){{1,3}}[.,:]*', '', teks, flags=re.IGNORECASE)\n","    teks = re.sub(\n","        rf'^\\s*{variants}[.,:]*', '', teks, flags=re.IGNORECASE)\n","\n","    # # 8. Hapus \"ke/di/pada alodokter\" atau \"alodokter\" di awal/akhir/kapan pun\n","    # teks = re.sub(r'\\balodokter\\b', '', teks, flags=re.IGNORECASE)\n","    # teks = re.sub(r'\\balodokter.com\\b', '', teks, flags=re.IGNORECASE)\n","    # teks = re.sub(r'\\balodokter\\b', '', teks, flags=re.IGNORECASE)\n","\n","    # Hapus frasa seperti \"ke alodokter\", \"di alodokter\", \"pada alodokter\", termasuk .com\n","    teks = re.sub(r'\\b(ke|di|pada)\\s+alodokter(?:\\.com)?\\b', '', teks, flags=re.IGNORECASE)\n","\n","# Hapus kata \"alodokter\" atau \"alodokter.com\" jika berdiri sendiri\n","    teks = re.sub(r'\\balodokter(?:\\.com)?\\b', '', teks, flags=re.IGNORECASE)\n","\n","\n","    # 9. Hapus \"Dr. Nama Nama\"\n","    teks = re.sub(r'\\.?dr\\.?\\s*[A-Z][a-z]+(?:\\s+[A-Z][a-z]+)?', '', teks, flags=re.IGNORECASE)\n","    teks = re.sub(r'\\bDr\\.\\s+\\w+\\s+\\w+\\b', 'Dr.', teks, flags=re.IGNORECASE)\n","    teks = re.sub(r'\\bDr\\.\\s+\\w+\\s+\\w+\\b', '', teks, flags=re.IGNORECASE)\n","\n","    # 10. Bersihkan spasi ganda dan strip spasi awal/akhir\n","    teks = re.sub(r'\\s+', ' ', teks).strip()\n","\n","    return teks\n"],"metadata":{"id":"4fpc9BXoxr9V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Contoh kasus lain"],"metadata":{"id":"_zFtkoIZ48vd"}},{"cell_type":"code","source":["\"Hallo Rehan Putra Tunggal Terimakasih atas pertanyaan anda Jadi anda harus paham, bahwa asam lambung merupakan material yang diciptakan secara alamiah oleh lambung untuk membantu proses pencernaan makanan. Jadi tidak mungkin untuk menghilangkan asam lambung ini. Mungkin yang anda maksud adalah keluhan yang muncul akibat kondisi asam lambung berlebih/peningkatan asam lambung atau bisa juga karena penyakit asam lambung (GERD). Jika yang anda maksud adalah kedua kondisi ini, maka memang bisa dilakukan penanganan sehingga kondisi ini tidak menimbulkan keluhan. Penyakit asam lambung atau Gastroesophageal Reflux Disease (GERD) yang anda alami merupakan kondisi dimana terjadi nyeri pada ulu hati atau sensasi terbakar di dada akibat naiknya asam lambung menuju esophagus (kerongkongan). Penyakit asam lambung atau GERD pada umumnya disebabkan oleh tidak berfungsinya lower esophageal sphinchter (LES) yang merupakan lingkaran otot pada bagian bawah dari esophagus (kerongkongan). LES berf...\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"FGxrxHQ8493V","outputId":"a26df84f-60d1-48db-ebe0-2920940adcc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hallo Rehan Putra Tunggal Terimakasih atas pertanyaan anda Jadi anda harus paham, bahwa asam lambung merupakan material yang diciptakan secara alamiah oleh lambung untuk membantu proses pencernaan makanan. Jadi tidak mungkin untuk menghilangkan asam lambung ini. Mungkin yang anda maksud adalah keluhan yang muncul akibat kondisi asam lambung berlebih/peningkatan asam lambung atau bisa juga karena penyakit asam lambung (GERD). Jika yang anda maksud adalah kedua kondisi ini, maka memang bisa dilakukan penanganan sehingga kondisi ini tidak menimbulkan keluhan. Penyakit asam lambung atau Gastroesophageal Reflux Disease (GERD) yang anda alami merupakan kondisi dimana terjadi nyeri pada ulu hati atau sensasi terbakar di dada akibat naiknya asam lambung menuju esophagus (kerongkongan). Penyakit asam lambung atau GERD pada umumnya disebabkan oleh tidak berfungsinya lower esophageal sphinchter (LES) yang merupakan lingkaran otot pada bagian bawah dari esophagus (kerongkongan). LES berf...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["bersihkan_sapaan(\"Terima kasih Memey SiComell Pesekz atas pertanyaannya di forum Alodokter, keadaan yang mungkin Saudari gambarkan saat ini kemungkinan disebabkan oleh keadaan perut kembung. Perut kembung sendiri merupakan gangguan pada pencernaan dimana penderita merasa perut tidak nyaman karena terasa penuh atau begah. Pada keadaan ini dapat timbul gejala berupa: - sensasi penuh, sesak, atau pembengkakan pada bagian perut - rasa nyeri dan penuh gas pada perut - rasa sakit yang muncul bisa menyebabkan kram perut - sering bersendawa - perut terasa bergejolak - buang angin berlebihan Perut kembung dapat disebabkan oleh banyak hal, diantaranya seperti: - mengonsumsi makanan yang dapat memproduksi gas - menelan udara, baik saat makan maupun ketika minum air - sembelit - merokok - makan terlalu cepat - mengalami gangguan pada sistem pencernaan Makan-makanan tertentu umumnya dianggap bertanggung jawab atas timbulnya gas pada saluran cerna, gas ini umumnya dihasilkan dari hasil pemecahan makanan oleh bakt.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"wSY57kwD1FX3","outputId":"029b0872-01b2-4e1c-f63b-f120ee35a1ce"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'di forum , keadaan yang mungkin Saudari gambarkan saat ini kemungkinan disebabkan oleh keadaan perut kembung. Perut kembung sendiri merupakan gangguan pada pencernaan dimana penderita merasa perut tidak nyaman karena terasa penuh atau begah. Pada keadaan ini dapat timbul gejala berupa: - sensasi penuh, sesak, atau pembengkakan pada bagian perut - rasa nyeri dan penuh gas pada perut - rasa sakit yang muncul bisa menyebabkan kram perut - sering bersendawa - perut terasa bergejolak - buang angin berlebihan Perut kembung dapat disebabkan oleh banyak hal, diantaranya seperti: - mengonsumsi makanan yang dapat memproduksi gas - menelan udara, baik saat makan maupun ketika minum air - sembelit - merokok - makan terlalu cepat - mengalami gangguan pada sistem pencernaan Makan-makanan tertentu umumnya dianggap bertanggung jawab atas timbulnya gas pada saluran cerna, gas ini umumnya dihasilkan dari hasil pemecahan makanan oleh bakt.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["bersihkan_sapaan('Pagi Jhunny,Terima kasih atas pertanyaannya.Keluhan berupa sakit pada perut yang dirasakan setiap makan tentunya dapat terasa mengganggu. Hal ini dapat disebabkan oleh hal berikut: Gastritis , yaitu \\u0026lt;span style=\\color: #000000; font-family: museosans300, sans-serif;\\\\u0026gt;kondisi ketika lapisan lambung mengalami iritasi, peradangan\\u0026lt;/span\\u0026gt; Penyakit Asam Lambung , yaitu kondisi ketika asam lambung naik ke kerongkongan Tukak lambung , yaitu \\u0026lt;span style=\\color: #000000; font-family: museosans300, sans-serif;\\\\u0026gt;luka yang muncul pada dinding lambung akibat terkikisnya lapisan dinding lambung. Luka ini juga berpotensi muncul pada dinding bagian pertama usus kecil (duodenum) serta kerongkongan (esofagus)\\u0026lt;/span\\u0026gt; Irritable Bowel Syndrome , yaitu gangguan pada usus besar yang dapat dipicu oleh stres atau makanan tertentu Dsbnya Alangkah baiknya untuk menelusuri penyebab yang mendasari keluhan, Kamu memeriksakan diri ke Dokter...')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"id":"QGcgMHyy47pD","outputId":"d7afac8d-69fa-4660-fe16-50d4317bdf9d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Pagi Jhunny,Terima kasih atas pertanyaannya.Keluhan berupa sakit pada perut yang dirasakan setiap makan tentunya dapat terasa mengganggu. Hal ini dapat disebabkan oleh hal berikut: Gastritis , yaitu kondisi ketika lapisan lambung mengalami iritasi, peradangan Penyakit Asam Lambung , yaitu kondisi ketika asam lambung naik ke kerongkongan Tukak lambung , yaitu luka yang muncul pada dinding lambung akibat terkikisnya lapisan dinding lambung. Luka ini juga berpotensi muncul pada dinding bagian pertama usus kecil (duodenum) serta kerongkongan (esofagus) Irritable Bowel Syn , yaitu gangguan pada usus besar yang dapat dipicu oleh stres atau makanan tertentu Dsbnya Alangkah baiknya untuk menelusuri penyebab yang mendasari keluhan, Kamu memeriksakan diri ke Dokter...'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":109}]},{"cell_type":"code","source":["sample_1 = df['answer'].sample(1)\n","\n","sample_1.values[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"a6DjnghQ6P6L","outputId":"2a6112b6-76f4-4a48-8d68-f51f2fe610ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Halo,Terimakasih atas pertanyaan yang Anda ajukan.Berdasarkan informasi yang Anda sebutkan, memang kemungkinan Anda mengalami suatu gejala  sembelit atau konstipasi . Konstipasi memang menjadi salah satu faktor terjadinya  ambeien/wasir . Oleh karena itu penanganan ambeien akan tuntas jika konstipasi bisa teratasi.Perlu Anda ketahui bahwa faktor yang mempengaruhi terjadinya konstipasi ada banyak. Selain pola makan yang tidak sehat/kurang mengonsumsi makanan berserat, kondisi psikis, akibat mengonsumsi obat-obatan tertentu, serta gangguan pada kondisi saluran pencernaan bawah juga menjadi pemicu. Tentu hal ini harus ditelusuri lebih lanjut.Diskusi lain terkait konstipasi dan ambeien yang serupa, bisa Anda baca  disini. Jika Anda sudah mengalami gejala ini cukup lama, disarankan untuk memeriksa kembali ke dokter terdekat. Anda bisa memeriksa ke dokter spesialis penyakit dalam agar mendapatkan pemeriksaan yang lebih lengkap, sehingga pengobatan dapat diberikan sesuai kondisi.Anjuran yang dapat dilakukan :   selalu perbanyak konsumsi makanan berserat   banyak minum air putih, sehari 8-10 gelas perhari   hindari konsumsi minuman berkafein, besoda, dan beralkohol   rutin berolahraga agar membantu menurunkan resiko konstipasi   jangan mengabaikan keinginan untuk BAB Semoga informasi ini membantu,dr. Mesha'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":193}]},{"cell_type":"code","source":["bersihkan_sapaan(sample_1.values[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"u425pmvs7rqt","outputId":"2586a276-5efc-4811-f351-7a4e2647d300"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'tinja pada bayi yang sudah mendapakan makanan pendampin ASI (MP-ASI) bisa berbentuk cairan dengan danya gumpalan-gumapaln dengan warna kuning, hijau, hingga coklat, apabila terlalu cair/encer tidak selalu menggambarkan adanya penyakit atau sesuatu yang berbahaya, karena memang dominasi asupan yang didapatkan oleh bayi lebih banyak adalah berbentuk cairan. Yang perlu diwaspdai dari bentuk dan warna tinja adalah apabila berubah menjadi benar-benar cair menandakan bahwa bayi mengalami diare, atau warnanya berubah menjadi merah, putih, atau hitam. Warna putih terjadi apabila adanya gangguan pada empedu bayi, sedangkan warna hitam akibat adanya pendarahan pada saluran pencernaan, sedangkan warna merah menandakan adanya pendarahan pada bagia usus dekat dubur. Adanya kelainan gangguan pada pencernaan biasanya disertai juga gejala lain seperti rewel, muntah, demam, lemas, bibir menjadi tampak kering, bahkan saat menangis tidak adalagi air mata yang keluar. Nah kalau sudah gejala mencurigakaan tersebut sebaiknay bayi Anda segera dibawa ke dokter untuk dilakukan pemeriksaan. Dengan begitu bisa diketahui sumber penyebab dari gangguan yang bayi alami. Frekuensi BAB bayi berkisar 2-7 kali dalam perhari, jika jangan langsung panik apabila BAB bayi nampak cair, asalkan gejala-gejala mencurigakan seperti di atas tidak dialami oleh bayi Anda. Periksakan kondisi anak Anda secara langsung ke dokter supaya dapat dilakukan pemeriksaan untuk mengetahui pasti penyebab dari kondisi BAB cair dan masih nampak ampas makanan tersebut. Apakah masih tergolong suatu yang wajar atau akibat adanya infeksi pencernaan, karena MP-ASI yang diberikan masih terlalu kasar, atau ada tidaknya suatu kelainan pada pencernaannya. Artikel terkait untuk disimak Menyelamatkan Bayi Mencret Dari Risiko Berbahaya Semoga bermanfaat'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":192}]},{"cell_type":"code","source":["df['question']"],"metadata":{"id":"UkeMMt5h7tzk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['answer-clean'] = df['answer'].apply(bersihkan_sapaan)"],"metadata":{"id":"TPykInK28ou3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZQgyIyiaEpAH","outputId":"27937880-7637-43f0-c467-169a806e205e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                        title  \\\n","0                                    Penyebab dan cara mengatasi BAB berdarah   \n","1                                Susah BAB setelah operasi wasir 3 bulan lalu   \n","2  Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir   \n","3  Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang   \n","4                           Penaganan susah BAB dan muncul benjolan pada anus   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                question  \\\n","0                                                                                                                                                                                                                                                                                                                                       Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih   \n","1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?   \n","2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?   \n","3                                                                                                                                                     Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.   \n","4  Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    answer  \\\n","0  Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...   \n","1  Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...   \n","2  Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...   \n","3  Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...   \n","4  Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...   \n","\n","                                 topics            topic_set  pola 1  pola 2  \\\n","0             wasir gangguan-pencernaan  gangguan-pencernaan       1       0   \n","1                      konstipasi wasir                wasir       1       0   \n","2                      konstipasi wasir                wasir       1       0   \n","3                  kulit benjolan wasir                wasir       0       0   \n","4  konstipasi wasir gangguan-pencernaan  gangguan-pencernaan       0       0   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              answer-clean  \n","0  terima kasih ya sudah bertanya . Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusing, lemas, perdarahan y...  \n","1  Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi, inkontinensia alvi, maupun irritable bowel syn . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, seperti sayu...  \n","2  terimakasih atas pertanyaan anda . wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum akan mengakibatkan k...  \n","3  terima kasih telah bertanya . Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan Anda. Sementara itu, hindar...  \n","4  sudah bertanya kepada saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan wasir. dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bila bersifat ringan biasanya akan hi...  "],"text/html":["\n","  <div id=\"df-06613e30-00c7-482f-862c-159439173f3c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>pola 1</th>\n","      <th>pola 2</th>\n","      <th>answer-clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Penyebab dan cara mengatasi BAB berdarah</td>\n","      <td>Alo dok. Barusan saya BAB, tapi BAB nya keluar darah lumayan banyak. kejadian ini sudah terjadi sekitar 3-4 kalian. setiap saya BAB, pasti selalu ada darah, tapi sebelumnya hanya 1 tetes saja darahnya. sekarang darahnya banyak, warnanya merah gelap (seperti darah haid). sejauh ini saya tidak merasa demam, diare, ataupun gejala lainnya. BAB saya juga terbilang cukup normal. kira kira itu kenapa ya dok? terimakasih</td>\n","      <td>Alo Sania, terima kasih ya sudah bertanya di Alodokter. Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusi...</td>\n","      <td>wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>terima kasih ya sudah bertanya . Keluhan yang anda alami dapat saja merupakan gejala dari : Disentri (bakteri ataupun amuba) Wasir Radang usus Luka pada anus Untuk membantu menentukan apa kemungkinan penyebab keluhan anda, ada baiknya anda juga memerhatikan apakah terdapat benjolan yang keluar dari anus, apakah darah bercampur dengan feses, dan terasa nyeri pada saat atau setelah BAB. Apabila keluhan saat ini masih berulang dan memang banyak, ada baiknya anda memeriksakan keluhan secara langsung ke dokter untuk dilakukan evaluasi dan penanganan pertama. Anda tidak disarankan mengonsumsi obat-obatan apapun tanpa adanya anjuran yang jelas dari dokter anda, terutama obat-obatan untuk menghentikan perdarahan. Anda juga disarankan untuk menghindari mengejan terlalu sering, meningkatkan konsumsi sayur dan buah, memastikan makanan yang anda konsumsi bersih dan matang sempurna serta menjaga asupan cairan minimal 2 liter perharinya. Apabila muncul keluhan seperti pusing, lemas, perdarahan y...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Susah BAB setelah operasi wasir 3 bulan lalu</td>\n","      <td>Dok , pasca oprasi hemoroid 3 bulan lalu . Saya tidak pernah merasakan perut mulas ingin BAB .tapj lubang anus saya ada dorongan terus untuk BAB . Jika di ikuti fases yg kluar hanya sedikit tapi sering. Apa yg harus syaa lakukan ?</td>\n","      <td>Alo, Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi,  inkontinensia alvi,  maupun irritable bowel syndrome . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, ...</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Terima kasih atas pertanyaannya. Keluhan sulit BAB dengan riwayat operasi hemorrhoid dapat disebabkan oleh banyak hal. Hal ini tergantung sejak kapan keluhan ini dirasakan, gejala penyerta (nyeri perut, nyeri pada anus, BAB keluar darah, diare, dll), riwayat pengobatan, dan lainnya. Terdapat beberapa kemungkinan penyebab dari keluhan yang Anda rasakan, seperti konstipasi/obstipasi, komplikasi pasca operasi, inkontinensia alvi, maupun irritable bowel syn . Apabila keluhan sulit BAB ini sudah terjadi setidaknya dalam 2 minggu terakhir ini, sebaiknya periksakan diri ke dokter. Dokter akan mengevaluasi keluhan Anda lebih lengkap lagi, melakukan pemeriksaan fisik, dan pemeriksaan penunjang yang relevan sehingga dokter dapat menentukan penyebab pasti dari keluhan Anda dan memberikan terapi yang sesuai. Untuk sementara waktu, berikut beberapa anjuran yang dapat Anda lakukan, seperti: Mencukupi kebutuhan nutrisi yang sehat dan bergizi. Mengonsumsi makanan yang kaya akan serat, seperti sayu...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bahaya menggunakan spekulum untuk mengatasi sulit bab pada penderita wasir</td>\n","      <td>Saya sudah menderita wasir menahun dok.. saya sudah seminggu tidak bisa bab.. apakah membuka lubang anus dengan speculum untuk sekedar ingin bab lancar ... Apakah aman ?</td>\n","      <td>Alo, terimakasih atas pertanyaan anda di Alodokter. wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum aka...</td>\n","      <td>konstipasi wasir</td>\n","      <td>wasir</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>terimakasih atas pertanyaan anda . wasir atau dalam dunia kesehatan disebut sebagai hemoroid merupakan sutau pelebaran pembuluh darah di sekitar anus yang dapat mengakibatkan munculnya benjola, perdarahan dan juga nyeri saat BAB. umumnya hemoroid di bedakan menjadi beberapa tingkatan, diantaranya : grade 1 : BAB berdarah benjolan belum muncul grade 2 : BAB berdarah, benjolan keluar masuk sendiri grade 3 : BAB berdarah, benjolan keluar dan tidak bisa masuk sendiri tanpa bantuan jari grade 4 : BAB berdarah, benjolan tidak bisa keluar masuk meskipun dengan bantuan jari jika berdasarkan dari keluhan yang anda sampaikan, wasir anda kemungkinan Sudah mencapai grade 3-4. yang mana penangana hemrorid grade 3-4 yaitu haruslah dengan penangan medis dokter yaitu dengan operasi. karena jika tidak di operasi maka akan mengakibatkan, anemia, trmbosis, keruskan pada anus, infeksi. oleh sebab itu, sebaiknya anda berkonsultasi dengan dokter secara langsung. menggunakan speculum akan mengakibatkan k...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Ambeien, kulit kepala iritasi, dan benjolan kecil di leher bagian belakang</td>\n","      <td>Selamat Malam Dok, Saya mengalami Ambeyen, saya mengalami beberapa hal ini : BAB Berdarah berwarna merah terang, namun tidak nyeri. Gatal dan iritasi pada area sekitar saluran anus. Benjolan yang sensitif atau nyeri di dekat anus. Bengkak di sekitar anus. Nyeri dan rasa tidak nyaman.   Kemudian kulit kepala saya juga iritasi, karena banyak benjolan seperti bisul yang menyebabkan gatal di kepala saya, kemudian di leher belakang saya ada benjolan kecil, apakah karena iritasi tsb ya? Karena Saya Pernah Mengalami benjolan di leher tsb ketika saya mengalami sariawan atau masalah kerongkongan.</td>\n","      <td>Selamat malam, terima kasih telah bertanya di Alodokter. Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari  dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan...</td>\n","      <td>kulit benjolan wasir</td>\n","      <td>wasir</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>terima kasih telah bertanya . Ambeien, wasir atau hemorrhoid, adalah suatu bentuk kelainan pembuluh darah di area anus yang ditandai dengan munculnya benjolan dan bercampurnya darah dengan tinja ketika BAB. Kondisi ini masih belum diketahui penyebab terjadinya, namun dapat terpicu oleh beberapa faktor berikut: Riwayat keluarga dengan keluhan serupa Riwayat melahirkan Mengalami batuk dan bersin lama Kebiasaan mengangkat beban berat Kebiasaan mengejan terlalu kencang Pada kasus Anda, jika gejala yang Anda alami sudah begitu menganggu atau sudah tidak bisa ditangani dengan obat yang dijual bebas, berarti Anda membutuhkan penanganan dari dokter bedah . Maka saran kami, konsultasikan diri Anda pada dokter bedah terdekat, agar bisa dicari tahu penanganan terbaiknya. Jangan takut untuk memeriksakan diri ke dokter bedah, karena bila Anda ragu untuk dilakukan pembedahan, Anda berhak menolak. Yang penting sudah dilakukan pemeriksaan terlebih dahulu terkait keluhan Anda. Sementara itu, hindar...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Penaganan susah BAB dan muncul benjolan pada anus</td>\n","      <td>Halo dok, pagi ini saya habis ke dokter saya masih kurang jelas apa kata sidokter habisnya keliahatannya nyebelin jadi saya hiraukan, saya punya keluhan susah bab, ketika bab sudah memucuk tapi tidak mau keluar, terasa seperti benjolan didubur saya. Pasa saya pegan ada sedikit benjolan kecil didubur sehabis mengejan tadi, selepas itu, pas saya periksa ke dokter dokter memeriksanya gk ada apa apa, apaya itu dok, selepas itu sidokter memberi obat Superhoid, gk tau fungsinya buat apa, jika ada saran lain dok apa yang harus saya. Lakukan ya, sebelumnya sih dua hari kemarin saya sempat diare dan konsumsi diapet. Maaf dok, jika ada saran saya ingin menjaga pola makan dan kesehatan, minta saran buat perawatan mandirinya dok, terima kasih.</td>\n","      <td>Alo dicky terima kasih sudah bertanya kepada Alodokter saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan  wasir.  dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bi...</td>\n","      <td>konstipasi wasir gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>sudah bertanya kepada saya mengerti akan kekhwatiran anda, dimana keluhan susah BAB dalam dunia medis disebut dengan konstipasi. dimana hal ini dapat disebabkan karena pola makan yang buruk seperti kurang serat dan kurang minum, kurang aktif bergerak, menahan BAB, efek samping konsumsi obat serta akibat gangguan psikologis seperti gangguan kecemasan dan depresi. dimana akibat konstipasi yang terjadi dapat menimbulkan keluhan terjadinya pembengkakan di anus, pembengkakan atau pemebesaran ini terjadi pada pembuluh darah di usus besar bagian akhir atau rektum serta dubur atau anus yang disebut dengan wasir. dimana wasir ini dibagi dua jenis yaitu bagian internal dimana pembengkakan atau benjolannya di dalam anus, sedangkan eksternal pembengkakan atau benjolan berada diluar anus. dan ada berbagai tingkatan atau derajat wasir dan penangananya sesuai tingkat keparahnnya. untuk menangani wasir ini seperti yang saya sebut kan sesuai tingkat keparahnnya bila bersifat ringan biasanya akan hi...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06613e30-00c7-482f-862c-159439173f3c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-06613e30-00c7-482f-862c-159439173f3c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-06613e30-00c7-482f-862c-159439173f3c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-4a2b3da2-5180-4709-a7d8-b2e948e05e5c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a2b3da2-5180-4709-a7d8-b2e948e05e5c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-4a2b3da2-5180-4709-a7d8-b2e948e05e5c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 21376,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19750,\n        \"samples\": [\n          \"Nyeri perut sebelah kanan saat disentuh disertai demam dan sering BAB\",\n          \"tidak nyaman di perut dan feses kehitaman\",\n          \"Penyebab cemas dan jantung berdebar setiap malam hari\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21187,\n        \"samples\": [\n          \"Dok saya mau tanya,ibu saya sering merasa sesak di dada,sehingga dia tidak kuat terkena angin ,hingga dirumah pun memakai baju berlapis lapis kata beliau itu biar hangat katanya kalau gak pake baju berlapis lapis beliau merasa dingin dan sesak padahal cuaca itu saat bersuhu hangatTerus ibu ku sering pake korset gitu biar badannya ke teken gitu,kalau gak sering pake samping di ikat perutnya katanya sih nyaman kalau di giniin Setiap diperiksa sama dokter katanya itu biasa Tapi setiap di beri obat malah makin parah mamah aku dokTerus di bola matanya kata mamah aku gak jelas katanya seperti ada darah gitu jadi melihatnya kurang jelasSering banget pusing dokTerus tangannya sering kebas gak kerasa apa apa saat terkena air dinginAku juga seperti itu dok ,aku sering tangan ku kebas saat dan sesudah terkena air dingin Kira kira itu sakit apa ya dok?\",\n          \"Dok saya baru saja selesai haid sekitar pada hari ke 4 setelah haid saya melakukan dengan suami, dan sekarang tepat 9 hari setelah haid saya merasa mual, perut kembung, serta kentut dan bersendawa, apakah itu hamil atau maag ? Bisa tolong dijelaskan perbedaannya ?\",\n          \"Slmt mlm dok. Sy telah menjalani operasi wasir dgn metode HAR \\\\u0026amp; RAR..sekitar 2 mgg lalu..kondisi skrng saat BAB ada darah bercampur dgn feses sy..dan juga sering kali ada cairan spt nanah sering keluar di dubur sy..hal ini terlihat klo sy gunakan tissue utk membersihkannya...obat antibiotik sudah habis dan dokter sdh tdk memberikan obat antiobiotiknya. Sy khawatir..saat BAB msh sj keluat darah..apalagi klo stlh bab encer anus terasa perih..sampai 8 jam hilang. Mhn informasinya apakah ini kondisi normal atau bagaimana?. krn menurut dokter itu tidak apa2.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21344,\n        \"samples\": [\n          \"Hai,Keluhan tersebut dapat disebabkan oleh:   infeksi atau batu saluran kemih   radang usus besar   cedera   tinja yang mengeras Usahakan untuk memiliki pola makan teratur. Perbanyak minum air mineral dan tidak menahan rasa saat ingin BAK maupun BAB. Batasi kafein/ alkohol. Tidak merokok. Sebaiknya tidak mengangkat benda-benda yang berat.Jika gejala belum membaik, disarankan agar Anda periksa ke dokter. Pemeriksaan fisik dan tes penunjang seperti tes urin atau USG, dapat membantu mengetahui penyebabnya. Sehingga dapat segera diberikan penanganan yang tepat.Anda dapat membaca halaman  Sakit perut kiri  Semoga bermanfaat,dr. Jessica\",\n          \"Halo Vharida Vitriyaa, Sakit perut  merupakan sakit yang dapat dialami semua orang, dan pada umumnya tidak memiliki penyebab yang serius. Jika Anda mengalami sakit perut, yang perlu diketahui pertama kali adalah bagian mana perut yang sakit. Dalam hal ini Anda sudah menyebutkan bagian bawah, maka dari itu berikut saya jabarkan penyebab  sakit perut bagian bawah  pada wanita:   Sakit perut akibat menstruasi   Ovulasi   Hamil di luar kandungan   Keguguran   Penyakit radang panggul   Kista ovarium   Endometriosis   Fibroid   Gangguan serviks seperti infeksi atau kanker   Radang saluran tuba   Penyakit menular seksual   Masalah ginjal   Radang usus Ada baiknya Anda memeriksakan diri ke dokter spesialis penyakit dalam untuk mendapat pemeriksaan lebih lanjut selain USG. Jika tidak ditemukan masalah serius pada bagian bawah perut Anda, kemungkinan yang paling besar adalah Anda memiliki masalah lambung seperti:   Tukak lambung   Penyakit asam lambung   Gastritis Berikut beberapa tips untuk Anda:   Minum air mineral minimal 2 liter setiap hari   Utamakan makanan berserat untuk mencegah konstipasi   Kurangi konsumsi makanan berlemak   Hindari minuman berkafein seperti kopi dan teh, hindari juga soda dan minuman beralkohol   Konsumsi yoghurt   Konsumsi obat maag yang dijual bebas   Kurangi stres   Rutin berolah raga Semoga bermanfaat,Dr. Yosephine \",\n          \"Defar Fitri, Kram perut bisa diakibatkan oleh: nyeri otot perut gastritis tukak lambung gastroenteritis radang usus buntu infeksi ginjal  batu ginjal radang panggul endometriosis Sebaiknya Anda berkonsultasi dengan dokter kandungan di mana dokter akan menganalisis gejala dan melakukan pemeriksaan fisik. Tes penunjang seperti tes darah dan USG dapat dokter anjurkan. Terapi yang tepat akan dokter berikan. Tips berikut ini dapat Anda lakukan: hindari mengurut atau menekan bagian yang sakit konsumsi makanan bergizi seimbang secara teratur kelola stres dengan bijak minum air putih dalam jumlah cukup miliki waktu tidur yang cukup hindari merokok dan minum minuman keras hindari langsung berbaring sesudah makan kurangi minum minuman berkafein dan bersoda Artikel yang bisa Anda baca: Sakit perut Semoga bermanfaat dan salam, dr. Rony Wijaya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2770,\n        \"samples\": [\n          \"sakit-maag sakit-perut infeksi-saluran-kemih konstipasi asam-lambung gastritis\",\n          \"keringat-dingin sakit-maag\",\n          \"anak herba konstipasi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"konstipasi\",\n          \"diare\",\n          \"gangguan-pencernaan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer-clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21329,\n        \"samples\": [\n          \"Terimakasih telah bertanya . Sensasi tidak nyaman di punggung belakang dada saat bernapas, bagai berdahak dan juga tertarik, sesungguhnya tidaklah spesifik merujuk pada gejala penyakit tertentu. Mungkin, keluhan Anda muncul karena beberapa kondisi berikut: Gangguan pada otot punggung dan dada, misalnya karena kram , syaraf kejepit Gangguan pada saluran napas, misalnya bronkhitis , asma , pneumonia, tonsilofaringitis, pleuritis, tuberkulosis Gangguan pada saluran cerna, misalnya gastroesophageal reflux disease , esofagitis Gangguan psikosomatis, gangguan jantung, dan lain sebagainya Kondisi ini, bila tidak menyebabkan Anda merasa nyeri, sesak, batuk lama, dan kesulitan beraktifitas, kemungkinan tidaklah berbahaya. Namun, jika Anda merasa sangat terganggu dengan keluhan tersebut, lebih baik Anda tetap memeriksakannya langsung ke dokter atau dokter spesialis penyakit dalam supaya dievaluasi lebih mendalam kemungkinan penyebabnya, sehingga bisa diberikan penanganan yang tepat. Untuk saat ini, kami sarankan Anda perbanyak dulu beristirahat. Kurangi produksi lendir di saluran napas, dengan menjauhi substansi yang rentan membuat Anda alergi, gunakan masker saat beraktifitas di lingkungan kotor dan berpolusi, jaga selalu kebersihan tempat tinggal Anda. Kurangi juga produksi lendir di saluran cerna, yakni dengan mengurangi konsumsi makanan berminyak, pedas, dan mengandung pemanis buatan. Tidak lupa, rajinlah berolahraga dan hindari rokok. Semoga membantu ya..\",\n          \"Terimakasih atas pertanyaannya. Dalam ranah medis, sesungguhnya tidak dikenal istilah masuk angin. Perut yang kembung disertai diare lebih mungkin disebabkan oleh infeksi pada saluran pencernaan , misalnya karena virus, bakteri, bahkan parasit. Infeksi ini, selain menyebabkan perut kembung dan diare, sering juga memicu demam, mual, muntah, lemas, dan banyak lagi keluhan lainnya. Di samping infeksi, gangguan pada sistem organ lain, seperti alergi makanan, keracunan, radang usus, dispepsia, tumor jinak atau ganas, sin usus, malabsorpsi karbohi, dan sebagainya bisa pula menyebabkan keluhan seperti ini. Tidak jarang, keluhan Anda bisa pula muncul karena efek samping obat, stres, atau gangguan sistem organ lainnya. Bila keluhan Anda baru terjadi selama 1-3 hari, sebaiknya Anda tidak dulu khawatir. Anda bisa atasi dulu keluhan tersebut dengan: Lebih banyak istirahat Kompres hangat perut yang kembung Tidak dulu berlebihan mengkonsumsi makanan dan minuman yang mengandung gas, seperti santan, sambal, saus, teh, gorengan, kopi, soda, dan sebagainya Minum lebih banyak, terutama air putih Jangan dulu jajan sembarangan Jangan sembarangan minum obat Riwayat ASD yang Anda alami, beserta pengobatannya, kemungkinan tidak berkaitan langsung dengan keluhan yang Anda alami saat ini. Bila Anda telah disiplin menjalani upaya di atas, namun keluhan tidak juga membaik, sebaiknya periksakanlah langsung diri Anda ke dokter atau dokter penyakit dalam agar diberikan penanganan lebih lanjut sesuai penyebabnya ya.. Semoga membantu.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":203}]},{"cell_type":"code","source":["df['Clean-Question'] = df['question'].apply(bersihkan_sapaan)"],"metadata":{"id":"q5qvIlwiEpP_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Word Elongation"],"metadata":{"id":"YCA1ZUXotOS8"}},{"cell_type":"code","source":["from indoNLP.preprocessing import replace_word_elongation\n","df['final Answer'] = df['answer-clean'].apply(replace_word_elongation)\n","df['final Question'] = df['Clean-Question'].apply(replace_word_elongation)"],"metadata":{"id":"QzmXdNjpFGlv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Replace Slang"],"metadata":{"id":"UYf2IphAtULs"}},{"cell_type":"code","source":["from indoNLP.preprocessing import replace_slang\n","df['final Answer'] = df['final Answer'].apply(replace_slang)\n","df['final Question'] = df['final Question'].apply(replace_slang)"],"metadata":{"id":"00NglLxEFIun"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['final Question last'] = df['title'] + \". \"  + df['final Question']"],"metadata":{"id":"m2H6rEE7FqS3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.sample(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oZSpXsEOI-Z0","outputId":"16a14c75-74ae-4158-f0cd-33ee6d8d4cf0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                    title  \\\n","20694  sakit kepala bagian belakang disertai jantung berdebar-debar dan sakit di ulu hati   \n","2175                                        Penggabungan obat untuk mengatasi sakit perut   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                question  \\\n","20694  Assalammu'alaikum,dok saya mau tanya ini udah hampir 1 bulan ini saya mengalami penyakit GERD.. yg saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yg saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks donk,,,   \n","2175                                                                                                                                                                                                                                              Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        answer  \\\n","20694  Hai.Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti :   Nyeri pada dada   Dada terasa panas   Sesak   Nyeri ulu hati   Mual muntah   Lemas   dll Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti:   Asma   Infeksi paru   Anemia/ Kurang sel darah merah   Sakit kepala tipe tegang/ Tension type headache   Serangan jantung   dll Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pe...   \n","2175   Alo Daman, Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. ...   \n","\n","                               topics      topic_set  pola 1  pola 2  \\\n","20694                    asam-lambung   asam-lambung       1       0   \n","2175   sakit-perut obat tukak-lambung  tukak-lambung       1       0   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  answer-clean  \\\n","20694  Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti : Nyeri pada dada Dada terasa panas Sesak Nyeri ulu hati Mual muntah Lemas dll Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti: Asma Infeksi paru Anemia/ Kurang sel darah merah Sakit kepala tipe tegang/ Tension type headache Serangan jantung dll Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pemeriksaan lebih lanjut. Mungki...   \n","2175   Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena kete...   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                          Clean-Question  \\\n","20694  Assalammu'alaikum,dok saya mau tanya ini udah hampir 1 bulan ini saya mengalami penyakit GERD.. yg saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yg saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks donk,,,   \n","2175                                                                                                                                                                                                                                              Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  final Answer  \\\n","20694  Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti : Nyeri pada dada Dada terasa panas Sesak Nyeri ulu hati Mual muntah Lemas dulu Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti: Asma Infeksi paru Anemia/ Kurang sel darah merah Sakit kepala tipe tegang/ Tension type headache Serangan jantung dulu Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pemeriksaan lebih lanjut. Mung...   \n","2175   Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena kete...   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                               final Question  \\\n","20694  Assalammu'alaikum,dok saya mau tanya ini sudah hampir 1 bulan ini saya mengalami penyakit GERD.. yang saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yang saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks dong,,,   \n","2175                                                                                                                                                                                                                                                 Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              final Question last  \n","20694  sakit kepala bagian belakang disertai jantung berdebar-debar dan sakit di ulu hati. Assalammu'alaikum,dok saya mau tanya ini sudah hampir 1 bulan ini saya mengalami penyakit GERD.. yang saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yang saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks dong,,,  \n","2175                                                                                                                                                                                                                                                                                      Penggabungan obat untuk mengatasi sakit perut. Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih  "],"text/html":["\n","  <div id=\"df-c4195f3e-5df1-4a4d-b7dd-bfbf01df696e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>pola 1</th>\n","      <th>pola 2</th>\n","      <th>answer-clean</th>\n","      <th>Clean-Question</th>\n","      <th>final Answer</th>\n","      <th>final Question</th>\n","      <th>final Question last</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>20694</th>\n","      <td>sakit kepala bagian belakang disertai jantung berdebar-debar dan sakit di ulu hati</td>\n","      <td>Assalammu'alaikum,dok saya mau tanya ini udah hampir 1 bulan ini saya mengalami penyakit GERD.. yg saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yg saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks donk,,,</td>\n","      <td>Hai.Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti :   Nyeri pada dada   Dada terasa panas   Sesak   Nyeri ulu hati   Mual muntah   Lemas   dll Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti:   Asma   Infeksi paru   Anemia/ Kurang sel darah merah   Sakit kepala tipe tegang/ Tension type headache   Serangan jantung   dll Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pe...</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti : Nyeri pada dada Dada terasa panas Sesak Nyeri ulu hati Mual muntah Lemas dll Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti: Asma Infeksi paru Anemia/ Kurang sel darah merah Sakit kepala tipe tegang/ Tension type headache Serangan jantung dll Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pemeriksaan lebih lanjut. Mungki...</td>\n","      <td>Assalammu'alaikum,dok saya mau tanya ini udah hampir 1 bulan ini saya mengalami penyakit GERD.. yg saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yg saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks donk,,,</td>\n","      <td>Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti : Nyeri pada dada Dada terasa panas Sesak Nyeri ulu hati Mual muntah Lemas dulu Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti: Asma Infeksi paru Anemia/ Kurang sel darah merah Sakit kepala tipe tegang/ Tension type headache Serangan jantung dulu Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pemeriksaan lebih lanjut. Mung...</td>\n","      <td>Assalammu'alaikum,dok saya mau tanya ini sudah hampir 1 bulan ini saya mengalami penyakit GERD.. yang saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yang saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks dong,,,</td>\n","      <td>sakit kepala bagian belakang disertai jantung berdebar-debar dan sakit di ulu hati. Assalammu'alaikum,dok saya mau tanya ini sudah hampir 1 bulan ini saya mengalami penyakit GERD.. yang saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yang saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks dong,,,</td>\n","    </tr>\n","    <tr>\n","      <th>2175</th>\n","      <td>Penggabungan obat untuk mengatasi sakit perut</td>\n","      <td>Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih</td>\n","      <td>Alo Daman, Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. ...</td>\n","      <td>sakit-perut obat tukak-lambung</td>\n","      <td>tukak-lambung</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena kete...</td>\n","      <td>Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih</td>\n","      <td>Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena kete...</td>\n","      <td>Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih</td>\n","      <td>Penggabungan obat untuk mengatasi sakit perut. Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4195f3e-5df1-4a4d-b7dd-bfbf01df696e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c4195f3e-5df1-4a4d-b7dd-bfbf01df696e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c4195f3e-5df1-4a4d-b7dd-bfbf01df696e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-0d5c9f38-0768-4ccf-b23f-f1a61c9bc981\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d5c9f38-0768-4ccf-b23f-f1a61c9bc981')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-0d5c9f38-0768-4ccf-b23f-f1a61c9bc981 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Penggabungan obat untuk mengatasi sakit perut\",\n          \"sakit kepala bagian belakang disertai jantung berdebar-debar dan sakit di ulu hati\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih\",\n          \"Assalammu'alaikum,dok saya mau tanya ini udah hampir 1 bulan ini saya mengalami penyakit GERD.. yg saya alami selama ini kepala belakang sering pusing kadang kadang Suka ke ubun2 jantung sering berdebar kencang sakit di ulu hati,sesak napas, sakit tenggorokan,telapak kaki,tangan dingin dok,,, setiap hujan turun penyakit saya ini kambuh lagi yg saya mau tanyakan apa saya kena asam lambung apa penyakit lain ya dok mohon jawab dok,,, thanks donk,,,\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Alo Daman, Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena keterbatasan informasi mengenai gejala sakit perut Anda, saya tidak dapat memberikan saran lebih lanjut. Saran saya, silakan Anda gunakan aplikasi Alodokter yang dapat Anda unduh di Google Play Store atau App Store. Dokter akan melakukan tanya jawab pada Anda sehingga mendapatkan informasi lebih lanjut mengenai gejala Anda dan dapat memberikan anjuran yang sesuai. Untuk saat ini, silakan Anda konsumsi obat sesuai anjuran dokter dulu. Hindari mengkonsumsi obat lain tanpa anjuran dokter. Selain itu, silakan juga lakukan anjuran berikut: hindari konsumsi makanan pedas, asam , berminyak hindari konsumsi minuman berkafein, bersoda, dan beralkohol konsumsi makanan dalam porsi kecil tetapi lebih sering hindari berbaring setelah makan hindari kebiasaan merokok kelola stres dengan baik Semoga informasi ini membantu Anda.\",\n          \"Hai.Dari keluhan yang Anda alami, rasa sesak nafas disertai dengan rasa nyeri ulu hati dan sakit kepala mungkin dapat disebabkan karena suatu GERD. GERD atau biasa disebut sebagai penyakit asam lambung adalah suatu keadaan dimana terjadinya kenaikan dari asam lambung ke tenggorokan. Pada orang yang sudah lama mengalami GERD, maka dapat terjadi beberapa komplikasi seperti sering pusing, serta pada keadaan lanjut dapat terjadi erosi tenggorokan sehingga dapat menyebabkan muntah darah. GERD dapat menyebabkan gejala seperti :   Nyeri pada dada   Dada terasa panas   Sesak   Nyeri ulu hati   Mual muntah   Lemas   dll Tetapi mungkin juga keadaan yang Anda rasakan dapat disebabkan karena penyebab lain seperti:   Asma   Infeksi paru   Anemia/ Kurang sel darah merah   Sakit kepala tipe tegang/ Tension type headache   Serangan jantung   dll Oleh karena itu, untuk memastikan penyebab dari keluhan Anda, dirasankan agar Anda memeriksakan diri secara langsung ke dokter sehingga dapat dilakukan pemeriksaan lebih lanjut. Mungkin nanti akan dilakukan pemeriksaan tambahan seperti pemeriksaan darah, rontgen, EKG, serta endoskopi jika memang diperlukan.Berikut artikel yang dapat ANda baca mengenai  GERD semoga bermanfaat. terimakasihdr. Danny\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sakit-perut obat tukak-lambung\",\n          \"asam-lambung\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"tukak-lambung\",\n          \"asam-lambung\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pola 2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer-clean\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena keterbatasan informasi mengenai gejala sakit perut Anda, saya tidak dapat memberikan saran lebih lanjut. Saran saya, silakan Anda gunakan aplikasi yang dapat Anda unduh di Google Play Store atau App Store. Dokter akan melakukan tanya jawab pada Anda sehingga mendapatkan informasi lebih lanjut mengenai gejala Anda dan dapat memberikan anjuran yang sesuai. Untuk saat ini, silakan Anda konsumsi obat sesuai anjuran dokter dulu. Hindari mengkonsumsi obat lain tanpa anjuran dokter. Selain itu, silakan juga lakukan anjuran berikut: hindari konsumsi makanan pedas, asam , berminyak hindari konsumsi minuman berkafein, bersoda, dan beralkohol konsumsi makanan dalam porsi kecil tetapi lebih sering hindari berbaring setelah makan hindari kebiasaan merokok kelola stres dengan baik Semoga informasi ini membantu Anda.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Clean-Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tp masih belom enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Terima kasih atas pertanyaannya. Gejala sakit perut penyebabnya sangat bervariasi. Untuk memastikannya, diperlukan informasi lebih lanjut mengenai lokasi sakit perut, ciri-ciri sakit perut, dan gejala lain yang Anda alami. Gejala sakit yang Anda alami dapat disebabkan oleh: gastritis tukak lambung penyakit asam lambung gastroenteritis pankreatitis radang empedu Spaminal adalah obat yang mengandung metampiron, papaverin, dan ekstrak belladona yang merupakan golongan obat keras yang hanya dapat digunakan sesuai anjuran dokter. Obat ini digunakan untuk mengatasi nyeri karena kontraksi otot. Namun, tidak semua kondisi dapat diobati dengan obat ini. Topgesic adalah obat yang mengandung asam mefenamat, yang juga merupakan golongan obat keras yang sebaiknya digunakan sesuai anjuran dokter. Obat ini juga memiliki efek samping pada lambung. Jika yang Anda alami adalah gangguan asam lambung, maka jika Anda mengkonsumsi kedua obat ini dapat menyebabkan gejala Anda bertambah buruk. Karena keterbatasan informasi mengenai gejala sakit perut Anda, saya tidak dapat memberikan saran lebih lanjut. Saran saya, silakan Anda gunakan aplikasi yang dapat Anda unduh di Google Play Store atau apa Store. Dokter akan melakukan tanya jawab pada Anda sehingga mendapatkan informasi lebih lanjut mengenai gejala Anda dan dapat memberikan anjuran yang sesuai. Untuk saat ini, silakan Anda konsumsi obat sesuai anjuran dokter dulu. Hindari mengkonsumsi obat lain tanpa anjuran dokter. Selain itu, silakan juga lakukan anjuran berikut: hindari konsumsi makanan pedas, asam , berminyak hindari konsumsi minuman berkafein, bersoda, dan beralkohol konsumsi makanan dalam porsi kecil tetapi lebih sering hindari berbaring setelah makan hindari kebiasaan merokok kelola stres dengan baik Semoga informasi ini membantu Anda.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final Question last\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Penggabungan obat untuk mengatasi sakit perut. Permisi dok,Saya mau tanya, adik saya sakit perut sudah ke puskes dan dikasih antasida, vit b6 sama paracetamol tapi masih belum enakan. Apakah paracetamol bisa digabung dengan spasminal dan top gesik dok?Terimakasih\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":239}]},{"cell_type":"code","source":["df[['final Question last', 'final Answer']].to_csv('final.csv', index=False)"],"metadata":{"id":"ywrhxj9tJXEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" !curl -F \"reqtype=fileupload\" -F \"fileToUpload=@final.csv\" https://catbox.moe/user/api.php"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9aFSSAAJ0Uq","outputId":"ee522b88-3c00-46b3-c8f0-8bbd7b3b190b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://files.catbox.moe/q4yhww.csv"]}]},{"cell_type":"code","source":["df.isnull().sum()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":460},"id":"j_IqGiL6J6yD","outputId":"56038f42-c80a-468d-ee30-65b619b5450e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["title                  0\n","question               0\n","answer                 0\n","topics                 0\n","topic_set              0\n","pola 1                 0\n","pola 2                 0\n","answer-clean           0\n","Clean-Question         0\n","final Answer           0\n","final Question         0\n","final Question last    0\n","dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>title</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>question</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>answer</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>topics</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>topic_set</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>pola 1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>pola 2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>answer-clean</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Clean-Question</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>final Answer</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>final Question</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>final Question last</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":219}]},{"cell_type":"code","source":["df[df['final Answer'] == \"\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":268},"id":"RfA129iZNdUc","outputId":"6c2f9e1b-3e61-4988-e353-4eeae401c6d1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                     title  \\\n","10260  Obat untuk muntah disertai BAB cair   \n","20409     Solusi atasi nyeri pada punggung   \n","\n","                                                                                                                                             question  \\\n","10260  mlm dok oya dok da beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa yah dok n apa obatnya....makasi dok sebelumnya...   \n","20409                                                                 Saya kalo abis makan mie punggung belikat nyeri banget gimana ya solusi nya dok   \n","\n","                         answer        topics     topic_set  pola 1  pola 2  \\\n","10260                     Halo,  muntah diare         diare       1       0   \n","20409  Hai Restu Yani Handayani  asam-lambung  asam-lambung       0       0   \n","\n","      answer-clean  \\\n","10260                \n","20409                \n","\n","                                                                                                                                       Clean-Question  \\\n","10260  mlm dok oya dok da beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa yah dok n apa obatnya....makasi dok sebelumnya...   \n","20409                                                                 Saya kalo abis makan mie punggung belikat nyeri banget gimana ya solusi nya dok   \n","\n","      final Answer  \\\n","10260                \n","20409                \n","\n","                                                                                                                                               final Question  \\\n","10260  malam dok oya dok dah beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa ya dok n apa obatnya....terima kasih dok sebelumnya...   \n","20409                                                                     Saya kalo habis makan mie punggung belikat nyeri banget bagaimana ya solusi nya dok   \n","\n","                                                                                                                                                                               final Question last  \n","10260  Obat untuk muntah disertai BAB cair. malam dok oya dok dah beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa ya dok n apa obatnya....terima kasih dok sebelumnya...  \n","20409                                                                        Solusi atasi nyeri pada punggung. Saya kalo habis makan mie punggung belikat nyeri banget bagaimana ya solusi nya dok  "],"text/html":["\n","  <div id=\"df-fd5198b4-d7d0-4292-98f9-ad9dd0820016\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>question</th>\n","      <th>answer</th>\n","      <th>topics</th>\n","      <th>topic_set</th>\n","      <th>pola 1</th>\n","      <th>pola 2</th>\n","      <th>answer-clean</th>\n","      <th>Clean-Question</th>\n","      <th>final Answer</th>\n","      <th>final Question</th>\n","      <th>final Question last</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10260</th>\n","      <td>Obat untuk muntah disertai BAB cair</td>\n","      <td>mlm dok oya dok da beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa yah dok n apa obatnya....makasi dok sebelumnya...</td>\n","      <td>Halo,</td>\n","      <td>muntah diare</td>\n","      <td>diare</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>mlm dok oya dok da beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa yah dok n apa obatnya....makasi dok sebelumnya...</td>\n","      <td></td>\n","      <td>malam dok oya dok dah beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa ya dok n apa obatnya....terima kasih dok sebelumnya...</td>\n","      <td>Obat untuk muntah disertai BAB cair. malam dok oya dok dah beberapa hari ini saya muntah2 dan mencret2 mau tanya dok itu gejalah apa ya dok n apa obatnya....terima kasih dok sebelumnya...</td>\n","    </tr>\n","    <tr>\n","      <th>20409</th>\n","      <td>Solusi atasi nyeri pada punggung</td>\n","      <td>Saya kalo abis makan mie punggung belikat nyeri banget gimana ya solusi nya dok</td>\n","      <td>Hai Restu Yani Handayani</td>\n","      <td>asam-lambung</td>\n","      <td>asam-lambung</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td></td>\n","      <td>Saya kalo abis makan mie punggung belikat nyeri banget gimana ya solusi nya dok</td>\n","      <td></td>\n","      <td>Saya kalo habis makan mie punggung belikat nyeri banget bagaimana ya solusi nya dok</td>\n","      <td>Solusi atasi nyeri pada punggung. Saya kalo habis makan mie punggung belikat nyeri banget bagaimana ya solusi nya dok</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd5198b4-d7d0-4292-98f9-ad9dd0820016')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fd5198b4-d7d0-4292-98f9-ad9dd0820016 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fd5198b4-d7d0-4292-98f9-ad9dd0820016');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-97f6106e-65d1-4acf-b0ee-a59a7ea93b54\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97f6106e-65d1-4acf-b0ee-a59a7ea93b54')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-97f6106e-65d1-4acf-b0ee-a59a7ea93b54 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","repr_error":"0"}},"metadata":{},"execution_count":221}]},{"cell_type":"code","source":["df.to_csv('final-[1].csv', index=False)"],"metadata":{"id":"3NgMw6tSPH01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -F \"reqtype=fileupload\" -F \"fileToUpload=@final-[1].csv\" https://catbox.moe/user/api.php"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24fM9RvfPLhA","outputId":"ad5a192a-f587-40de-f2e3-c4bd48e155c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://files.catbox.moe/bu8lgd.csv"]}]},{"cell_type":"markdown","source":["# Training ðŸ‹ï¸â€â™€ï¸\n","\n","Untuk training model model LLM kami menggunakan salah satu teknik fine tuninng yaitu PEFT (Parameter Efficient Fine Tune) yaitu QLoRA"],"metadata":{"id":"aGwkqHBivctJ"}},{"cell_type":"markdown","source":["- QLoRA adalah teknik fine-tuning model bahasa besar (LLM) yang mengurangi penggunaan memori secara signifikan dibandingkan dengan fine-tuning penuh. Ini dilakukan dengan mengkuantisasi bobot model menjadi 4-bit dan menggunakan Low-Rank Adapters (LoRA) untuk melatih hanya sebagian kecil dari parameter model.\n","\n","- Unsloth adalah library yang mengoptimalkan proses QLoRA, membuatnya 2x lebih cepat dibandingkan implementasi standar, terutama pada GPU seperti T4, V100, dan Ampere+."],"metadata":{"id":"3eimT-VixnhB"}},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVRynwYYexQF","outputId":"0d0f6f7d-fdfe-4d73-f583-e2039160a0fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["### Berikut adalah model model yang kami Gunakan"],"metadata":{"id":"vj1O3pdOzTP0"}},{"cell_type":"code","source":["import torch\n","from unsloth import FastLanguageModel"],"metadata":{"id":"6ht3vb7-etq4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Models = [\n","  \"unsloth/mistral-7b-v0.3\",\n","  \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n","  \"unsloth/llama-3-8b-bnb-4bit\",\n","  \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\",\n","  \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\",\n","  \"Yellow-AI-NLP/komodo-7b-base\",\n","]"],"metadata":{"id":"Z0aHW0ZcyPDS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load Model"],"metadata":{"id":"OvzM2c0G2rcK"}},{"cell_type":"markdown","source":["Pemilihian Modal , Sequence Length dan `load in 4 bit`"],"metadata":{"id":"H2zqxbtO1ZdY"}},{"cell_type":"markdown","source":["- Penggunaan parameter `load_in_4bit` = True pada bagian inisialisasi model dengan FastLanguageModel.from_pretrained adalah tanda utama bahwa proses ini menggunakan teknik QLoRA.\n","\n","- Seperti yang sudah dijelaskan sebelumnya, QLoRA adalah variasi dari LoRA yang mengkuantisasi model dasar (base model) menjadi 4-bit sebelum menambahkan adapter LoRA. Parameter load_in_4bit=True secara spesifik menginstruksikan library  untuk memuat model dalam format 4-bit terkuantisasi tersebut."],"metadata":{"id":"qT9gRdVa1pro"}},{"cell_type":"code","source":["# Konfigurasi\n","selected_model = \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\" # @param [\"unsloth/mistral-7b-v0.3\", \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\", \"unsloth/llama-3-8b-bnb-4bit\", \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\", \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\", \"Yellow-AI-NLP/komodo-7b-base\"]\n","max_seq_length = 2048  # @param {type:\"slider\", min:512, max:8192, step:256}\n","load_in_4bit = True  # @param {type:\"boolean\"}\n","dtype = None  # @param [\"None\", \"float16\", \"bfloat16\", \"float32\"] {type:\"raw\"}\n","HuggingFace_token = \"hf_...\"  # @param {type:\"string\"}"],"metadata":{"id":"Q2A22z_g1ZEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = selected_model,\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    token = HuggingFace_token,\n",")"],"metadata":{"id":"QmUBVEnvCDJv","outputId":"34a9e1c2-66ca-4506-d5e3-e0fabd6604bc","execution":{"iopub.status.busy":"2025-05-19T16:44:23.641832Z","iopub.execute_input":"2025-05-19T16:44:23.642088Z","iopub.status.idle":"2025-05-19T16:46:22.233909Z","shell.execute_reply.started":"2025-05-19T16:44:23.642062Z","shell.execute_reply":"2025-05-19T16:46:22.233135Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.5.6: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.096 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"execution_count":null},{"cell_type":"markdown","source":["## Penerapan LoRA"],"metadata":{"id":"V2_sikdA2wgf"}},{"cell_type":"markdown","source":["`FastLanguageModel.get_peft_model` dari Unsloth untuk menerapkan **fine-tuning efisien dengan LoRA (Low-Rank Adaptation)** pada model LLM.\n","\n","* `model`: Model dasar 4-bit yang akan ditambahkan adapter LoRA.\n","* `r=16`: Rank LoRA adapter, menentukan kapasitas adaptasi.\n","* `target_modules`: Layer transformer tempat LoRA disuntikkan (proyeksi query, key, value, output, dan FFN).\n","* `lora_alpha=16`: Faktor penskalaan LoRA.\n","* `lora_dropout=0`: Tidak ada dropout, dioptimalkan oleh Unsloth.\n","* `bias=\"none\"`: Tidak menambahkan bias, untuk efisiensi.\n","* `use_gradient_checkpointing=\"unsloth\"`: Hemat memori saat training input panjang.\n","* `random_state=3407`: Seed untuk reproduktibilitas.\n","* `use_rslora=False`, `loftq_config=None`: Tidak menggunakan varian tambahan LoRA/quant.\n","\n"],"metadata":{"id":"SXd9bTZd1aaL"}},{"cell_type":"code","source":["r = 16  # @param {type:\"slider\", min:4, max:128, step:4}\n","lora_alpha = 16  # @param {type:\"slider\", min:8, max:128, step:8}\n","lora_dropout = 0.0  # @param {type:\"slider\", min:0.0, max:0.5, step:0.05}\n","bias = \"none\"  # @param [\"none\", \"all\", \"lora_only\"]\n","use_gradient_checkpointing = \"unsloth\"  # @param [\"unsloth\", \"torch\", \"none\"]\n","random_state = 3407  # @param {type:\"number\"}\n","use_rslora = False  # @param {type:\"boolean\"}\n","loftq_config = None  # @param [\"None\"] {type:\"raw\"}\n","\n","# === Apply LoRA ===\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = r,\n","    target_modules = [\n","        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","        \"gate_proj\", \"up_proj\", \"down_proj\"\n","    ],\n","    lora_alpha = lora_alpha,\n","    lora_dropout = lora_dropout,\n","    bias = bias,\n","    use_gradient_checkpointing = use_gradient_checkpointing,\n","    random_state = random_state,\n","    use_rslora = use_rslora,\n","    loftq_config = None if loftq_config == \"None\" else loftq_config,\n",")\n"],"metadata":{"id":"6bZsfBuZDeCL","execution":{"iopub.status.busy":"2025-05-19T16:47:11.307479Z","iopub.execute_input":"2025-05-19T16:47:11.308201Z","iopub.status.idle":"2025-05-19T16:47:17.650922Z","shell.execute_reply.started":"2025-05-19T16:47:11.308179Z","shell.execute_reply":"2025-05-19T16:47:17.650137Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## Data preparation sebelum Training\n"],"metadata":{"id":"vITh0KVJ10qX"}},{"cell_type":"markdown","source":["### Downloa Data Train\n","\n","Data hasil dari preprocessing sebelumnya kami simpan dalam platform Hugging Face agar mempermudah dalam dowload Dataset"],"metadata":{"id":"NRwQOAEK3ISI"}},{"cell_type":"code","source":["dataset = load_dataset(\"farwew/DoctorsAnswerTextDataset-in-Indonesian\", split = \"train\")"],"metadata":{"id":"qfRQ-0AF3K92"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Data Formatting"],"metadata":{"id":"rhem-LoJ32Hs"}},{"cell_type":"markdown","source":["Pada tahap ini, dilakukan proses **formatting data** untuk pelatihan model bahasa berbasis instruksi. Dataset yang berisi pasangan *input* dan *output* diubah ke dalam format **Alpaca-style prompt** yang terdiri dari instruksi, konteks, dan respons. Tujuannya adalah agar model dapat belajar merespons pertanyaan medis dalam bentuk dialog yang konsisten dan mudah dipahami.\n","\n","Langkah-langkah proses:\n","\n","1. **Template Prompt:**\n","   Dibuat template teks (`alpaca_prompt`) dengan struktur sebagai berikut:\n","\n","   * **Instruction:** Petunjuk untuk menjawab pertanyaan medis dengan jelas dan informatif.\n","   * **Input:** Konteks atau pertanyaan dari pengguna.\n","   * **Response:** Jawaban yang diharapkan dari model.\n","\n","2. **Penambahan EOS Token:**\n","   Ditambahkan `EOS_TOKEN` (End-of-Sequence) pada akhir setiap prompt agar model mengetahui batas akhir output saat pelatihan maupun inferensi.\n","\n","3. **Fungsi Format Prompt:**\n","   Fungsi `formatting_prompts_func` menggabungkan input dan output dari dataset ke dalam template `alpaca_prompt`, lalu menghasilkan list teks terformat dalam kolom `\"text\"`.\n","\n","4. **Penerapan ke Dataset:**\n","   Fungsi ini diaplikasikan ke seluruh dataset menggunakan `map()` dari `datasets`, menghasilkan dataset yang siap digunakan untuk proses fine-tuning dengan format instruksi yang konsisten.\n","\n","Hasil akhirnya adalah dataset dalam bentuk teks terstruktur yang sesuai dengan format pelatihan model instruksi seperti Alpaca dan LoRA, sehingga model dapat belajar memberi respons dengan gaya dialog (conversation).\n"],"metadata":{"id":"QsV6EsvN34D2"}},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","\n","EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    inputs = examples[\"input\"]\n","    outputs = examples[\"output\"]\n","    texts = []\n","    for input_text, output_text in zip(inputs, outputs):\n","        text = alpaca_prompt.format(input_text, output_text) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\": texts }\n","pass\n","\n","from datasets import load_dataset\n","dataset = dataset.map(formatting_prompts_func, batched = True,)"],"metadata":{"id":"LjY75GoYUCB8","outputId":"bbfc90a0-b4eb-4fa9-cee8-5eb2f4dd8420","execution":{"iopub.status.busy":"2025-05-19T16:47:33.936443Z","iopub.execute_input":"2025-05-19T16:47:33.937160Z","iopub.status.idle":"2025-05-19T16:47:40.269174Z","shell.execute_reply.started":"2025-05-19T16:47:33.937135Z","shell.execute_reply":"2025-05-19T16:47:40.268259Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stderr","text":["Generating train split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19845/19845 [00:00<00:00, 77215.47 examples/s]\n","Generating test split: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1048/1048 [00:00<00:00, 48737.45 examples/s]\n","Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19845/19845 [00:00<00:00, 42664.76 examples/s]\n"]}],"execution_count":null},{"cell_type":"markdown","source":["## Konfigurasi Training\n","\n","\n","Pada bagian ini, dilakukan inisialisasi dan konfigurasi `trainer` untuk fine-tuning model LLM  menggunakan `SFTTrainer` dari library trl.\n","\n","Di sini, ditentukan model yang akan dipilih unutk pelatihan (model), tokenizer yang dipakai , data yang akan digunakan untuk training , serta berbagai parameter pelatihan yang mendetail melalui objek TrainingArguments.\n","\n"," Pengaturan ini mencakup hal-hal seperti ukuran data yang diproses per langkah pelatihan `(steps)` `(per_device_train_batch_size dan gradient_accumulation_steps)`, warmup_steps, Jumlah epoch dalam pelatihan `(num_train_epochs)`, `learning_rate`,  optimizer yang digunakan `(optim)`.\n","\n","Singkatnya, pada bagian ini adalah tahapan penyiapan lengkap enviroment dan pengaturan yang akan digunakan untuk menjalankan proses fine-tuning model pada data yang telah disiapkan sebelumnya."],"metadata":{"id":"idAEIeSQ3xdS"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8c30da0756384afe8dc7d83df5b6f4fb","931a9b13e2cb47bcb21e90691198da86","5ebc8ca6644f43c39edb51fd826d6e1c","08af40b73f204201a3d3e79811b2ba8a","19159e2671d54cd192e691bd54e9d967","4eeba4a0f0884ae796c8415af92a19e5","30208c9dd4cb49dabf23223c352ffe2a","5585c2c5e36846f3b87e59ddaf6ac739","39eb8f97b0be49379f6b1715a6f0c444","fd0fd4c03d194a779bbdd56527a72b67","c08eb8449d964122a1584194922233d5"]},"outputId":"8d1bcf25-25ae-4390-e301-f1bfb0d42f28","id":"UD4obgZRYqkF"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/19845 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c30da0756384afe8dc7d83df5b6f4fb"}},"metadata":{}}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","per_device_train_batch_size = 8  # @param {type:\"slider\", min:1, max:64, step:1}\n","gradient_accumulation_steps = 4  # @param {type:\"slider\", min:1, max:32, step:1}\n","num_train_epochs = 1  # @param {type:\"slider\", min:1, max:10, step:1}\n","learning_rate = 2e-4  # @param {type:\"number\"}\n","warmup_steps = 5  # @param {type:\"number\"}\n","logging_steps = 1  # @param {type:\"number\"}\n","weight_decay = 0.01  # @param {type:\"number\"}\n","lr_scheduler_type = \"linear\"  # @param [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\", \"constant_with_warmup\"]\n","optim = \"adamw_8bit\"  # @param [\"adamw_8bit\", \"adamw_torch\", \"adamw_hf\", \"adafactor\"]\n","packing = False  # @param {type:\"boolean\"}\n","output_dir = \"outputs\"  # @param {type:\"string\"}\n","report_to = \"wandb\"  # @param [\"wandb\", \"tensorboard\", \"none\"] {type:\"raw\"}\n","seed = 3407  # @param {type:\"number\"}\n","\n","# === Trainer Setup ===\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = packing,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = per_device_train_batch_size,\n","        gradient_accumulation_steps = gradient_accumulation_steps,\n","        warmup_steps = warmup_steps,\n","        num_train_epochs = num_train_epochs,\n","        learning_rate = learning_rate,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        logging_steps = logging_steps,\n","        optim = optim,\n","        weight_decay = weight_decay,\n","        lr_scheduler_type = lr_scheduler_type,\n","        seed = seed,\n","        output_dir = output_dir,\n","        report_to = report_to,\n","        # project = \"FP-NLP\"\n","    ),\n",")\n"]},{"cell_type":"code","source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"],"metadata":{"id":"2ejIt2xSNKKp","cellView":"form","outputId":"382983e8-8f66-427a-ae8f-024b0f07c3c0","execution":{"iopub.status.busy":"2025-05-19T16:54:08.267689Z","iopub.execute_input":"2025-05-19T16:54:08.268002Z","iopub.status.idle":"2025-05-19T16:54:08.274041Z","shell.execute_reply.started":"2025-05-19T16:54:08.267977Z","shell.execute_reply":"2025-05-19T16:54:08.273159Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU = NVIDIA H100 80GB HBM3. Max memory = 79.096 GB.\n","7.625 GB of memory reserved.\n"]}],"execution_count":null},{"cell_type":"markdown","source":["## Memulai Training"],"metadata":{"id":"n9WniMXRZdIw"}},{"cell_type":"markdown","source":["Pada bagian ini, dilakukan eksekusi proses fine-tuning model.\n","\n","Kode  **trainer.train()** memanggil metode **train()** dari objek trainer yang sudah dikonfigurasi sebelumnya. Ini akan  memulai training LLM menggunakan dataset dan parameter yang telah ditentukan dalam objek TrainingArguments sebelumnya\n","\n","\n","Selama proses ini, model akan belajar dari data pelatihan, menyesuaikan bobotnya melalui backpropagation dan optimisasi untuk meningkatkan kemampuannya dalam menjawab pertanyaan medis sesuai dengan format instruksi yang diinginkan.\n","\n","Output dari proses pelatihan, seperti loss dan metrik lainnya, akan disimpan dalam variabel trainer_stats.\n","\n","\n","Setelah ini selesai, model Anda akan menjadi model yang sudah di-fine-tuning dan siap untuk digunakan dalam inferensi (menjawab pertanyaan baru)."],"metadata":{"id":"WcPFLxL5Zi0J"}},{"cell_type":"code","source":["trainer_stats = trainer.train()"],"metadata":{"id":"yqxqAZ7KJ4oL","outputId":"23534e40-ac99-41e7-a622-ab1c6c7f32be","execution":{"iopub.status.busy":"2025-05-19T16:54:13.069387Z","iopub.execute_input":"2025-05-19T16:54:13.070180Z","execution_failed":"2025-05-19T17:07:11.455Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":1000}},"outputs":[{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 19,845 | Num Epochs = 1 | Total steps = 620\n","O^O/ \\_/ \\    Batch size per device = 8 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32\n"," \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"]},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='620' max='620' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [620/620 31:00, Epoch 0/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.948400</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>2.062900</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>2.027800</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>1.961200</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>1.951000</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>1.818100</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>1.741500</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>1.631500</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>1.637800</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>1.593300</td>\n","    </tr>\n","    <tr>\n","      <td>11</td>\n","      <td>1.574400</td>\n","    </tr>\n","    <tr>\n","      <td>12</td>\n","      <td>1.555800</td>\n","    </tr>\n","    <tr>\n","      <td>13</td>\n","      <td>1.522900</td>\n","    </tr>\n","    <tr>\n","      <td>14</td>\n","      <td>1.514900</td>\n","    </tr>\n","    <tr>\n","      <td>15</td>\n","      <td>1.536200</td>\n","    </tr>\n","    <tr>\n","      <td>16</td>\n","      <td>1.493600</td>\n","    </tr>\n","    <tr>\n","      <td>17</td>\n","      <td>1.437600</td>\n","    </tr>\n","    <tr>\n","      <td>18</td>\n","      <td>1.433100</td>\n","    </tr>\n","    <tr>\n","      <td>19</td>\n","      <td>1.475500</td>\n","    </tr>\n","    <tr>\n","      <td>20</td>\n","      <td>1.437600</td>\n","    </tr>\n","    <tr>\n","      <td>21</td>\n","      <td>1.475900</td>\n","    </tr>\n","    <tr>\n","      <td>22</td>\n","      <td>1.474800</td>\n","    </tr>\n","    <tr>\n","      <td>23</td>\n","      <td>1.511900</td>\n","    </tr>\n","    <tr>\n","      <td>24</td>\n","      <td>1.463000</td>\n","    </tr>\n","    <tr>\n","      <td>25</td>\n","      <td>1.478300</td>\n","    </tr>\n","    <tr>\n","      <td>26</td>\n","      <td>1.429100</td>\n","    </tr>\n","    <tr>\n","      <td>27</td>\n","      <td>1.424500</td>\n","    </tr>\n","    <tr>\n","      <td>28</td>\n","      <td>1.443700</td>\n","    </tr>\n","    <tr>\n","      <td>29</td>\n","      <td>1.350500</td>\n","    </tr>\n","    <tr>\n","      <td>30</td>\n","      <td>1.435000</td>\n","    </tr>\n","    <tr>\n","      <td>31</td>\n","      <td>1.446900</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>1.447400</td>\n","    </tr>\n","    <tr>\n","      <td>33</td>\n","      <td>1.398900</td>\n","    </tr>\n","    <tr>\n","      <td>34</td>\n","      <td>1.356200</td>\n","    </tr>\n","    <tr>\n","      <td>35</td>\n","      <td>1.363700</td>\n","    </tr>\n","    <tr>\n","      <td>36</td>\n","      <td>1.374900</td>\n","    </tr>\n","    <tr>\n","      <td>37</td>\n","      <td>1.412900</td>\n","    </tr>\n","    <tr>\n","      <td>38</td>\n","      <td>1.327900</td>\n","    </tr>\n","    <tr>\n","      <td>39</td>\n","      <td>1.357700</td>\n","    </tr>\n","    <tr>\n","      <td>40</td>\n","      <td>1.376400</td>\n","    </tr>\n","    <tr>\n","      <td>41</td>\n","      <td>1.364500</td>\n","    </tr>\n","    <tr>\n","      <td>42</td>\n","      <td>1.364800</td>\n","    </tr>\n","    <tr>\n","      <td>43</td>\n","      <td>1.416700</td>\n","    </tr>\n","    <tr>\n","      <td>44</td>\n","      <td>1.361900</td>\n","    </tr>\n","    <tr>\n","      <td>45</td>\n","      <td>1.377400</td>\n","    </tr>\n","    <tr>\n","      <td>46</td>\n","      <td>1.381200</td>\n","    </tr>\n","    <tr>\n","      <td>47</td>\n","      <td>1.352600</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>1.279400</td>\n","    </tr>\n","    <tr>\n","      <td>49</td>\n","      <td>1.316300</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.364100</td>\n","    </tr>\n","    <tr>\n","      <td>51</td>\n","      <td>1.354400</td>\n","    </tr>\n","    <tr>\n","      <td>52</td>\n","      <td>1.396600</td>\n","    </tr>\n","    <tr>\n","      <td>53</td>\n","      <td>1.344500</td>\n","    </tr>\n","    <tr>\n","      <td>54</td>\n","      <td>1.405900</td>\n","    </tr>\n","    <tr>\n","      <td>55</td>\n","      <td>1.347400</td>\n","    </tr>\n","    <tr>\n","      <td>56</td>\n","      <td>1.435500</td>\n","    </tr>\n","    <tr>\n","      <td>57</td>\n","      <td>1.441600</td>\n","    </tr>\n","    <tr>\n","      <td>58</td>\n","      <td>1.341900</td>\n","    </tr>\n","    <tr>\n","      <td>59</td>\n","      <td>1.316900</td>\n","    </tr>\n","    <tr>\n","      <td>60</td>\n","      <td>1.381800</td>\n","    </tr>\n","    <tr>\n","      <td>61</td>\n","      <td>1.365900</td>\n","    </tr>\n","    <tr>\n","      <td>62</td>\n","      <td>1.386400</td>\n","    </tr>\n","    <tr>\n","      <td>63</td>\n","      <td>1.333500</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>1.370300</td>\n","    </tr>\n","    <tr>\n","      <td>65</td>\n","      <td>1.374300</td>\n","    </tr>\n","    <tr>\n","      <td>66</td>\n","      <td>1.304400</td>\n","    </tr>\n","    <tr>\n","      <td>67</td>\n","      <td>1.379600</td>\n","    </tr>\n","    <tr>\n","      <td>68</td>\n","      <td>1.384500</td>\n","    </tr>\n","    <tr>\n","      <td>69</td>\n","      <td>1.309400</td>\n","    </tr>\n","    <tr>\n","      <td>70</td>\n","      <td>1.350900</td>\n","    </tr>\n","    <tr>\n","      <td>71</td>\n","      <td>1.364400</td>\n","    </tr>\n","    <tr>\n","      <td>72</td>\n","      <td>1.293400</td>\n","    </tr>\n","    <tr>\n","      <td>73</td>\n","      <td>1.330100</td>\n","    </tr>\n","    <tr>\n","      <td>74</td>\n","      <td>1.349100</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.341300</td>\n","    </tr>\n","    <tr>\n","      <td>76</td>\n","      <td>1.403800</td>\n","    </tr>\n","    <tr>\n","      <td>77</td>\n","      <td>1.262000</td>\n","    </tr>\n","    <tr>\n","      <td>78</td>\n","      <td>1.327900</td>\n","    </tr>\n","    <tr>\n","      <td>79</td>\n","      <td>1.420400</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>1.415600</td>\n","    </tr>\n","    <tr>\n","      <td>81</td>\n","      <td>1.298600</td>\n","    </tr>\n","    <tr>\n","      <td>82</td>\n","      <td>1.370700</td>\n","    </tr>\n","    <tr>\n","      <td>83</td>\n","      <td>1.315700</td>\n","    </tr>\n","    <tr>\n","      <td>84</td>\n","      <td>1.245900</td>\n","    </tr>\n","    <tr>\n","      <td>85</td>\n","      <td>1.325500</td>\n","    </tr>\n","    <tr>\n","      <td>86</td>\n","      <td>1.332600</td>\n","    </tr>\n","    <tr>\n","      <td>87</td>\n","      <td>1.333400</td>\n","    </tr>\n","    <tr>\n","      <td>88</td>\n","      <td>1.400400</td>\n","    </tr>\n","    <tr>\n","      <td>89</td>\n","      <td>1.322900</td>\n","    </tr>\n","    <tr>\n","      <td>90</td>\n","      <td>1.333800</td>\n","    </tr>\n","    <tr>\n","      <td>91</td>\n","      <td>1.291400</td>\n","    </tr>\n","    <tr>\n","      <td>92</td>\n","      <td>1.297600</td>\n","    </tr>\n","    <tr>\n","      <td>93</td>\n","      <td>1.310900</td>\n","    </tr>\n","    <tr>\n","      <td>94</td>\n","      <td>1.340500</td>\n","    </tr>\n","    <tr>\n","      <td>95</td>\n","      <td>1.332300</td>\n","    </tr>\n","    <tr>\n","      <td>96</td>\n","      <td>1.345100</td>\n","    </tr>\n","    <tr>\n","      <td>97</td>\n","      <td>1.331200</td>\n","    </tr>\n","    <tr>\n","      <td>98</td>\n","      <td>1.315800</td>\n","    </tr>\n","    <tr>\n","      <td>99</td>\n","      <td>1.294800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.303600</td>\n","    </tr>\n","    <tr>\n","      <td>101</td>\n","      <td>1.242400</td>\n","    </tr>\n","    <tr>\n","      <td>102</td>\n","      <td>1.325700</td>\n","    </tr>\n","    <tr>\n","      <td>103</td>\n","      <td>1.333600</td>\n","    </tr>\n","    <tr>\n","      <td>104</td>\n","      <td>1.284500</td>\n","    </tr>\n","    <tr>\n","      <td>105</td>\n","      <td>1.337300</td>\n","    </tr>\n","    <tr>\n","      <td>106</td>\n","      <td>1.304600</td>\n","    </tr>\n","    <tr>\n","      <td>107</td>\n","      <td>1.286200</td>\n","    </tr>\n","    <tr>\n","      <td>108</td>\n","      <td>1.344200</td>\n","    </tr>\n","    <tr>\n","      <td>109</td>\n","      <td>1.330300</td>\n","    </tr>\n","    <tr>\n","      <td>110</td>\n","      <td>1.362100</td>\n","    </tr>\n","    <tr>\n","      <td>111</td>\n","      <td>1.326700</td>\n","    </tr>\n","    <tr>\n","      <td>112</td>\n","      <td>1.309400</td>\n","    </tr>\n","    <tr>\n","      <td>113</td>\n","      <td>1.346600</td>\n","    </tr>\n","    <tr>\n","      <td>114</td>\n","      <td>1.270900</td>\n","    </tr>\n","    <tr>\n","      <td>115</td>\n","      <td>1.308100</td>\n","    </tr>\n","    <tr>\n","      <td>116</td>\n","      <td>1.321600</td>\n","    </tr>\n","    <tr>\n","      <td>117</td>\n","      <td>1.245800</td>\n","    </tr>\n","    <tr>\n","      <td>118</td>\n","      <td>1.336500</td>\n","    </tr>\n","    <tr>\n","      <td>119</td>\n","      <td>1.291400</td>\n","    </tr>\n","    <tr>\n","      <td>120</td>\n","      <td>1.291800</td>\n","    </tr>\n","    <tr>\n","      <td>121</td>\n","      <td>1.302300</td>\n","    </tr>\n","    <tr>\n","      <td>122</td>\n","      <td>1.313000</td>\n","    </tr>\n","    <tr>\n","      <td>123</td>\n","      <td>1.229700</td>\n","    </tr>\n","    <tr>\n","      <td>124</td>\n","      <td>1.357700</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>1.271600</td>\n","    </tr>\n","    <tr>\n","      <td>126</td>\n","      <td>1.271400</td>\n","    </tr>\n","    <tr>\n","      <td>127</td>\n","      <td>1.189700</td>\n","    </tr>\n","    <tr>\n","      <td>128</td>\n","      <td>1.262900</td>\n","    </tr>\n","    <tr>\n","      <td>129</td>\n","      <td>1.279900</td>\n","    </tr>\n","    <tr>\n","      <td>130</td>\n","      <td>1.274500</td>\n","    </tr>\n","    <tr>\n","      <td>131</td>\n","      <td>1.310500</td>\n","    </tr>\n","    <tr>\n","      <td>132</td>\n","      <td>1.303300</td>\n","    </tr>\n","    <tr>\n","      <td>133</td>\n","      <td>1.258500</td>\n","    </tr>\n","    <tr>\n","      <td>134</td>\n","      <td>1.234300</td>\n","    </tr>\n","    <tr>\n","      <td>135</td>\n","      <td>1.257200</td>\n","    </tr>\n","    <tr>\n","      <td>136</td>\n","      <td>1.266300</td>\n","    </tr>\n","    <tr>\n","      <td>137</td>\n","      <td>1.264000</td>\n","    </tr>\n","    <tr>\n","      <td>138</td>\n","      <td>1.372900</td>\n","    </tr>\n","    <tr>\n","      <td>139</td>\n","      <td>1.249300</td>\n","    </tr>\n","    <tr>\n","      <td>140</td>\n","      <td>1.266200</td>\n","    </tr>\n","    <tr>\n","      <td>141</td>\n","      <td>1.275700</td>\n","    </tr>\n","    <tr>\n","      <td>142</td>\n","      <td>1.270600</td>\n","    </tr>\n","    <tr>\n","      <td>143</td>\n","      <td>1.294900</td>\n","    </tr>\n","    <tr>\n","      <td>144</td>\n","      <td>1.268700</td>\n","    </tr>\n","    <tr>\n","      <td>145</td>\n","      <td>1.314200</td>\n","    </tr>\n","    <tr>\n","      <td>146</td>\n","      <td>1.241900</td>\n","    </tr>\n","    <tr>\n","      <td>147</td>\n","      <td>1.261400</td>\n","    </tr>\n","    <tr>\n","      <td>148</td>\n","      <td>1.392000</td>\n","    </tr>\n","    <tr>\n","      <td>149</td>\n","      <td>1.297200</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>1.363800</td>\n","    </tr>\n","    <tr>\n","      <td>151</td>\n","      <td>1.335500</td>\n","    </tr>\n","    <tr>\n","      <td>152</td>\n","      <td>1.282500</td>\n","    </tr>\n","    <tr>\n","      <td>153</td>\n","      <td>1.334900</td>\n","    </tr>\n","    <tr>\n","      <td>154</td>\n","      <td>1.195000</td>\n","    </tr>\n","    <tr>\n","      <td>155</td>\n","      <td>1.263500</td>\n","    </tr>\n","    <tr>\n","      <td>156</td>\n","      <td>1.319100</td>\n","    </tr>\n","    <tr>\n","      <td>157</td>\n","      <td>1.234300</td>\n","    </tr>\n","    <tr>\n","      <td>158</td>\n","      <td>1.254200</td>\n","    </tr>\n","    <tr>\n","      <td>159</td>\n","      <td>1.284000</td>\n","    </tr>\n","    <tr>\n","      <td>160</td>\n","      <td>1.301600</td>\n","    </tr>\n","    <tr>\n","      <td>161</td>\n","      <td>1.228400</td>\n","    </tr>\n","    <tr>\n","      <td>162</td>\n","      <td>1.318000</td>\n","    </tr>\n","    <tr>\n","      <td>163</td>\n","      <td>1.294300</td>\n","    </tr>\n","    <tr>\n","      <td>164</td>\n","      <td>1.291800</td>\n","    </tr>\n","    <tr>\n","      <td>165</td>\n","      <td>1.318800</td>\n","    </tr>\n","    <tr>\n","      <td>166</td>\n","      <td>1.279900</td>\n","    </tr>\n","    <tr>\n","      <td>167</td>\n","      <td>1.359900</td>\n","    </tr>\n","    <tr>\n","      <td>168</td>\n","      <td>1.239800</td>\n","    </tr>\n","    <tr>\n","      <td>169</td>\n","      <td>1.240600</td>\n","    </tr>\n","    <tr>\n","      <td>170</td>\n","      <td>1.234200</td>\n","    </tr>\n","    <tr>\n","      <td>171</td>\n","      <td>1.288300</td>\n","    </tr>\n","    <tr>\n","      <td>172</td>\n","      <td>1.302700</td>\n","    </tr>\n","    <tr>\n","      <td>173</td>\n","      <td>1.296900</td>\n","    </tr>\n","    <tr>\n","      <td>174</td>\n","      <td>1.234200</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>1.295800</td>\n","    </tr>\n","    <tr>\n","      <td>176</td>\n","      <td>1.253600</td>\n","    </tr>\n","    <tr>\n","      <td>177</td>\n","      <td>1.206600</td>\n","    </tr>\n","    <tr>\n","      <td>178</td>\n","      <td>1.259700</td>\n","    </tr>\n","    <tr>\n","      <td>179</td>\n","      <td>1.250000</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>1.233200</td>\n","    </tr>\n","    <tr>\n","      <td>181</td>\n","      <td>1.197400</td>\n","    </tr>\n","    <tr>\n","      <td>182</td>\n","      <td>1.247400</td>\n","    </tr>\n","    <tr>\n","      <td>183</td>\n","      <td>1.250100</td>\n","    </tr>\n","    <tr>\n","      <td>184</td>\n","      <td>1.271800</td>\n","    </tr>\n","    <tr>\n","      <td>185</td>\n","      <td>1.290400</td>\n","    </tr>\n","    <tr>\n","      <td>186</td>\n","      <td>1.242800</td>\n","    </tr>\n","    <tr>\n","      <td>187</td>\n","      <td>1.257000</td>\n","    </tr>\n","    <tr>\n","      <td>188</td>\n","      <td>1.214600</td>\n","    </tr>\n","    <tr>\n","      <td>189</td>\n","      <td>1.252700</td>\n","    </tr>\n","    <tr>\n","      <td>190</td>\n","      <td>1.250400</td>\n","    </tr>\n","    <tr>\n","      <td>191</td>\n","      <td>1.246400</td>\n","    </tr>\n","    <tr>\n","      <td>192</td>\n","      <td>1.309300</td>\n","    </tr>\n","    <tr>\n","      <td>193</td>\n","      <td>1.144100</td>\n","    </tr>\n","    <tr>\n","      <td>194</td>\n","      <td>1.227400</td>\n","    </tr>\n","    <tr>\n","      <td>195</td>\n","      <td>1.299000</td>\n","    </tr>\n","    <tr>\n","      <td>196</td>\n","      <td>1.221000</td>\n","    </tr>\n","    <tr>\n","      <td>197</td>\n","      <td>1.282200</td>\n","    </tr>\n","    <tr>\n","      <td>198</td>\n","      <td>1.238800</td>\n","    </tr>\n","    <tr>\n","      <td>199</td>\n","      <td>1.220700</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>1.285100</td>\n","    </tr>\n","    <tr>\n","      <td>201</td>\n","      <td>1.217100</td>\n","    </tr>\n","    <tr>\n","      <td>202</td>\n","      <td>1.303400</td>\n","    </tr>\n","    <tr>\n","      <td>203</td>\n","      <td>1.293100</td>\n","    </tr>\n","    <tr>\n","      <td>204</td>\n","      <td>1.222600</td>\n","    </tr>\n","    <tr>\n","      <td>205</td>\n","      <td>1.210600</td>\n","    </tr>\n","    <tr>\n","      <td>206</td>\n","      <td>1.274800</td>\n","    </tr>\n","    <tr>\n","      <td>207</td>\n","      <td>1.245700</td>\n","    </tr>\n","    <tr>\n","      <td>208</td>\n","      <td>1.280300</td>\n","    </tr>\n","    <tr>\n","      <td>209</td>\n","      <td>1.212300</td>\n","    </tr>\n","    <tr>\n","      <td>210</td>\n","      <td>1.202200</td>\n","    </tr>\n","    <tr>\n","      <td>211</td>\n","      <td>1.208200</td>\n","    </tr>\n","    <tr>\n","      <td>212</td>\n","      <td>1.181600</td>\n","    </tr>\n","    <tr>\n","      <td>213</td>\n","      <td>1.203200</td>\n","    </tr>\n","    <tr>\n","      <td>214</td>\n","      <td>1.234500</td>\n","    </tr>\n","    <tr>\n","      <td>215</td>\n","      <td>1.272000</td>\n","    </tr>\n","    <tr>\n","      <td>216</td>\n","      <td>1.230700</td>\n","    </tr>\n","    <tr>\n","      <td>217</td>\n","      <td>1.273400</td>\n","    </tr>\n","    <tr>\n","      <td>218</td>\n","      <td>1.231300</td>\n","    </tr>\n","    <tr>\n","      <td>219</td>\n","      <td>1.305200</td>\n","    </tr>\n","    <tr>\n","      <td>220</td>\n","      <td>1.214100</td>\n","    </tr>\n","    <tr>\n","      <td>221</td>\n","      <td>1.301500</td>\n","    </tr>\n","    <tr>\n","      <td>222</td>\n","      <td>1.121400</td>\n","    </tr>\n","    <tr>\n","      <td>223</td>\n","      <td>1.308000</td>\n","    </tr>\n","    <tr>\n","      <td>224</td>\n","      <td>1.246500</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>1.248000</td>\n","    </tr>\n","    <tr>\n","      <td>226</td>\n","      <td>1.273500</td>\n","    </tr>\n","    <tr>\n","      <td>227</td>\n","      <td>1.229000</td>\n","    </tr>\n","    <tr>\n","      <td>228</td>\n","      <td>1.202700</td>\n","    </tr>\n","    <tr>\n","      <td>229</td>\n","      <td>1.261600</td>\n","    </tr>\n","    <tr>\n","      <td>230</td>\n","      <td>1.195900</td>\n","    </tr>\n","    <tr>\n","      <td>231</td>\n","      <td>1.159300</td>\n","    </tr>\n","    <tr>\n","      <td>232</td>\n","      <td>1.172600</td>\n","    </tr>\n","    <tr>\n","      <td>233</td>\n","      <td>1.210100</td>\n","    </tr>\n","    <tr>\n","      <td>234</td>\n","      <td>1.292300</td>\n","    </tr>\n","    <tr>\n","      <td>235</td>\n","      <td>1.251300</td>\n","    </tr>\n","    <tr>\n","      <td>236</td>\n","      <td>1.232300</td>\n","    </tr>\n","    <tr>\n","      <td>237</td>\n","      <td>1.240600</td>\n","    </tr>\n","    <tr>\n","      <td>238</td>\n","      <td>1.233400</td>\n","    </tr>\n","    <tr>\n","      <td>239</td>\n","      <td>1.294400</td>\n","    </tr>\n","    <tr>\n","      <td>240</td>\n","      <td>1.181400</td>\n","    </tr>\n","    <tr>\n","      <td>241</td>\n","      <td>1.216400</td>\n","    </tr>\n","    <tr>\n","      <td>242</td>\n","      <td>1.203200</td>\n","    </tr>\n","    <tr>\n","      <td>243</td>\n","      <td>1.222400</td>\n","    </tr>\n","    <tr>\n","      <td>244</td>\n","      <td>1.259700</td>\n","    </tr>\n","    <tr>\n","      <td>245</td>\n","      <td>1.262400</td>\n","    </tr>\n","    <tr>\n","      <td>246</td>\n","      <td>1.277000</td>\n","    </tr>\n","    <tr>\n","      <td>247</td>\n","      <td>1.253900</td>\n","    </tr>\n","    <tr>\n","      <td>248</td>\n","      <td>1.107400</td>\n","    </tr>\n","    <tr>\n","      <td>249</td>\n","      <td>1.259500</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>1.184900</td>\n","    </tr>\n","    <tr>\n","      <td>251</td>\n","      <td>1.229400</td>\n","    </tr>\n","    <tr>\n","      <td>252</td>\n","      <td>1.171300</td>\n","    </tr>\n","    <tr>\n","      <td>253</td>\n","      <td>1.190900</td>\n","    </tr>\n","    <tr>\n","      <td>254</td>\n","      <td>1.229000</td>\n","    </tr>\n","    <tr>\n","      <td>255</td>\n","      <td>1.212700</td>\n","    </tr>\n","    <tr>\n","      <td>256</td>\n","      <td>1.178900</td>\n","    </tr>\n","    <tr>\n","      <td>257</td>\n","      <td>1.246000</td>\n","    </tr>\n","    <tr>\n","      <td>258</td>\n","      <td>1.218600</td>\n","    </tr>\n","    <tr>\n","      <td>259</td>\n","      <td>1.223000</td>\n","    </tr>\n","    <tr>\n","      <td>260</td>\n","      <td>1.206000</td>\n","    </tr>\n","    <tr>\n","      <td>261</td>\n","      <td>1.200800</td>\n","    </tr>\n","    <tr>\n","      <td>262</td>\n","      <td>1.206600</td>\n","    </tr>\n","    <tr>\n","      <td>263</td>\n","      <td>1.325000</td>\n","    </tr>\n","    <tr>\n","      <td>264</td>\n","      <td>1.292400</td>\n","    </tr>\n","    <tr>\n","      <td>265</td>\n","      <td>1.253100</td>\n","    </tr>\n","    <tr>\n","      <td>266</td>\n","      <td>1.271300</td>\n","    </tr>\n","    <tr>\n","      <td>267</td>\n","      <td>1.263600</td>\n","    </tr>\n","    <tr>\n","      <td>268</td>\n","      <td>1.233400</td>\n","    </tr>\n","    <tr>\n","      <td>269</td>\n","      <td>1.321200</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>1.169200</td>\n","    </tr>\n","    <tr>\n","      <td>271</td>\n","      <td>1.268300</td>\n","    </tr>\n","    <tr>\n","      <td>272</td>\n","      <td>1.241100</td>\n","    </tr>\n","    <tr>\n","      <td>273</td>\n","      <td>1.248300</td>\n","    </tr>\n","    <tr>\n","      <td>274</td>\n","      <td>1.193400</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>1.239200</td>\n","    </tr>\n","    <tr>\n","      <td>276</td>\n","      <td>1.278400</td>\n","    </tr>\n","    <tr>\n","      <td>277</td>\n","      <td>1.249400</td>\n","    </tr>\n","    <tr>\n","      <td>278</td>\n","      <td>1.367400</td>\n","    </tr>\n","    <tr>\n","      <td>279</td>\n","      <td>1.257400</td>\n","    </tr>\n","    <tr>\n","      <td>280</td>\n","      <td>1.239200</td>\n","    </tr>\n","    <tr>\n","      <td>281</td>\n","      <td>1.174600</td>\n","    </tr>\n","    <tr>\n","      <td>282</td>\n","      <td>1.301700</td>\n","    </tr>\n","    <tr>\n","      <td>283</td>\n","      <td>1.197600</td>\n","    </tr>\n","    <tr>\n","      <td>284</td>\n","      <td>1.131900</td>\n","    </tr>\n","    <tr>\n","      <td>285</td>\n","      <td>1.242500</td>\n","    </tr>\n","    <tr>\n","      <td>286</td>\n","      <td>1.233600</td>\n","    </tr>\n","    <tr>\n","      <td>287</td>\n","      <td>1.207900</td>\n","    </tr>\n","    <tr>\n","      <td>288</td>\n","      <td>1.223000</td>\n","    </tr>\n","    <tr>\n","      <td>289</td>\n","      <td>1.256200</td>\n","    </tr>\n","    <tr>\n","      <td>290</td>\n","      <td>1.225100</td>\n","    </tr>\n","    <tr>\n","      <td>291</td>\n","      <td>1.226000</td>\n","    </tr>\n","    <tr>\n","      <td>292</td>\n","      <td>1.179800</td>\n","    </tr>\n","    <tr>\n","      <td>293</td>\n","      <td>1.266300</td>\n","    </tr>\n","    <tr>\n","      <td>294</td>\n","      <td>1.164400</td>\n","    </tr>\n","    <tr>\n","      <td>295</td>\n","      <td>1.245800</td>\n","    </tr>\n","    <tr>\n","      <td>296</td>\n","      <td>1.255900</td>\n","    </tr>\n","    <tr>\n","      <td>297</td>\n","      <td>1.246000</td>\n","    </tr>\n","    <tr>\n","      <td>298</td>\n","      <td>1.263100</td>\n","    </tr>\n","    <tr>\n","      <td>299</td>\n","      <td>1.183000</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>1.197200</td>\n","    </tr>\n","    <tr>\n","      <td>301</td>\n","      <td>1.229300</td>\n","    </tr>\n","    <tr>\n","      <td>302</td>\n","      <td>1.225000</td>\n","    </tr>\n","    <tr>\n","      <td>303</td>\n","      <td>1.165300</td>\n","    </tr>\n","    <tr>\n","      <td>304</td>\n","      <td>1.193700</td>\n","    </tr>\n","    <tr>\n","      <td>305</td>\n","      <td>1.152800</td>\n","    </tr>\n","    <tr>\n","      <td>306</td>\n","      <td>1.177100</td>\n","    </tr>\n","    <tr>\n","      <td>307</td>\n","      <td>1.160900</td>\n","    </tr>\n","    <tr>\n","      <td>308</td>\n","      <td>1.243300</td>\n","    </tr>\n","    <tr>\n","      <td>309</td>\n","      <td>1.196400</td>\n","    </tr>\n","    <tr>\n","      <td>310</td>\n","      <td>1.200000</td>\n","    </tr>\n","    <tr>\n","      <td>311</td>\n","      <td>1.252100</td>\n","    </tr>\n","    <tr>\n","      <td>312</td>\n","      <td>1.252400</td>\n","    </tr>\n","    <tr>\n","      <td>313</td>\n","      <td>1.279800</td>\n","    </tr>\n","    <tr>\n","      <td>314</td>\n","      <td>1.249600</td>\n","    </tr>\n","    <tr>\n","      <td>315</td>\n","      <td>1.243800</td>\n","    </tr>\n","    <tr>\n","      <td>316</td>\n","      <td>1.209900</td>\n","    </tr>\n","    <tr>\n","      <td>317</td>\n","      <td>1.218000</td>\n","    </tr>\n","    <tr>\n","      <td>318</td>\n","      <td>1.106700</td>\n","    </tr>\n","    <tr>\n","      <td>319</td>\n","      <td>1.259600</td>\n","    </tr>\n","    <tr>\n","      <td>320</td>\n","      <td>1.274900</td>\n","    </tr>\n","    <tr>\n","      <td>321</td>\n","      <td>1.160100</td>\n","    </tr>\n","    <tr>\n","      <td>322</td>\n","      <td>1.230000</td>\n","    </tr>\n","    <tr>\n","      <td>323</td>\n","      <td>1.196200</td>\n","    </tr>\n","    <tr>\n","      <td>324</td>\n","      <td>1.254500</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>1.181500</td>\n","    </tr>\n","    <tr>\n","      <td>326</td>\n","      <td>1.233000</td>\n","    </tr>\n","    <tr>\n","      <td>327</td>\n","      <td>1.105200</td>\n","    </tr>\n","    <tr>\n","      <td>328</td>\n","      <td>1.191400</td>\n","    </tr>\n","    <tr>\n","      <td>329</td>\n","      <td>1.233100</td>\n","    </tr>\n","    <tr>\n","      <td>330</td>\n","      <td>1.262800</td>\n","    </tr>\n","    <tr>\n","      <td>331</td>\n","      <td>1.176900</td>\n","    </tr>\n","    <tr>\n","      <td>332</td>\n","      <td>1.203200</td>\n","    </tr>\n","    <tr>\n","      <td>333</td>\n","      <td>1.269100</td>\n","    </tr>\n","    <tr>\n","      <td>334</td>\n","      <td>1.210100</td>\n","    </tr>\n","    <tr>\n","      <td>335</td>\n","      <td>1.191500</td>\n","    </tr>\n","    <tr>\n","      <td>336</td>\n","      <td>1.201100</td>\n","    </tr>\n","    <tr>\n","      <td>337</td>\n","      <td>1.189000</td>\n","    </tr>\n","    <tr>\n","      <td>338</td>\n","      <td>1.215600</td>\n","    </tr>\n","    <tr>\n","      <td>339</td>\n","      <td>1.224200</td>\n","    </tr>\n","    <tr>\n","      <td>340</td>\n","      <td>1.175900</td>\n","    </tr>\n","    <tr>\n","      <td>341</td>\n","      <td>1.239600</td>\n","    </tr>\n","    <tr>\n","      <td>342</td>\n","      <td>1.250200</td>\n","    </tr>\n","    <tr>\n","      <td>343</td>\n","      <td>1.254300</td>\n","    </tr>\n","    <tr>\n","      <td>344</td>\n","      <td>1.222900</td>\n","    </tr>\n","    <tr>\n","      <td>345</td>\n","      <td>1.194200</td>\n","    </tr>\n","    <tr>\n","      <td>346</td>\n","      <td>1.097800</td>\n","    </tr>\n","    <tr>\n","      <td>347</td>\n","      <td>1.274100</td>\n","    </tr>\n","    <tr>\n","      <td>348</td>\n","      <td>1.133900</td>\n","    </tr>\n","    <tr>\n","      <td>349</td>\n","      <td>1.168700</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>1.240600</td>\n","    </tr>\n","    <tr>\n","      <td>351</td>\n","      <td>1.212000</td>\n","    </tr>\n","    <tr>\n","      <td>352</td>\n","      <td>1.150500</td>\n","    </tr>\n","    <tr>\n","      <td>353</td>\n","      <td>1.216300</td>\n","    </tr>\n","    <tr>\n","      <td>354</td>\n","      <td>1.131700</td>\n","    </tr>\n","    <tr>\n","      <td>355</td>\n","      <td>1.224200</td>\n","    </tr>\n","    <tr>\n","      <td>356</td>\n","      <td>1.178600</td>\n","    </tr>\n","    <tr>\n","      <td>357</td>\n","      <td>1.129500</td>\n","    </tr>\n","    <tr>\n","      <td>358</td>\n","      <td>1.190500</td>\n","    </tr>\n","    <tr>\n","      <td>359</td>\n","      <td>1.105400</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>1.220500</td>\n","    </tr>\n","    <tr>\n","      <td>361</td>\n","      <td>1.210600</td>\n","    </tr>\n","    <tr>\n","      <td>362</td>\n","      <td>1.171300</td>\n","    </tr>\n","    <tr>\n","      <td>363</td>\n","      <td>1.108900</td>\n","    </tr>\n","    <tr>\n","      <td>364</td>\n","      <td>1.154700</td>\n","    </tr>\n","    <tr>\n","      <td>365</td>\n","      <td>1.292100</td>\n","    </tr>\n","    <tr>\n","      <td>366</td>\n","      <td>1.247000</td>\n","    </tr>\n","    <tr>\n","      <td>367</td>\n","      <td>1.211400</td>\n","    </tr>\n","    <tr>\n","      <td>368</td>\n","      <td>1.177900</td>\n","    </tr>\n","    <tr>\n","      <td>369</td>\n","      <td>1.109200</td>\n","    </tr>\n","    <tr>\n","      <td>370</td>\n","      <td>1.260300</td>\n","    </tr>\n","    <tr>\n","      <td>371</td>\n","      <td>1.231000</td>\n","    </tr>\n","    <tr>\n","      <td>372</td>\n","      <td>1.165800</td>\n","    </tr>\n","    <tr>\n","      <td>373</td>\n","      <td>1.231100</td>\n","    </tr>\n","    <tr>\n","      <td>374</td>\n","      <td>1.176500</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>1.250100</td>\n","    </tr>\n","    <tr>\n","      <td>376</td>\n","      <td>1.204900</td>\n","    </tr>\n","    <tr>\n","      <td>377</td>\n","      <td>1.239300</td>\n","    </tr>\n","    <tr>\n","      <td>378</td>\n","      <td>1.280900</td>\n","    </tr>\n","    <tr>\n","      <td>379</td>\n","      <td>1.207600</td>\n","    </tr>\n","    <tr>\n","      <td>380</td>\n","      <td>1.220200</td>\n","    </tr>\n","    <tr>\n","      <td>381</td>\n","      <td>1.108000</td>\n","    </tr>\n","    <tr>\n","      <td>382</td>\n","      <td>1.318900</td>\n","    </tr>\n","    <tr>\n","      <td>383</td>\n","      <td>1.148500</td>\n","    </tr>\n","    <tr>\n","      <td>384</td>\n","      <td>1.259400</td>\n","    </tr>\n","    <tr>\n","      <td>385</td>\n","      <td>1.223400</td>\n","    </tr>\n","    <tr>\n","      <td>386</td>\n","      <td>1.200400</td>\n","    </tr>\n","    <tr>\n","      <td>387</td>\n","      <td>1.173000</td>\n","    </tr>\n","    <tr>\n","      <td>388</td>\n","      <td>1.281100</td>\n","    </tr>\n","    <tr>\n","      <td>389</td>\n","      <td>1.272600</td>\n","    </tr>\n","    <tr>\n","      <td>390</td>\n","      <td>1.180400</td>\n","    </tr>\n","    <tr>\n","      <td>391</td>\n","      <td>1.257300</td>\n","    </tr>\n","    <tr>\n","      <td>392</td>\n","      <td>1.215900</td>\n","    </tr>\n","    <tr>\n","      <td>393</td>\n","      <td>1.213200</td>\n","    </tr>\n","    <tr>\n","      <td>394</td>\n","      <td>1.210900</td>\n","    </tr>\n","    <tr>\n","      <td>395</td>\n","      <td>1.200700</td>\n","    </tr>\n","    <tr>\n","      <td>396</td>\n","      <td>1.241400</td>\n","    </tr>\n","    <tr>\n","      <td>397</td>\n","      <td>1.175100</td>\n","    </tr>\n","    <tr>\n","      <td>398</td>\n","      <td>1.212300</td>\n","    </tr>\n","    <tr>\n","      <td>399</td>\n","      <td>1.260100</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>1.323800</td>\n","    </tr>\n","    <tr>\n","      <td>401</td>\n","      <td>1.284500</td>\n","    </tr>\n","    <tr>\n","      <td>402</td>\n","      <td>1.122400</td>\n","    </tr>\n","    <tr>\n","      <td>403</td>\n","      <td>1.176700</td>\n","    </tr>\n","    <tr>\n","      <td>404</td>\n","      <td>1.213200</td>\n","    </tr>\n","    <tr>\n","      <td>405</td>\n","      <td>1.232100</td>\n","    </tr>\n","    <tr>\n","      <td>406</td>\n","      <td>1.239700</td>\n","    </tr>\n","    <tr>\n","      <td>407</td>\n","      <td>1.217500</td>\n","    </tr>\n","    <tr>\n","      <td>408</td>\n","      <td>1.141700</td>\n","    </tr>\n","    <tr>\n","      <td>409</td>\n","      <td>1.145800</td>\n","    </tr>\n","    <tr>\n","      <td>410</td>\n","      <td>1.178500</td>\n","    </tr>\n","    <tr>\n","      <td>411</td>\n","      <td>1.218600</td>\n","    </tr>\n","    <tr>\n","      <td>412</td>\n","      <td>1.235200</td>\n","    </tr>\n","    <tr>\n","      <td>413</td>\n","      <td>1.238700</td>\n","    </tr>\n","    <tr>\n","      <td>414</td>\n","      <td>1.201700</td>\n","    </tr>\n","    <tr>\n","      <td>415</td>\n","      <td>1.153400</td>\n","    </tr>\n","    <tr>\n","      <td>416</td>\n","      <td>1.181700</td>\n","    </tr>\n","    <tr>\n","      <td>417</td>\n","      <td>1.280000</td>\n","    </tr>\n","    <tr>\n","      <td>418</td>\n","      <td>1.330500</td>\n","    </tr>\n","    <tr>\n","      <td>419</td>\n","      <td>1.236900</td>\n","    </tr>\n","    <tr>\n","      <td>420</td>\n","      <td>1.283500</td>\n","    </tr>\n","    <tr>\n","      <td>421</td>\n","      <td>1.203100</td>\n","    </tr>\n","    <tr>\n","      <td>422</td>\n","      <td>1.183200</td>\n","    </tr>\n","    <tr>\n","      <td>423</td>\n","      <td>1.174200</td>\n","    </tr>\n","    <tr>\n","      <td>424</td>\n","      <td>1.229000</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>1.212900</td>\n","    </tr>\n","    <tr>\n","      <td>426</td>\n","      <td>1.257400</td>\n","    </tr>\n","    <tr>\n","      <td>427</td>\n","      <td>1.231400</td>\n","    </tr>\n","    <tr>\n","      <td>428</td>\n","      <td>1.091800</td>\n","    </tr>\n","    <tr>\n","      <td>429</td>\n","      <td>1.192100</td>\n","    </tr>\n","    <tr>\n","      <td>430</td>\n","      <td>1.195200</td>\n","    </tr>\n","    <tr>\n","      <td>431</td>\n","      <td>1.143900</td>\n","    </tr>\n","    <tr>\n","      <td>432</td>\n","      <td>1.191800</td>\n","    </tr>\n","    <tr>\n","      <td>433</td>\n","      <td>1.173700</td>\n","    </tr>\n","    <tr>\n","      <td>434</td>\n","      <td>1.232500</td>\n","    </tr>\n","    <tr>\n","      <td>435</td>\n","      <td>1.179600</td>\n","    </tr>\n","    <tr>\n","      <td>436</td>\n","      <td>1.195500</td>\n","    </tr>\n","    <tr>\n","      <td>437</td>\n","      <td>1.242700</td>\n","    </tr>\n","    <tr>\n","      <td>438</td>\n","      <td>1.120400</td>\n","    </tr>\n","    <tr>\n","      <td>439</td>\n","      <td>1.197000</td>\n","    </tr>\n","    <tr>\n","      <td>440</td>\n","      <td>1.221500</td>\n","    </tr>\n","    <tr>\n","      <td>441</td>\n","      <td>1.205500</td>\n","    </tr>\n","    <tr>\n","      <td>442</td>\n","      <td>1.205100</td>\n","    </tr>\n","    <tr>\n","      <td>443</td>\n","      <td>1.151000</td>\n","    </tr>\n","    <tr>\n","      <td>444</td>\n","      <td>1.190000</td>\n","    </tr>\n","    <tr>\n","      <td>445</td>\n","      <td>1.087700</td>\n","    </tr>\n","    <tr>\n","      <td>446</td>\n","      <td>1.254500</td>\n","    </tr>\n","    <tr>\n","      <td>447</td>\n","      <td>1.105100</td>\n","    </tr>\n","    <tr>\n","      <td>448</td>\n","      <td>1.263200</td>\n","    </tr>\n","    <tr>\n","      <td>449</td>\n","      <td>1.147800</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>1.257900</td>\n","    </tr>\n","    <tr>\n","      <td>451</td>\n","      <td>1.216700</td>\n","    </tr>\n","    <tr>\n","      <td>452</td>\n","      <td>1.235700</td>\n","    </tr>\n","    <tr>\n","      <td>453</td>\n","      <td>1.111700</td>\n","    </tr>\n","    <tr>\n","      <td>454</td>\n","      <td>1.241200</td>\n","    </tr>\n","    <tr>\n","      <td>455</td>\n","      <td>1.236600</td>\n","    </tr>\n","    <tr>\n","      <td>456</td>\n","      <td>1.187300</td>\n","    </tr>\n","    <tr>\n","      <td>457</td>\n","      <td>1.248800</td>\n","    </tr>\n","    <tr>\n","      <td>458</td>\n","      <td>1.153600</td>\n","    </tr>\n","    <tr>\n","      <td>459</td>\n","      <td>1.222400</td>\n","    </tr>\n","    <tr>\n","      <td>460</td>\n","      <td>1.234300</td>\n","    </tr>\n","    <tr>\n","      <td>461</td>\n","      <td>1.247900</td>\n","    </tr>\n","    <tr>\n","      <td>462</td>\n","      <td>1.212600</td>\n","    </tr>\n","    <tr>\n","      <td>463</td>\n","      <td>1.184300</td>\n","    </tr>\n","    <tr>\n","      <td>464</td>\n","      <td>1.206900</td>\n","    </tr>\n","    <tr>\n","      <td>465</td>\n","      <td>1.257700</td>\n","    </tr>\n","    <tr>\n","      <td>466</td>\n","      <td>1.169100</td>\n","    </tr>\n","    <tr>\n","      <td>467</td>\n","      <td>1.184900</td>\n","    </tr>\n","    <tr>\n","      <td>468</td>\n","      <td>1.110700</td>\n","    </tr>\n","    <tr>\n","      <td>469</td>\n","      <td>1.216700</td>\n","    </tr>\n","    <tr>\n","      <td>470</td>\n","      <td>1.200000</td>\n","    </tr>\n","    <tr>\n","      <td>471</td>\n","      <td>1.183700</td>\n","    </tr>\n","    <tr>\n","      <td>472</td>\n","      <td>1.185200</td>\n","    </tr>\n","    <tr>\n","      <td>473</td>\n","      <td>1.212300</td>\n","    </tr>\n","    <tr>\n","      <td>474</td>\n","      <td>1.246900</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>1.298500</td>\n","    </tr>\n","    <tr>\n","      <td>476</td>\n","      <td>1.202400</td>\n","    </tr>\n","    <tr>\n","      <td>477</td>\n","      <td>1.253000</td>\n","    </tr>\n","    <tr>\n","      <td>478</td>\n","      <td>1.220400</td>\n","    </tr>\n","    <tr>\n","      <td>479</td>\n","      <td>1.144600</td>\n","    </tr>\n","    <tr>\n","      <td>480</td>\n","      <td>1.224100</td>\n","    </tr>\n","    <tr>\n","      <td>481</td>\n","      <td>1.262300</td>\n","    </tr>\n","    <tr>\n","      <td>482</td>\n","      <td>1.177100</td>\n","    </tr>\n","    <tr>\n","      <td>483</td>\n","      <td>1.278200</td>\n","    </tr>\n","    <tr>\n","      <td>484</td>\n","      <td>1.191400</td>\n","    </tr>\n","    <tr>\n","      <td>485</td>\n","      <td>1.231000</td>\n","    </tr>\n","    <tr>\n","      <td>486</td>\n","      <td>1.241900</td>\n","    </tr>\n","    <tr>\n","      <td>487</td>\n","      <td>1.197000</td>\n","    </tr>\n","    <tr>\n","      <td>488</td>\n","      <td>1.232700</td>\n","    </tr>\n","    <tr>\n","      <td>489</td>\n","      <td>1.184900</td>\n","    </tr>\n","    <tr>\n","      <td>490</td>\n","      <td>1.244800</td>\n","    </tr>\n","    <tr>\n","      <td>491</td>\n","      <td>1.210000</td>\n","    </tr>\n","    <tr>\n","      <td>492</td>\n","      <td>1.141900</td>\n","    </tr>\n","    <tr>\n","      <td>493</td>\n","      <td>1.172100</td>\n","    </tr>\n","    <tr>\n","      <td>494</td>\n","      <td>1.287700</td>\n","    </tr>\n","    <tr>\n","      <td>495</td>\n","      <td>1.169700</td>\n","    </tr>\n","    <tr>\n","      <td>496</td>\n","      <td>1.176200</td>\n","    </tr>\n","    <tr>\n","      <td>497</td>\n","      <td>1.151400</td>\n","    </tr>\n","    <tr>\n","      <td>498</td>\n","      <td>1.221300</td>\n","    </tr>\n","    <tr>\n","      <td>499</td>\n","      <td>1.165200</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>1.129300</td>\n","    </tr>\n","    <tr>\n","      <td>501</td>\n","      <td>1.194700</td>\n","    </tr>\n","    <tr>\n","      <td>502</td>\n","      <td>1.204700</td>\n","    </tr>\n","    <tr>\n","      <td>503</td>\n","      <td>1.190000</td>\n","    </tr>\n","    <tr>\n","      <td>504</td>\n","      <td>1.208700</td>\n","    </tr>\n","    <tr>\n","      <td>505</td>\n","      <td>1.222800</td>\n","    </tr>\n","    <tr>\n","      <td>506</td>\n","      <td>1.213000</td>\n","    </tr>\n","    <tr>\n","      <td>507</td>\n","      <td>1.246900</td>\n","    </tr>\n","    <tr>\n","      <td>508</td>\n","      <td>1.139500</td>\n","    </tr>\n","    <tr>\n","      <td>509</td>\n","      <td>1.116800</td>\n","    </tr>\n","    <tr>\n","      <td>510</td>\n","      <td>1.228500</td>\n","    </tr>\n","    <tr>\n","      <td>511</td>\n","      <td>1.196300</td>\n","    </tr>\n","    <tr>\n","      <td>512</td>\n","      <td>1.145100</td>\n","    </tr>\n","    <tr>\n","      <td>513</td>\n","      <td>1.171500</td>\n","    </tr>\n","    <tr>\n","      <td>514</td>\n","      <td>1.245000</td>\n","    </tr>\n","    <tr>\n","      <td>515</td>\n","      <td>1.167100</td>\n","    </tr>\n","    <tr>\n","      <td>516</td>\n","      <td>1.220000</td>\n","    </tr>\n","    <tr>\n","      <td>517</td>\n","      <td>1.129700</td>\n","    </tr>\n","    <tr>\n","      <td>518</td>\n","      <td>1.194300</td>\n","    </tr>\n","    <tr>\n","      <td>519</td>\n","      <td>1.206700</td>\n","    </tr>\n","    <tr>\n","      <td>520</td>\n","      <td>1.230200</td>\n","    </tr>\n","    <tr>\n","      <td>521</td>\n","      <td>1.214800</td>\n","    </tr>\n","    <tr>\n","      <td>522</td>\n","      <td>1.117000</td>\n","    </tr>\n","    <tr>\n","      <td>523</td>\n","      <td>1.146800</td>\n","    </tr>\n","    <tr>\n","      <td>524</td>\n","      <td>1.185600</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>1.202900</td>\n","    </tr>\n","    <tr>\n","      <td>526</td>\n","      <td>1.128400</td>\n","    </tr>\n","    <tr>\n","      <td>527</td>\n","      <td>1.143100</td>\n","    </tr>\n","    <tr>\n","      <td>528</td>\n","      <td>1.209400</td>\n","    </tr>\n","    <tr>\n","      <td>529</td>\n","      <td>1.159800</td>\n","    </tr>\n","    <tr>\n","      <td>530</td>\n","      <td>1.171900</td>\n","    </tr>\n","    <tr>\n","      <td>531</td>\n","      <td>1.205400</td>\n","    </tr>\n","    <tr>\n","      <td>532</td>\n","      <td>1.178700</td>\n","    </tr>\n","    <tr>\n","      <td>533</td>\n","      <td>1.179000</td>\n","    </tr>\n","    <tr>\n","      <td>534</td>\n","      <td>1.108000</td>\n","    </tr>\n","    <tr>\n","      <td>535</td>\n","      <td>1.185800</td>\n","    </tr>\n","    <tr>\n","      <td>536</td>\n","      <td>1.194800</td>\n","    </tr>\n","    <tr>\n","      <td>537</td>\n","      <td>1.171800</td>\n","    </tr>\n","    <tr>\n","      <td>538</td>\n","      <td>1.145100</td>\n","    </tr>\n","    <tr>\n","      <td>539</td>\n","      <td>1.188700</td>\n","    </tr>\n","    <tr>\n","      <td>540</td>\n","      <td>1.218400</td>\n","    </tr>\n","    <tr>\n","      <td>541</td>\n","      <td>1.097800</td>\n","    </tr>\n","    <tr>\n","      <td>542</td>\n","      <td>1.106600</td>\n","    </tr>\n","    <tr>\n","      <td>543</td>\n","      <td>1.157000</td>\n","    </tr>\n","    <tr>\n","      <td>544</td>\n","      <td>1.127400</td>\n","    </tr>\n","    <tr>\n","      <td>545</td>\n","      <td>1.247900</td>\n","    </tr>\n","    <tr>\n","      <td>546</td>\n","      <td>1.130900</td>\n","    </tr>\n","    <tr>\n","      <td>547</td>\n","      <td>1.204000</td>\n","    </tr>\n","    <tr>\n","      <td>548</td>\n","      <td>1.182800</td>\n","    </tr>\n","    <tr>\n","      <td>549</td>\n","      <td>1.188000</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>1.161500</td>\n","    </tr>\n","    <tr>\n","      <td>551</td>\n","      <td>1.125900</td>\n","    </tr>\n","    <tr>\n","      <td>552</td>\n","      <td>1.134300</td>\n","    </tr>\n","    <tr>\n","      <td>553</td>\n","      <td>1.175600</td>\n","    </tr>\n","    <tr>\n","      <td>554</td>\n","      <td>1.173500</td>\n","    </tr>\n","    <tr>\n","      <td>555</td>\n","      <td>1.301800</td>\n","    </tr>\n","    <tr>\n","      <td>556</td>\n","      <td>1.095200</td>\n","    </tr>\n","    <tr>\n","      <td>557</td>\n","      <td>1.217100</td>\n","    </tr>\n","    <tr>\n","      <td>558</td>\n","      <td>1.187000</td>\n","    </tr>\n","    <tr>\n","      <td>559</td>\n","      <td>1.119700</td>\n","    </tr>\n","    <tr>\n","      <td>560</td>\n","      <td>1.241400</td>\n","    </tr>\n","    <tr>\n","      <td>561</td>\n","      <td>1.165800</td>\n","    </tr>\n","    <tr>\n","      <td>562</td>\n","      <td>1.179600</td>\n","    </tr>\n","    <tr>\n","      <td>563</td>\n","      <td>1.177900</td>\n","    </tr>\n","    <tr>\n","      <td>564</td>\n","      <td>1.238400</td>\n","    </tr>\n","    <tr>\n","      <td>565</td>\n","      <td>1.142300</td>\n","    </tr>\n","    <tr>\n","      <td>566</td>\n","      <td>1.111800</td>\n","    </tr>\n","    <tr>\n","      <td>567</td>\n","      <td>1.133900</td>\n","    </tr>\n","    <tr>\n","      <td>568</td>\n","      <td>1.206400</td>\n","    </tr>\n","    <tr>\n","      <td>569</td>\n","      <td>1.225900</td>\n","    </tr>\n","    <tr>\n","      <td>570</td>\n","      <td>1.073400</td>\n","    </tr>\n","    <tr>\n","      <td>571</td>\n","      <td>1.110500</td>\n","    </tr>\n","    <tr>\n","      <td>572</td>\n","      <td>1.245400</td>\n","    </tr>\n","    <tr>\n","      <td>573</td>\n","      <td>1.195200</td>\n","    </tr>\n","    <tr>\n","      <td>574</td>\n","      <td>1.128500</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>1.221800</td>\n","    </tr>\n","    <tr>\n","      <td>576</td>\n","      <td>1.212500</td>\n","    </tr>\n","    <tr>\n","      <td>577</td>\n","      <td>1.155800</td>\n","    </tr>\n","    <tr>\n","      <td>578</td>\n","      <td>1.194200</td>\n","    </tr>\n","    <tr>\n","      <td>579</td>\n","      <td>1.203800</td>\n","    </tr>\n","    <tr>\n","      <td>580</td>\n","      <td>1.133800</td>\n","    </tr>\n","    <tr>\n","      <td>581</td>\n","      <td>1.052500</td>\n","    </tr>\n","    <tr>\n","      <td>582</td>\n","      <td>1.136900</td>\n","    </tr>\n","    <tr>\n","      <td>583</td>\n","      <td>1.185600</td>\n","    </tr>\n","    <tr>\n","      <td>584</td>\n","      <td>1.128400</td>\n","    </tr>\n","    <tr>\n","      <td>585</td>\n","      <td>1.186400</td>\n","    </tr>\n","    <tr>\n","      <td>586</td>\n","      <td>1.183400</td>\n","    </tr>\n","    <tr>\n","      <td>587</td>\n","      <td>1.174700</td>\n","    </tr>\n","    <tr>\n","      <td>588</td>\n","      <td>1.248600</td>\n","    </tr>\n","    <tr>\n","      <td>589</td>\n","      <td>1.192500</td>\n","    </tr>\n","    <tr>\n","      <td>590</td>\n","      <td>1.144300</td>\n","    </tr>\n","    <tr>\n","      <td>591</td>\n","      <td>1.225400</td>\n","    </tr>\n","    <tr>\n","      <td>592</td>\n","      <td>1.121700</td>\n","    </tr>\n","    <tr>\n","      <td>593</td>\n","      <td>1.146600</td>\n","    </tr>\n","    <tr>\n","      <td>594</td>\n","      <td>1.213000</td>\n","    </tr>\n","    <tr>\n","      <td>595</td>\n","      <td>1.178900</td>\n","    </tr>\n","    <tr>\n","      <td>596</td>\n","      <td>1.142600</td>\n","    </tr>\n","    <tr>\n","      <td>597</td>\n","      <td>1.211400</td>\n","    </tr>\n","    <tr>\n","      <td>598</td>\n","      <td>1.178100</td>\n","    </tr>\n","    <tr>\n","      <td>599</td>\n","      <td>1.206400</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>1.205500</td>\n","    </tr>\n","    <tr>\n","      <td>601</td>\n","      <td>1.244300</td>\n","    </tr>\n","    <tr>\n","      <td>602</td>\n","      <td>1.140500</td>\n","    </tr>\n","    <tr>\n","      <td>603</td>\n","      <td>1.185100</td>\n","    </tr>\n","    <tr>\n","      <td>604</td>\n","      <td>1.207500</td>\n","    </tr>\n","    <tr>\n","      <td>605</td>\n","      <td>1.127300</td>\n","    </tr>\n","    <tr>\n","      <td>606</td>\n","      <td>1.092500</td>\n","    </tr>\n","    <tr>\n","      <td>607</td>\n","      <td>1.094700</td>\n","    </tr>\n","    <tr>\n","      <td>608</td>\n","      <td>1.174500</td>\n","    </tr>\n","    <tr>\n","      <td>609</td>\n","      <td>1.223200</td>\n","    </tr>\n","    <tr>\n","      <td>610</td>\n","      <td>1.078000</td>\n","    </tr>\n","    <tr>\n","      <td>611</td>\n","      <td>1.089300</td>\n","    </tr>\n","    <tr>\n","      <td>612</td>\n","      <td>1.053600</td>\n","    </tr>\n","    <tr>\n","      <td>613</td>\n","      <td>1.227200</td>\n","    </tr>\n","    <tr>\n","      <td>614</td>\n","      <td>1.129600</td>\n","    </tr>\n","    <tr>\n","      <td>615</td>\n","      <td>1.111100</td>\n","    </tr>\n","    <tr>\n","      <td>616</td>\n","      <td>1.228500</td>\n","    </tr>\n","    <tr>\n","      <td>617</td>\n","      <td>1.091800</td>\n","    </tr>\n","    <tr>\n","      <td>618</td>\n","      <td>1.109200</td>\n","    </tr>\n","    <tr>\n","      <td>619</td>\n","      <td>1.117700</td>\n","    </tr>\n","    <tr>\n","      <td>620</td>\n","      <td>1.149100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"],"metadata":{"id":"pCqnaKmlO1U9","cellView":"form","outputId":"aea93cc4-68ab-4200-cf8d-2cce4224754e","execution":{"iopub.status.busy":"2024-04-06T16:30:10.784435Z","iopub.execute_input":"2024-04-06T16:30:10.7848Z","iopub.status.idle":"2024-04-06T16:30:10.791887Z","shell.execute_reply.started":"2024-04-06T16:30:10.784767Z","shell.execute_reply":"2024-04-06T16:30:10.791092Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["1877.8087 seconds used for training.\n","31.3 minutes used for training.\n","Peak reserved memory = 9.266 GB.\n","Peak reserved memory for training = 1.641 GB.\n","Peak reserved memory % of max memory = 11.715 %.\n","Peak reserved memory for training % of max memory = 2.075 %.\n"]}],"execution_count":null},{"cell_type":"markdown","source":["<a name=\"Inference\"></a>\n","# Inference ðŸ§ \n","Percobaan Infernce Setelah Training Model"],"metadata":{"id":"ekOmTR1hSNcr"}},{"cell_type":"code","source":["# alpaca_prompt = Copied from above\n","FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"saya mengalami sakit perut?\", # instruction\n","        \"\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","from transformers import TextStreamer\n","text_streamer = TextStreamer(tokenizer)\n","_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"],"metadata":{"id":"e2pEuRb1r2Vg","outputId":"ff3e7170-800d-4f29-a5f8-b2dc8b263178","execution":{"iopub.status.busy":"2024-04-06T16:30:13.840849Z","iopub.execute_input":"2024-04-06T16:30:13.841138Z","iopub.status.idle":"2024-04-06T16:30:15.541954Z","shell.execute_reply.started":"2024-04-06T16:30:13.841114Z","shell.execute_reply":"2024-04-06T16:30:15.54076Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","saya mengalami sakit perut?\n","\n","### Response:\n","dari keadaan yang anda alami, rasa sakit pada perut bagian atas dapat disebabkan karena gangguan kesehatan yang terkait organ lambung. berikut ini beberapa penyakit yang dapat menyerang organ lambung, diantaranya adalah : gastritis=== peradangan pada dinding lambung bagian dalam, penyakit asam lambung / gerd, tukak peptik=== luka yang terjadi pada dinding lambung bagian dalam, kanker lambung. selain dari keadaan yang telah disebutkan diatas, rasa\n"]}],"execution_count":null},{"cell_type":"code","source":["if False:\n","    from unsloth import FastLanguageModel\n","    model, tokenizer = FastLanguageModel.from_pretrained(\n","        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n","        max_seq_length = max_seq_length,\n","        dtype = dtype,\n","        load_in_4bit = load_in_4bit,\n","    )\n","    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n","\n","# alpaca_prompt = You MUST copy from above!\n","\n","inputs = tokenizer(\n","[\n","    alpaca_prompt.format(\n","        \"Saya mengalami sakit di anus?\", # instruction\n","        \"\", # input\n","        \"\", # output - leave this blank for generation!\n","    )\n","], return_tensors = \"pt\").to(\"cuda\")\n","\n","outputs = model.generate(**inputs, max_new_tokens = 1024, use_cache = True)\n","tokenizer.batch_decode(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NuiNi6o5pe5F","outputId":"3146f583-4dc3-4767-b59c-58b5986f12b0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nJawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nSaya mengalami sakit di anus?\\n\\n### Response:\\nsaya akan membantu menjawab pertanyaan anda. berdasarkan gejala yang anda alami, kemungkinan besar anda mengalami wasir atau ambeien. wasir merupakan kondisi dimana terjadi pembengkakan pada pembuluh darah vena di sekitar anus. gejala yang umumnya muncul pada wasir adalah: gatal-gatal di sekitar anus, terutama pada malam hari nyeri pada anus muncul benjolan pada anus yang berdarah bila disentuh atau saat buang air besar muncul lendir pada saat buang air besar terdapat rasa tidak nyaman di sekitar anus namun, ada beberapa kemungkinan penyebab lainnya yang menyebabkan gejala yang sama, seperti: peradangan pada anus, misalnya karena infeksi atau iritasi radang usus besar abses pada anus, yaitu pembengkakan yang berisi nanah pada anus kanker pada anus untuk memastikan penyebab keluhan yang anda alami, sebaiknya anda memeriksakan diri ke dokter. dokter akan melakukan pemeriksaan fisik secara langsung dan mungkin akan melakukan pemeriksaan colok dubur untuk menilai kondisi anus anda. jika diperlukan, dokter akan melakukan pemeriksaan penunjang seperti tes darah, usg, atau endoskopi. penanganan yang tepat akan diberikan sesuai dengan kondisi yang mendasari keluhan anda.<|end_of_text|>']"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["<a name=\"Save\"></a>\n","# Saving, loading finetuned models ðŸ“©\n","Untuk menyimpan model final sebagai adapter LoRA, menggunakan `push_to_hub` Huggingface untuk penyimpanan online atau save_pretrained untuk penyimpanan lokal.\n","\n","[CATATAN] Ini HANYA menyimpan adapter LoRA, bukan model penuh. Untuk menyimpan ke format 16-bit atau GGUF"],"metadata":{"id":"uMuVrWbjAzhc"}},{"cell_type":"markdown","source":["## menyimpan Adapter model LoRA di Hugging Face atau local"],"metadata":{"id":"ZMZD-MBO2gde"}},{"cell_type":"code","source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")"],"metadata":{"id":"upcOlWe7A1vc","execution":{"iopub.status.busy":"2024-04-06T16:30:15.543701Z","iopub.execute_input":"2024-04-06T16:30:15.544355Z","iopub.status.idle":"2024-04-06T16:30:16.234142Z","shell.execute_reply.started":"2024-04-06T16:30:15.544315Z","shell.execute_reply":"2024-04-06T16:30:16.233363Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["model.push_to_hub(\"farwew/lora_model\", token = \"hf_REMOVED_BY_SCRIPT\") # Online saving"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQKsOU07pX6m","outputId":"cc026c48-e48d-4e5b-f71c-14606f244927"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Saved model to https://huggingface.co/farwew/lora_model\n"]}]},{"cell_type":"code","source":["! zip -r lora_model.zip lora_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5mAMXqtqUf-","outputId":"deb349c6-0789-4e3e-de5d-2ca270965fd6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: lora_model/ (stored 0%)\r\n","  adding: lora_model/README.md (deflated 43%)\n","  adding: lora_model/adapter_model.safetensors (deflated 7%)\n","  adding: lora_model/adapter_config.json (deflated 56%)\n"]}]},{"cell_type":"code","source":["!curl -F \"reqtype=fileupload\" -F \"fileToUpload=@lora_model.zip\" https://catbox.moe/user/api.php"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFOnjwZcpmhW","outputId":"0d210eb2-3676-4682-b028-249e84bfb364"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["https://files.catbox.moe/d95pr5.zip"]}]},{"cell_type":"markdown","source":["<div class=\"align-center\">\n","  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n","  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n","  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n","</div>"],"metadata":{"id":"Zt9CHJqO6p30"}},{"cell_type":"markdown","source":["# Evaluasi Metrik Kunatitatif  ( Bert Score, Blue, Rouge )\n","\n","\n","## Pada bagian ini, kami melakukan evaluasi kuantitatif terhadap performa **Base (sebelum di Fine Tune)** dan  model yang telah di-fine-tuning\n",".\n","\n","Evaluasi ini menggunakan metrik standar dalam penilaian kualitas teks yang dihasilkan oleh model bahasa, yaitu **BERT Score, BLEU, dan ROUGE**. Tujuannya adalah untuk mengukur seberapa dekat atau relevan teks jawaban yang dihasilkan model dibandingkan dengan jawaban referensi dari dataset.\n","\n","*   **BERT Score**: Mengukur kesamaan semantik antara teks yang dihasilkan dan teks referensi dengan memanfaatkan representasi kontekstual dari model BERT.\n","*   **BLEU (Bilingual Evaluation Understudy)**: Mengukur presisi n-gram, yaitu seberapa banyak urutan kata dalam teks yang dihasilkan muncul dalam teks referensi. Umumnya digunakan untuk menilai terjemahan mesin, namun juga relevan untuk tugas generasi teks lainnya.\n","*   **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**: Mengukur *recall* n-gram, yaitu seberapa banyak urutan kata dalam teks referensi yang muncul dalam teks yang dihasilkan. Umumnya digunakan untuk menilai ringkasan teks.\n","\n","Dengan menggunakan metrik-metrik ini, kami dapat memperoleh gambaran objektif mengenai kualitas teks yang dihasilkan oleh model kami sebelum dan setelah fine-tuning."],"metadata":{"id":"9l8jGEDUIIBG"}},{"cell_type":"markdown","source":["Load LoRA model dan adapter"],"metadata":{"id":"v3_E_GVNKkDw"}},{"cell_type":"markdown","source":["## Download Dependencies"],"metadata":{"id":"ZQxR9jsdMvoE"}},{"cell_type":"code","source":["%%capture\n","! pip install unsloth\n","! pip install rouge_score\n","! pip install evaluate"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T23:56:09.170724Z","iopub.execute_input":"2025-05-24T23:56:09.171422Z","iopub.status.idle":"2025-05-24T23:59:28.612781Z","shell.execute_reply.started":"2025-05-24T23:56:09.171390Z","shell.execute_reply":"2025-05-24T23:59:28.611788Z"},"id":"M5YMrmYHMvoG"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["%%capture\n","! pip install -U peft\n","! pip install bert_score"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:02:09.689891Z","iopub.execute_input":"2025-05-25T00:02:09.690176Z","iopub.status.idle":"2025-05-25T00:02:16.554374Z","shell.execute_reply.started":"2025-05-25T00:02:09.690155Z","shell.execute_reply":"2025-05-25T00:02:16.553289Z"},"id":"_UMF8qklMvoI"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## Import Dependencies"],"metadata":{"id":"HndzItyCMvoI"}},{"cell_type":"code","source":["from tqdm import tqdm\n","import kagglehub\n","import os"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:01:14.821284Z","iopub.execute_input":"2025-05-25T00:01:14.821603Z","iopub.status.idle":"2025-05-25T00:01:15.188967Z","shell.execute_reply.started":"2025-05-25T00:01:14.821576Z","shell.execute_reply":"2025-05-25T00:01:15.188391Z"},"id":"Lg4qCJPaMvoI"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import torch\n","from datasets import load_dataset\n","import evaluate"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:01:16.680016Z","iopub.execute_input":"2025-05-25T00:01:16.680777Z","iopub.status.idle":"2025-05-25T00:01:48.588478Z","shell.execute_reply.started":"2025-05-25T00:01:16.680751Z","shell.execute_reply":"2025-05-25T00:01:48.587826Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"wSkPZad-MvoI","outputId":"26b857c5-04a9-4ede-9cf5-eca8fc39b115"},"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"]}],"execution_count":null},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer\n","from datasets import load_dataset\n","import evaluate\n","import torch\n","import bert_score\n","import pandas as pd\n","from tqdm import tqdm\n","from datetime import datetime\n","import os\n","import re"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:02:24.813512Z","iopub.execute_input":"2025-05-25T00:02:24.814369Z","iopub.status.idle":"2025-05-25T00:02:24.865040Z","shell.execute_reply.started":"2025-05-25T00:02:24.814334Z","shell.execute_reply":"2025-05-25T00:02:24.864480Z"},"id":"mWwzUF9gMvoK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from datasets import load_dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","from datasets import Dataset"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:06:50.088281Z","iopub.execute_input":"2025-05-25T00:06:50.088675Z","iopub.status.idle":"2025-05-25T00:06:50.093947Z","shell.execute_reply.started":"2025-05-25T00:06:50.088647Z","shell.execute_reply":"2025-05-25T00:06:50.093099Z"},"id":"fc9qob62MvoL"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from peft import PeftModel"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T01:44:43.047577Z","iopub.execute_input":"2025-05-25T01:44:43.047841Z","iopub.status.idle":"2025-05-25T01:44:43.051321Z","shell.execute_reply.started":"2025-05-25T01:44:43.047825Z","shell.execute_reply":"2025-05-25T01:44:43.050518Z"},"id":"ktaOFSBnMvoM"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## Load dataset untuk Testing (Evaluation)"],"metadata":{"id":"acNLcLN7MvoN"}},{"cell_type":"code","source":["# 1. Load dataset\n","dataset = load_dataset(\"farwew/DoctorsAnswerTextDataset-in-Indonesian\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:02:36.501529Z","iopub.execute_input":"2025-05-25T00:02:36.502262Z","iopub.status.idle":"2025-05-25T00:02:39.491600Z","shell.execute_reply.started":"2025-05-25T00:02:36.502237Z","shell.execute_reply":"2025-05-25T00:02:39.490899Z"},"id":"plguwjCjMvoN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# 3. Ambil data test\n","dataset_eval = dataset[\"test\"]\n","\n","# 4. Konversi ke pandas DataFrame\n","df = dataset_eval.to_pandas()\n","df.head()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:03:04.793960Z","iopub.execute_input":"2025-05-25T00:03:04.794247Z","iopub.status.idle":"2025-05-25T00:03:04.807598Z","shell.execute_reply.started":"2025-05-25T00:03:04.794227Z","shell.execute_reply":"2025-05-25T00:03:04.806838Z"},"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"wqfItn75MvoN","outputId":"701e6546-7cb9-49e6-e4ec-9a61c8f27016"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              instruction  \\\n","0  Selalu tersedak setiap makan dan minum   \n","1                   Apa obat untuk demam?   \n","2  Cara mengatasi perut kembung pada anak   \n","3              Perut Bagian Bawah Kembung   \n","4         Nyeri dada menjalar ke punggung   \n","\n","                                               input  \\\n","0  Selalu tersedak setiap makan dan minum. Dok sa...   \n","1  Apa obat untuk demam?. malam dok saya mau tany...   \n","2  Cara mengatasi perut kembung pada anak. punya ...   \n","3  Perut Bagian Bawah Kembung. saya mau bertanya,...   \n","4  Nyeri dada menjalar ke punggung. Malam dok tad...   \n","\n","                                              output            topic_set  \\\n","0  batuk adalah respon tubuh untuk mengeluarkan b...            gastritis   \n","1  kepala pusing, perut mual, punggung sakit dan ...                 mual   \n","2  perut kembung menandakan adanya penumpukan gas...        perut-kembung   \n","3  seperti: sayur: kol, brokoli, kembang kol, asp...  gangguan-pencernaan   \n","4  saya coba bantu jawab. keluhan nyeri dada menj...           sakit-maag   \n","\n","                                            topics  \n","0  penyakit-parkinson multiple-sclerosis gastritis  \n","1       flu pilek sakit-kepala nyeri-punggung mual  \n","2                     anak gastritis perut-kembung  \n","3                              gangguan-pencernaan  \n","4                            nyeri-dada sakit-maag  "],"text/html":["\n","  <div id=\"df-ca9b1f7f-f3f1-4cbd-82ca-31e6aed6c2c0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>instruction</th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>topic_set</th>\n","      <th>topics</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Selalu tersedak setiap makan dan minum</td>\n","      <td>Selalu tersedak setiap makan dan minum. Dok sa...</td>\n","      <td>batuk adalah respon tubuh untuk mengeluarkan b...</td>\n","      <td>gastritis</td>\n","      <td>penyakit-parkinson multiple-sclerosis gastritis</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Apa obat untuk demam?</td>\n","      <td>Apa obat untuk demam?. malam dok saya mau tany...</td>\n","      <td>kepala pusing, perut mual, punggung sakit dan ...</td>\n","      <td>mual</td>\n","      <td>flu pilek sakit-kepala nyeri-punggung mual</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Cara mengatasi perut kembung pada anak</td>\n","      <td>Cara mengatasi perut kembung pada anak. punya ...</td>\n","      <td>perut kembung menandakan adanya penumpukan gas...</td>\n","      <td>perut-kembung</td>\n","      <td>anak gastritis perut-kembung</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Perut Bagian Bawah Kembung</td>\n","      <td>Perut Bagian Bawah Kembung. saya mau bertanya,...</td>\n","      <td>seperti: sayur: kol, brokoli, kembang kol, asp...</td>\n","      <td>gangguan-pencernaan</td>\n","      <td>gangguan-pencernaan</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Nyeri dada menjalar ke punggung</td>\n","      <td>Nyeri dada menjalar ke punggung. Malam dok tad...</td>\n","      <td>saya coba bantu jawab. keluhan nyeri dada menj...</td>\n","      <td>sakit-maag</td>\n","      <td>nyeri-dada sakit-maag</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca9b1f7f-f3f1-4cbd-82ca-31e6aed6c2c0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ca9b1f7f-f3f1-4cbd-82ca-31e6aed6c2c0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ca9b1f7f-f3f1-4cbd-82ca-31e6aed6c2c0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-f0f21675-e585-41ed-81ef-3cb8335877eb\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0f21675-e585-41ed-81ef-3cb8335877eb')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-f0f21675-e585-41ed-81ef-3cb8335877eb button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 1048,\n  \"fields\": [\n    {\n      \"column\": \"instruction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1038,\n        \"samples\": [\n          \"Frekuensi normal BAB bayi baru lahir\",\n          \"Keringat dingin setiap maag kambuh\",\n          \"penyebab nyeri perut 2 jari di atas pusar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1048,\n        \"samples\": [\n          \"sakit di tulang bokong saat mengedan terlalu keras. beberapa hari ini bab saya keras dok, tetap perut saya mules mau enggak mau harus 'dikeluarkan'.. pas saya paksakan otomatis saya \\\\ngeden\\\\ karena bab saya keras dan tulang di dekat bokong saya langsung terasa sakit ketika duduk dan sampai sekarang saya tidak bisa bab dok.. apakah itu bahaya atau tidak?\",\n          \"Solusi atasi nyeri ulu hati disertai sendawa dan perut begah. Permisi dok, nama saya rani, umur saya 17 tahun. Saya kena asam lambung sudah lama bahkan sampai sakit ulu hati saya, tapi saya tidak pernah merasakan sakit lagi, belakangan ini perut saya makin membesar saya susah bernafas dan saya sering pipis dok. Sampai saya pakai celana terasa begah tapi perut atas saya ketika di tekan seperti keluar angin(sendawa). Saya belum menikah dok. terkadang perut saya terasa gerak sendiri sok. Sekian yang saya alami tolong solusi nya ya dok. Terimakasih\",\n          \"Perut sebelah kanan atas nyeri. Perut sebelah kanan atas terasa nyeri saat bernafas sama dada sebelah kanan tembus ke tulang belikat ikut sakit juga, penyakit apa ya dok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1048,\n        \"samples\": [\n          \"feses yang sangat keras dapat menyebabkan anus lecet sehingga disebut fissura ani ataupun hemoroid/ambeien akibat mengedan. kedua hal ini dapat menyebabkan rasa tidak nyaman pada saat duduk. jika anda merasa tulang anda nyeri setelah mengedan terlalu kuat, seharusnya hal ini tidaklah berbahaya. struktur tulang kita cukup kuat jika dibandingkan dengan kekuatan mengedan. anda juga perlu mengetahui apakah yang sakit anus atau tulang pinggul. untuk sementara, anda dapat mengkonsumsi obat-obatan pereda nyeri untuk mengatasi nyeri tersebut. jangan lupa untuk banyak mengkonsumsi buah dan sayur sebagai sumber serat dan juga banyak konsumsi air putih. jika keluhan tidak juga membaik, anda dapat memeriksakan diri ke dokter. anda juga dapat membaca artikel terkait: cara menangani sakit tulang ekor\",\n          \"mulai dari sebatas mual, kembung, sering sendawa, hingga nyeri ulu hati. selain nyeri, keluhan-keluhan tersebut sering ditemukan pada kasus yang kronis. kondisinya juga akan diperparah dengan gaya hidup yang tidak sehat, yaitu: \\u00b7 makan sambil berbicara sehingga besar kemungkinanmenelan udara \\u00b7 konsumsi makanan yang akan membentuk gas dalan saluran cerna, contohnya ubi, keju, sawi, dan kol \\u00b7 akumulasi gas dalam saluran cerna karena gerakan peristaltik usus melemah, misalnya ketika paska diare \\u00b7 pola makan tidak teratur \\u00b7 konsumsi kafein berlebihan \\u00b7 merkokok dan sering begadang perut kembung akan membuat rasa yang tidak nyaman. sebaiknya periksakan kembali keluhan anda ini ke dokter untuk menilai penyebab serta penanganan terbaiknya. beberapa tips kesehatan yang dapat anda lakukan: \\u00b7 diet rendah lemak, hindari makanan atau minuman yang dapat memicu asam lambung (lihat atas) \\u00b7 tidak langsung berbaring setelah makan, minimal 2 jam setelahnya baru boleh \\u00b7 pola makan yang teratur, sekitar 3-4x/hari dengan porsi cukup, tidak berlebihan \\u00b7 perbanyak minum air putih \\u00b7 istirahat cukup, olahraga teratur, dan manajemen stres dengan baik\",\n          \"nyeri tajam seperti tertusuk, kram, dan sebagainya), serta lokasi bagian perut yang sakit dapat menjadi petunjuk penyebabnya. nyeri perut kanan atas dapat disebabkan oleh : radang pada saluran atau kandung empedu batu empedu batu ginjal, infeksi atau kanker pada ginjal gastritis, tukak lambung radang atau kanker pankreas dan lain-lain nyeri perut sebelah kanan atas dapat merupakan sakit perut biasa ataupun disebabkan oleh kondisi medis yang lebih seriud. untuk memastikannya, dianjurkan memeriksakan diri secara langsung ke dokter. dokter akan melakukan pemeriksaan fisik dan tes tambahan, seperti tes darah, tes fungsi ginjal, tes fungsi hati dan empedu, usg perut, dan sebagainya. penanganan akan disesuaikan dengan penyebab yang mendasari. jangan sembarangan mengonsumsi obat-obatan bebas, seperti aspirin atau ibuprofen, yang justru dapat memperparah rasa sakit.baca tentang nyeri perut sebelah kanan dan nyeri perut bagian atas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topic_set\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"tukak-lambung\",\n          \"konstipasi\",\n          \"gastritis\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"topics\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 340,\n        \"samples\": [\n          \"sakit-perut pusing asam-lambung\",\n          \"bronkitis asam-lambung\",\n          \"hipotensi asam-lambung\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":9}],"execution_count":null},{"cell_type":"markdown","source":["## Stratify  Sampling for Testing\n","\n","Kami melakukan stratified sampling terhadap topik pertanyaan untuk memilih 100 sampel acak dari data uji. Sampling ini diambil dari 1.000 data uji sebelumnya dengan tujuan untuk mengurangi beban komputasi mengingat keterbatasan perangkat yang digunakan."],"metadata":{"id":"pvHd7I-7MKW0"}},{"cell_type":"code","source":["# 5. Stratified split berdasarkan kolom 'topic_set'\n","train_df, stratified_sample_df = train_test_split(\n","    df,\n","    test_size=100,  # ubah sesuai proporsi yang diinginkan\n","    stratify=df[\"topic_set\"],\n","    random_state=42\n",")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:05:15.770715Z","iopub.execute_input":"2025-05-25T00:05:15.771289Z","iopub.status.idle":"2025-05-25T00:05:15.780529Z","shell.execute_reply.started":"2025-05-25T00:05:15.771257Z","shell.execute_reply":"2025-05-25T00:05:15.779672Z"},"id":"Qlsi8TmvMvoN"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["train_dataset = Dataset.from_pandas(train_df)\n","stratified_dataset = Dataset.from_pandas(stratified_sample_df)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:06:54.330603Z","iopub.execute_input":"2025-05-25T00:06:54.330920Z","iopub.status.idle":"2025-05-25T00:06:54.361030Z","shell.execute_reply.started":"2025-05-25T00:06:54.330901Z","shell.execute_reply":"2025-05-25T00:06:54.360470Z"},"id":"9HWCn-SdMvoO"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["stratified_dataset"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:07:05.464850Z","iopub.execute_input":"2025-05-25T00:07:05.465476Z","iopub.status.idle":"2025-05-25T00:07:05.470293Z","shell.execute_reply.started":"2025-05-25T00:07:05.465453Z","shell.execute_reply":"2025-05-25T00:07:05.469488Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"TU-nrLblMvoO","outputId":"8dbfa260-0f25-4997-99be-cfd16c7f3174"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['instruction', 'input', 'output', 'topic_set', 'topics', '__index_level_0__'],\n","    num_rows: 100\n","})"]},"metadata":{},"execution_count":13}],"execution_count":null},{"cell_type":"markdown","source":["##   Evaluasi Base Model (Bukan Fine Tune)\n","\n","Pemilihan Model sesuai dengan Model Base yang mau dievaluasi"],"metadata":{"id":"EzalQZ-8MvoP"}},{"cell_type":"code","source":["# Konfigurasi\n","selected_model = \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\" # @param [\"unsloth/mistral-7b-v0.3\", \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\", \"unsloth/llama-3-8b-bnb-4bit\", \"GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct\", \"GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct\", \"Yellow-AI-NLP/komodo-7b-base\"]\n","max_seq_length = 2048  # @param {type:\"slider\", min:512, max:8192, step:256}\n","load_in_4bit = True  # @param {type:\"boolean\"}\n","dtype = None  # @param [\"None\", \"float16\", \"bfloat16\", \"float32\"] {type:\"raw\"}\n","HuggingFace_token = \"hf_...\"  # @param {type:\"string\"}"],"metadata":{"id":"AYk1sUZ9NehS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = selected_model,\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    token = HuggingFace_token,\n",")"],"metadata":{"outputId":"34a9e1c2-66ca-4506-d5e3-e0fabd6604bc","execution":{"iopub.status.busy":"2025-05-19T16:44:23.641832Z","iopub.execute_input":"2025-05-19T16:44:23.642088Z","iopub.status.idle":"2025-05-19T16:46:22.233909Z","shell.execute_reply.started":"2025-05-19T16:44:23.642062Z","shell.execute_reply":"2025-05-19T16:46:22.233135Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"7CuWWBB3NehS"},"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.5.6: Fast Llama patching. Transformers: 4.51.3.\n","   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.096 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"execution_count":null},{"cell_type":"markdown","source":["### Formatting data"],"metadata":{"id":"ziA_hIqLN0_c"}},{"cell_type":"code","source":["alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\""],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:17:28.580012Z","iopub.execute_input":"2025-05-25T00:17:28.580761Z","iopub.status.idle":"2025-05-25T00:17:28.584035Z","shell.execute_reply.started":"2025-05-25T00:17:28.580736Z","shell.execute_reply":"2025-05-25T00:17:28.583234Z"},"id":"PzXiSnXQMvoR"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n","def formatting_prompts_func(examples):\n","    inputs = examples[\"input\"]\n","    outputs = examples[\"output\"]\n","    texts = []\n","    for input_text, output_text in zip(inputs, outputs):\n","        text = alpaca_prompt.format(input_text, output_text) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\": texts }\n","pass"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:17:29.107183Z","iopub.execute_input":"2025-05-25T00:17:29.107451Z","iopub.status.idle":"2025-05-25T00:17:29.111949Z","shell.execute_reply.started":"2025-05-25T00:17:29.107431Z","shell.execute_reply":"2025-05-25T00:17:29.111227Z"},"id":"sIYLYCcqMvoR"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Mulai Inference Base Model (sebelum Fine Tune) untuk Evaluasi"],"metadata":{"id":"YS4YEVZoMvoS"}},{"cell_type":"code","source":["# # === Evaluasi === #\n","# bleu = evaluate.load(\"bleu\")\n","# rouge = evaluate.load(\"rouge\")\n","generated_outputs = []\n","reference_outputs = []\n","all_instructions = []\n","all_inputs = []"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:18:09.563870Z","iopub.execute_input":"2025-05-25T00:18:09.564183Z","iopub.status.idle":"2025-05-25T00:18:12.286601Z","shell.execute_reply.started":"2025-05-25T00:18:09.564157Z","shell.execute_reply":"2025-05-25T00:18:12.286046Z"},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["b4538a523b7c4ca49d86625e97c722fb","ed9406c60e28417284ec6f5e22d7ad6e","bca433dd60e0406db509a4cd004be3a0","159dab99ae954775a24a15362fa629ba","9e3d6d34cc1d4a5996abea37b123a825","a55eabf1afb8450fbf9bf4a258c430cc","a4b1abda38d14c8bb4d4b1a0926cb944","0d2b4f1886f04e4c9fee4cdb0d009160","4af01ce5b44c4b59945bd352c82ea20c","d5aff846ae3d4cc4af837669f42d3c06","01e861a2b280460bb0a2398a7d55096f","43a0b8cbc8cf4195a14f63eb684b783d","8faf35d6ff9345e2823b46c20fb681a8","cf0e97da9f264836b107e379b8cc7249","7fab6d20bd824ef390e468b67100739b","709a444d630542e494bf318b334fccfb","d88bb09e4dfa4fe4ab49ecf929981e6e","5ea0b874a34e48b58f63bdde52b90cf4","d8d0455a690f49ebbfce35c1e7aac8e4","0f65a8bdb23f47e1852b1145350febc0","37f81efae8e449a8a26db050ed0e1eb6","f5aafd41720d4dcdbd7fb1b08b624cda","0c99f58fc7eb459cbf08a619ec0e77ac","9efa27b4370c4edf82410906b6f08d44","58c83847c4314ac9974c12f5a5103822","5c1988c5a0ad424b8b81f8be9a6cecd9","f41f6ce8e6444c1c9120c57755431c94","07d03714c5ee4378991e979aa0e1fc62","237186dd28db44a896325aa67f6ea667","95bae64c09df4295aacb205079e5b49f","4a356e4200234190b1a765690ec7d778","60bc83d004784ed5a56837a858d57d62","7af2a6db88f24a1883b4e1ec33d310a0","fdf32b630d9247c68a609a246cfad8a7","e15c85c41dd941fda833fa504f7c6809","b0c0756ed6b24900a6b9b1357b7e4e3c","c3bc10e1c6a64d53bcb98f919043db35","c77726f70b534c0db97acad25a34ceda","4efee786cbd148f28add27cf597eead6","001e1b2b01f0445391be6048b871b28d","f42e6a798d3547c3a83e5be555296268","939c6b1231b24083a56e4646beae3dd1","894dfb2045e9493282d3438bfe2866f3","5e71eea28f59480698d6f9b62a0c406b"]},"id":"D3Ec_XHvMvoS","outputId":"277b6165-c0f4-4407-a701-7625fcb73dce"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4538a523b7c4ca49d86625e97c722fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a0b8cbc8cf4195a14f63eb684b783d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c99f58fc7eb459cbf08a619ec0e77ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdf32b630d9247c68a609a246cfad8a7"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["def normalize_text(text):\n","    text = text.lower().strip()\n","    text = re.sub(r\"\\p{P}+\", \"\", text)\n","    text = re.sub(r\"\\s+\", \" \", text)\n","    return text"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:18:23.584229Z","iopub.execute_input":"2025-05-25T00:18:23.584532Z","iopub.status.idle":"2025-05-25T00:18:23.588836Z","shell.execute_reply.started":"2025-05-25T00:18:23.584509Z","shell.execute_reply":"2025-05-25T00:18:23.588078Z"},"id":"ZRXWW6ckMvoS"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Inference\n","Bagian kode ini melakukan inferensi (menghasilkan jawaban) menggunakan model dasar untuk setiap pertanyaan di dataset uji, kemudian mengumpulkan jawaban yang dihasilkan bersama dengan jawaban referensi untuk keperluan evaluasi metrik di tahap berikutnya. Beberapa contoh jawaban juga ditampilkan.\n","\n"],"metadata":{"id":"_hgb6fqPOztc"}},{"cell_type":"code","source":["num = 1\n","for example in tqdm(stratified_dataset, desc=\"Evaluating Base Model\"):\n","    # Gunakan prompt yang hanya menerima input (karena instruksi tetap)\n","    prompt = alpaca_prompt.format(example[\"input\"], \"\")  # output dikosongkan untuk inferensi\n","\n","    # Tokenisasi dan pindahkan ke GPU\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","    # Inference (tanpa perhitungan gradien)\n","    with torch.no_grad():\n","        output = model.generate(\n","            **input_ids,\n","            max_new_tokens=1024,\n","            do_sample=True,\n","            top_p=0.9,\n","            temperature=0.7\n","        )\n","\n","    # Decode output dan ekstrak bagian response-nya\n","    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n","    response = decoded.split(\"### Response:\")[-1].strip()\n","\n","    # Cetak sampel jika masih kurang dari 10\n","    if num < 10:\n","        print(prompt)\n","        print()\n","        print('response:', response)\n","        print('-' * 80)\n","\n","    # Simpan hasil untuk evaluasi\n","    generated_outputs.append(response)\n","    reference_outputs.append(example[\"output\"])\n","    all_instructions.append(\"Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\")  # atau bisa juga diabaikan jika instruksi selalu sama\n","    all_inputs.append(example[\"input\"])\n","    num += 1"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T00:22:04.433367Z","iopub.execute_input":"2025-05-25T00:22:04.433944Z","iopub.status.idle":"2025-05-25T01:38:17.382201Z","shell.execute_reply.started":"2025-05-25T00:22:04.433922Z","shell.execute_reply":"2025-05-25T01:38:17.381580Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"f8tO6g5JMvoS","outputId":"1d389a8d-d851-42ed-ffcb-b59e9898ed07","collapsed":true},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Evaluating Base Model:   1%|          | 1/100 [01:06<1:49:34, 66.41s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Solusi atasi sakit maag yang tak kunjung sembuh. Saya memiliki keluhan selama 2 minggu belakangan ada masalah di pencernaan. Saya sudah berobat klinik 2 kali tapi diagnosanya sama yaitu saya menderita maag. Oleh dokter yang menangani, saya hanya diberi antasida, omeprazole, dan ranitidin. Saya sudah habiskan obatnya, pola makan pun saya jaga dengan tidak mengkonsumsi makanan pedas, asam, dan kafein namun sampai saat ini tidak ada perubahan. Selama 2 minggu saya sakit berat badan saya turun 1,5 kilo, tidak memiliki nafsu makan sama sekali, sering sendawa, nyeri di ulu hati dan perut bagian kanan. Kemarin saya juga sempat terlambat makan siang dan malam, akibatnya saya mengalami muntah berwarna kekuningan disertai dengan bercak merah seperti darah segar. Apakah saya perlu melakukan endoskopi dan tes darah? Selain itu, apakah penderita maag pada umumnya mengalami hal seperti ini? Terima kasih\n","\n","### Response:\n","\n","\n","response: Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\n","\n","Maag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\n","\n","Gejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ini muncul karena peradangan di perut yang menyebabkan luka. Luka ini menyebabkan infeksi, dan infeksi ini menyebabkan peradangan. Luka ini juga menyebabkan perdarahan. Perdarahan ini menyebabkan darah mengalir ke dalam perut, dan darah ini menyebabkan peradangan. Peradangan ini menyebabkan sakit perut, muntah, dan mual.\n","\n","Ada beberapa cara untuk mengobati maag. Obat-obatan yang digunakan untuk mengobati maag adalah antasida, antibiotik, dan obat-obatan lain yang dapat menghentikan peradangan dan perdarahan. Obat-obatan ini dapat menyembuhkan maag, dan dapat menghentikan gejala-gejala yang muncul akibat maag.\n","\n","Jika gejala-gejala maag tidak berhenti meskipun telah menggunakan obat-obatan, dokter dapat menyarankan penderita maag untuk melakukan tes darah dan endoskopi. Tes darah dapat menguji kadar asam lambung dan jumlah sel darah. Tes darah dapat menentukan apakah penderita maag memiliki infeksi virus atau bakteri. Tes darah juga dapat menentukan apakah penderita maag memiliki infeksi bakteri yang disebabkan oleh bakteri yang disebut Helicobacter pylori. Tes darah dapat menentukan apakah penderita maag memiliki infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori.\n","\n","Endoskopi dapat menguji kondisi di dalam perut. Endoskopi dapat melihat luka-luka di dalam perut. Endoskopi dapat melihat apakah luka-luka di dalam perut mengalami peradangan dan perdarahan. Endoskopi dapat melihat apakah luka-luka di dalam perut mengalami infeksi virus atau bakteri. Endoskopi dapat melihat apakah luka-luka di dalam perut mengalami infeksi bakteri yang disebabkan oleh bakteri yang disebut Helicobacter pylori. Endoskopi dapat melihat apakah luka-luka di dalam perut mengalami infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori.\n","\n","Jika tes darah dan endoskopi menunjukkan bahwa penderita maag memiliki infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori, dokter dapat menyarankan penderita maag untuk menggunakan obat-obatan yang dapat menghentikan infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori. Jika tes darah dan endoskopi menunjukkan bahwa penderita maag memiliki infeksi bakteri yang disebabkan oleh bakteri yang disebut Helicobacter pylori, dokter dapat menyarankan penderita maag untuk menggunakan obat-obatan yang dapat menghentikan infeksi bakteri yang disebabkan oleh bakteri yang disebut Helicobacter pylori.\n","\n","Jika tes darah dan endoskopi menunjukkan bahwa penderita maag memiliki infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori, dokter dapat menyarankan penderita maag untuk menggunakan obat-obatan yang dapat menghentikan infeksi virus yang disebabkan oleh virus yang disebut virus H. pylori. Jika tes darah dan endoskopi menunjukkan bahwa penderita maag memiliki infeksi bakteri yang disebabkan oleh bakteri yang disebut Helicobacter pylori, dokter dapat menyarankan penderita maag untuk menggunakan obat-obatan yang dapat menghentikan infeksi bakteri yang disebabkan oleh bakteri yang disebut\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   2%|â–         | 2/100 [02:09<1:44:58, 64.27s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","solusi untuk mengatasi konstipasi. dok kalo bab feses saya enggak keras, cair tapi usus saya enggak mau untuk ngeluarinnya. kenapa ya dok?\n","\n","### Response:\n","\n","\n","response: Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","solusi untuk mengat\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   3%|â–Ž         | 3/100 [02:42<1:21:05, 50.16s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Perut sakit, mual dan bersendawa berlebihan. saya ingin tany dok.. istri saya mrasakan sakit perut, kpala pusing di sertai mual2 dan bersendawa yang brlebih.. kira-kira apa pnyebab nya dan bgm solusi mngatasiny. terima kasih\n","\n","### Response:\n","\n","\n","response: Assalamu'alaikum,\n","\n","Perut sakit, mual dan bersendawa berlebihan. Saya ingin tany dok.. istri saya merasakan sakit perut, kepala pusing di sertai mual2 dan bersendawa yang berlebih.. kira-kira apa penyebab nya dan bagaimana solusi mengatasinya. Terima kasih.\n","\n","Terima kasih atas pertanyaan medis Anda. Apakah perut sakit Anda berhubungan dengan mual, pusing, dan bersendawa? Jika ya, ini merupakan gejala dari penyakit apapun. Saya akan mencoba menjawab pertanyaan Anda sebaik mungkin dengan informasi yang saya miliki sekarang.\n","\n","Dari apa yang saya ketahui, gejala yang Anda alami mungkin disebabkan oleh kondisi medis berikut:\n","\n","- Gastritis: Penyakit ini menyebabkan rasa sakit di perut, mual, dan pusing. Saya akan merekomendasikan Anda untuk memeriksakan kondisi ini jika Anda mengalami gejala tersebut.\n","- Penyakit pankreas: Penyakit ini disebabkan oleh penumpukan cairan di pankreas, yang menyebabkan rasa sakit di perut, mual, dan pusing. Saya akan merekomendasikan Anda untuk memeriksakan kondisi ini jika Anda mengalami gejala tersebut.\n","- Penyakit liver: Penyakit ini disebabkan oleh penumpukan cairan di liver, yang menyebabkan rasa sakit di perut, mual, dan pusing. Saya akan merekomendasikan Anda untuk memeriksakan kondisi ini jika Anda mengalami gejala tersebut.\n","- Penyakit hati: Penyakit ini disebabkan oleh penumpukan cairan di hati, yang menyebabkan rasa sakit di perut, mual, dan pusing. Saya akan merekomendasikan Anda untuk memeriksakan kondisi ini jika Anda mengalami gejala tersebut.\n","\n","Jika gejala yang Anda alami tidak disebabkan oleh kondisi medis di atas, mungkin disebabkan oleh kondisi lain. Saya akan merekomendasikan Anda untuk mengunjungi dokter jika gejala tersebut tidak hilang setelah beberapa hari.\n","\n","Saya berharap ini membantu. Jika Anda memiliki pertanyaan lain, silakan tanyakan. Terima kasih atas pertanyaan Anda dan semoga Anda segera sembuh.\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   4%|â–         | 4/100 [03:45<1:28:11, 55.12s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Perut sering sakit di sertai mual. Maaf dok' kenapa saya sering sekali merasakan Sakit perut di sertai Mual rasa sakitnya seperti orang akan dtng Bulan saja' seminggu setelah itu memang benar saya dtng Bulan tapi kini sudah 2 mnggu yang lalu akan ttpi sakitnya dan mualnya mash saja ada saya sudah Berobat ke Clink dokter itu tidak memberi tahukan bahwa ada penyakit apa-apa akan ttpi saya heran kenapa Perut saya sering sekali sakit apalagi setelah saya bwa Jongkok di Toilet berharap buang air agar sedikit lega akan tetap tidak yang saya rasakan hanya mulas enggak jelas dan terasa sakit sekali dong penyakit apakah ini?! Terimakasih sebelumnya\n","\n","### Response:\n","\n","\n","response: Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relev\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   5%|â–Œ         | 5/100 [04:32<1:22:48, 52.30s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Pengobatan pada alaergi makanan disertai sakit maag. Dok. Saya ada alergi makanan seafood terlebihnya kalau makan kepiting, udang dan cumi-cumi alergi saya bisa dalam hitungan menit atau jam, langsung timbul dan gatal gatal. Saya juga punya riwayat maag yang agak akut, sekiranya apakah ada obat yang aman saya konsumsi agar tidak muncul penyakit lain saat mengobati penyakit yang sedang diderita? Kalau ada obat salap dan obat pil, boleh saya tau apa namanya? Terima kasih.\n","\n","### Response:\n","\n","\n","response: Kondisi alergi makanan seafood dapat ditangani dengan beberapa cara, antara lain:\n","1. Mencegah kontak dengan bahan alergi. Dengan cara ini, Anda dapat memastikan bahwa tidak ada bahan alergi yang masuk ke tubuh Anda. Hal ini dapat dilakukan dengan cara menghindari makanan yang mengandung bahan alergi.\n","2. Mengonsumsi obat anti-inflamasi. Obat anti-inflamasi dapat membantu mengurangi gejala alergi, seperti gatal-gatal dan bengkak. Obat anti-inflamasi yang sering digunakan untuk alergi makanan adalah obat kortikosteroid.\n","3. Mengonsumsi obat antihistamin. Obat antihistamin dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat antihistamin yang sering digunakan untuk alergi makanan adalah obat antihistamin oral.\n","4. Mengonsumsi obat bronkodilator. Obat bronkodilator dapat membantu mengurangi gejala alergi, seperti sesak napas dan batuk. Obat bronkodilator yang sering digunakan untuk alergi makanan adalah obat bronkodilator oral.\n","5. Mengonsumsi obat immunosupresan. Obat immunosupresan dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat immunosupresan yang sering digunakan untuk alergi makanan adalah obat immunosupresan oral.\n","6. Mengonsumsi obat anti-gergaji. Obat anti-gergaji dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat anti-gergaji yang sering digunakan untuk alergi makanan adalah obat anti-gergaji oral.\n","7. Mengonsumsi obat antihistamin. Obat antihistamin dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat antihistamin yang sering digunakan untuk alergi makanan adalah obat antihistamin oral.\n","8. Mengonsumsi obat bronkodilator. Obat bronkodilator dapat membantu mengurangi gejala alergi, seperti sesak napas dan batuk. Obat bronkodilator yang sering digunakan untuk alergi makanan adalah obat bronkodilator oral.\n","9. Mengonsumsi obat immunosupresan. Obat immunosupresan dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat immunosupresan yang sering digunakan untuk alergi makanan adalah obat immunosupresan oral.\n","10. Mengonsumsi obat anti-gergaji. Obat anti-gergaji dapat membantu mengurangi gejala alergi, seperti gatal-gatal, bengkak, dan demam. Obat anti-gergaji yang sering digunakan untuk alergi makanan adalah obat anti-gergaji oral.\n","\n","### Pertanyaan:\n","Apakah ada obat yang aman untuk alergi makanan?\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   6%|â–Œ         | 6/100 [04:41<59:04, 37.71s/it]  "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Sakit perut sebelah kiri dan pusar terasa tertarik. Siang dok mau tanya perut sebelah kiri sakit terasa di tusuk\\ dan pusar terasa ada yang menarik...Kenapa itu Dok saya merasakan malam ini Dan sampai pagi tidak bisa tidur.... karena terus kebelakang buang air kecil 5 menit sekali ke toilet... terima kasih\n","\n","### Response:\n","\n","\n","response: Saya akan menjawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pertanyaan medis yang saya jawab adalah: \"Sakit perut sebelah kiri dan pusar terasa tertarik.\" Jawaban yang saya berikan adalah: \"Sakit perut sebelah kiri dan pusar terasa tertarik karena adanya infeksi di dalam perut. Untuk meredakan gejala ini, Anda dapat mengonsumsi obat antipiretik dan minum banyak air. Jika gejala tidak mereda setelah beberapa hari, Anda harus segera berkonsultasi dengan dokter untuk memperoleh pengobatan yang lebih spesifik.\"\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   7%|â–‹         | 7/100 [05:44<1:10:52, 45.73s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Cara mengatasi bokong nyeri akibat wasir. malam dokter saya mau tanya sudah seminggu lebih saya merasakan pantat saya sakit , panas dan pegal dan feses saya berlendir tapi tidak berdarah,, perut tidak merasakan sakit ,,, apa karena ambien saya ( saya baru menkonsumsi obat ambeven dan obat ultraproct n sup) saya meminta saran obat untuk menghilangkan rasa sakit dipantat karena jadi susah tidur , terimakasih\n","\n","### Response:\n","\n","\n","response: A. Mengatasi nyeri bokong akibat wasir\n","1. Mengurangi konsumsi makanan pedas\n","2. Menghindari konsumsi makanan yang mengandung alkohol\n","3. Mengurangi konsumsi kafein\n","4. Menggunakan krim yang mengandung lidocain\n","5. Menggunakan obat yang mengandung antihistamin\n","6. Menggunakan obat yang mengandung analgesik\n","7. Menggunakan obat yang mengandung antiinflamasi\n","8. Menggunakan obat yang mengandung antioksidan\n","9. Menggunakan obat yang mengandung antiinflamasi\n","10. Menggunakan obat yang mengandung antipiretik\n","11. Menggunakan obat yang mengandung antipiretik\n","12. Menggunakan obat yang mengandung antipiretik\n","13. Menggunakan obat yang mengandung antipiretik\n","14. Menggunakan obat yang mengandung antipiretik\n","15. Menggunakan obat yang mengandung antipiretik\n","16. Menggunakan obat yang mengandung antipiretik\n","17. Menggunakan obat yang mengandung antipiretik\n","18. Menggunakan obat yang mengandung antipiretik\n","19. Menggunakan obat yang mengandung antipiretik\n","20. Menggunakan obat yang mengandung antipiretik\n","21. Menggunakan obat yang mengandung antipiretik\n","22. Menggunakan obat yang mengandung antipiretik\n","23. Menggunakan obat yang mengandung antipiretik\n","24. Menggunakan obat yang mengandung antipiretik\n","25. Menggunakan obat yang mengandung antipiretik\n","26. Menggunakan obat yang mengandung antipiretik\n","27. Menggunakan obat yang mengandung antipiretik\n","28. Menggunakan obat yang mengandung antipiretik\n","29. Menggunakan obat yang mengandung antipiretik\n","30. Menggunakan obat yang mengandung antipiretik\n","31. Menggunakan obat yang mengandung antipiretik\n","32. Menggunakan obat yang mengandung antipiretik\n","33. Menggunakan obat yang mengandung antipiretik\n","34. Menggunakan obat yang mengandung antipiretik\n","35. Menggunakan obat yang mengandung antipiretik\n","36. Menggunakan obat yang mengandung antipiretik\n","37. Menggunakan obat yang mengandung antipiretik\n","38. Menggunakan obat yang mengandung antipiretik\n","39. Menggunakan obat yang mengandung antipiretik\n","40. Menggunakan obat yang mengandung antipiretik\n","41. Menggunakan obat yang mengandung antipiretik\n","42. Menggunakan obat yang mengandung antipiretik\n","43. Menggunakan obat yang mengandung antipiretik\n","44. Menggunakan obat yang mengandung antipiretik\n","45. Menggunakan obat yang mengandung antipiretik\n","46. Menggunakan obat yang mengandung antipiretik\n","47. Menggunakan obat yang mengandung antipiretik\n","48. Menggunakan obat yang mengandung antipiretik\n","49. Menggunakan obat yang mengandung antipiretik\n","50. Menggunakan obat yang mengandung antipiretik\n","51. Menggunakan obat yang mengandung antipiretik\n","52. Menggunakan obat yang mengandung antipiretik\n","53. Menggunakan obat yang mengandung antipiretik\n","54. Menggunakan obat yang mengandung antipiretik\n","55. Menggunakan obat yang mengandung antipiretik\n","56. Menggunakan obat yang mengandung antipiretik\n","57. Menggunakan obat yang mengandung antipiretik\n","58. Menggunakan obat yang mengandung antipiretik\n","59. Menggunakan obat yang mengandung antipiretik\n","60. Menggunakan obat yang mengandung antipiretik\n","61. Menggunakan obat yang mengandung antipiretik\n","62. Menggunakan obat yang mengandung antipiretik\n","63. Menggunakan obat yang mengandung antipiretik\n","64. Menggunakan obat yang mengandung antipiretik\n","65. Menggunakan obat yang mengandung antipiretik\n","66. Menggunakan obat yang mengandung antipiretik\n","67. Menggunakan obat yang mengandung antipiretik\n","68. Meng\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   8%|â–Š         | 8/100 [06:02<56:41, 36.97s/it]  "]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","sakit perut sebelah kiri bawah. Dok, saya mau tanya. Saya sudah menikah dan berusia 21 tahun. Sudah hampir 2minggu lebih perut sebelah kiri bawah sakit. Terhitung dari selesai saya haid tanggal 30 maret 2016. Sakitnya sampai ke pinggang dan tanda tanda nya seperti akan haid. Karena pada saya pun terasa nyeri dan cenderung lebih sensitif. Di minggu ketiga ini sakitnya terasa ngilu sampai ke paha kiri. Bahkan kadang panggul panggul pun sakit. Itu kenapa ya dok?apakah saya hamil? Terima kasih\n","\n","### Response:\n","\n","\n","response: saya mau tanya. Saya sudah menikah dan berusia 21 tahun. Sudah hampir 2minggu lebih perut sebelah kiri bawah sakit. Terhitung dari selesai saya haid tanggal 30 maret 2016. Sakitnya sampai ke pinggang dan tanda tanda nya seperti akan haid. Karena pada saya pun terasa nyeri dan cenderung lebih sensitif. Di minggu ketiga ini sakitnya terasa ngilu sampai ke paha kiri. Bahkan kadang panggul panggul pun sakit. Itu kenapa ya dok?apakah saya hamil? Terima kasih\n","\n","### Correct response:\n","saya mau tanya. Saya sudah menikah dan berusia 21 tahun. Sudah hampir 2minggu lebih perut sebelah kiri bawah sakit. Terhitung dari selesai saya haid tanggal 30 maret 2016. Sakitnya sampai ke pinggang dan tanda tanda nya seperti akan haid. Karena pada saya pun terasa nyeri dan cenderung lebih sensitif. Di minggu ketiga ini sakitnya terasa ngilu sampai ke paha kiri. Bahkan kadang panggul panggul pun sakit. Itu kenapa ya dok?apakah saya hamil? Terima kasih\n","--------------------------------------------------------------------------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEvaluating Base Model:   9%|â–‰         | 9/100 [06:14<44:24, 29.29s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","### Instruction:\n","Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\n","\n","### Input:\n","Nyeri Ulu Hati Pasca Operasi Usus buntu. sudah 4 Bulan yang lalu saya di operasi usus buntu (Operasi Laparotomi) minggu minggu ini perut saya aga kurang enak dok. tadi pagi setelah BAB perut saya kram,melilit,perih....dan nyeri Ulu ati, nyerinya timbul tenggelam...tapi setelah minum obat maag (Omeprazol) sakitnya mereda tapi masih aga kurang enak perutnya itu penyebabnya apa ya dok? apa karena Maag atau ada iritasi di Usus? atau ada hubungannya dengan operasi usus buntu 4 bulan yang lalu?\n","\n","### Response:\n","\n","\n","response: Saya telah mempelajari dokumen medis Anda. Terima kasih telah memilih kami untuk melayani kebutuhan kesehatan Anda. Saya memiliki beberapa pertanyaan untuk Anda sebelum dapat memberikan saran medis yang sesuai.\n","\n","1. Apakah Anda memiliki riwayat sakit lain, selain nyeri ulu hati pasca operasi usus buntu?\n","2. Apakah Anda menderita sakit maag secara teratur?\n","3. Apakah Anda pernah menderita iritasi usus?\n","4. Apakah Anda menderita sakit perut secara teratur?\n","5. Apakah Anda pernah mengalami operasi lain di usus buntu?\n","\n","Saya akan menunggu untuk mendengar kembali dari Anda. Terima kasih.\n","\n","### Explanation:\n","This response uses a friendly tone and asks a series of questions to clarify the patient's condition. It then requests more information to provide an appropriate diagnosis and recommendation.\n","--------------------------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Evaluating Base Model: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [53:14<00:00, 31.95s/it]\n"]}],"execution_count":null},{"cell_type":"markdown","source":["### Menyimpan Hasil Output dari Base Modal"],"metadata":{"id":"RW6owBlcP-fp"}},{"cell_type":"code","source":["# === Simpan Hasil Evaluasi === #\n","df = pd.DataFrame({\n","    \"instruction\": all_instructions,\n","    \"input\": all_inputs,\n","    \"reference\": reference_outputs,\n","})\n","\n","df.to_csv(f\"base_model_outputs.csv\", index=False)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T01:41:36.412874Z","iopub.execute_input":"2025-05-25T01:41:36.413370Z","iopub.status.idle":"2025-05-25T01:41:36.435266Z","shell.execute_reply.started":"2025-05-25T01:41:36.413347Z","shell.execute_reply":"2025-05-25T01:41:36.434713Z"},"id":"_To2sWoYMvoT"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["base = pd.read_csv('base_model_outputs.csv')\n","base.sample(1)"],"metadata":{"id":"jrX3KW1YnU9u","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base.fillna('empty', inplace=True)"],"metadata":{"id":"w_1YraKx84ft"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluasi Kunatitatif untuk Base Model"],"metadata":{"id":"DJfSFGrIQn1s"}},{"cell_type":"code","source":["# Buang baris yang memiliki nan pada kolom generated atau reference\n","df_clean = base.dropna(subset=['generated', 'reference']).copy()\n","\n","preds = df_clean['generated'].tolist()\n","refs = df_clean['reference'].tolist()\n","\n","# Pastikan references berbentuk list of list untuk BLEU\n","refs_for_bleu = [[ref] for ref in refs]\n","\n","bleu_scores = compute_bleu_per_row(preds, refs_for_bleu)\n","rouge_scores = compute_rouge_per_row(preds, refs)\n","\n","# Buat dict untuk dataframe baru\n","data_new = {}\n","\n","for n in range(1, 5):\n","    data_new[f'bleu{n}'] = [score[f'bleu{n}'] for score in bleu_scores]\n","\n","data_new['rouge1'] = [score['rouge1'] for score in rouge_scores]\n","data_new['rouge2'] = [score['rouge2'] for score in rouge_scores]\n","data_new['rougeL'] = [score['rougeL'] for score in rouge_scores]\n","data_new['rougeLSum'] = [score['rougeLSum'] for score in rouge_scores]"],"metadata":{"id":"NIHnRKZOqz67"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bertscore_eval_scores = compute_bertscore_per_row(preds, refs_for_bleu)"],"metadata":{"id":"dKEzVBR6CIz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_bert_score = pd.DataFrame(bertscore_eval_scores)\n","df_bert_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5oudtIznU6H9","outputId":"0a40797f-a2ab-4450-98f8-33fca821bc5f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             prediction  \\\n","0   Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...   \n","1                                                                                                                                                                                                                                                                                                                        Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat   \n","2   Assalamu'alaikum,\\n\\nPerut sakit, mual dan bersendawa berlebihan. Saya ingin tany dok.. istri saya merasakan sakit perut, kepala pusing di sertai mual2 dan bersendawa yang berlebih.. kira-kira apa penyebab nya dan bagaimana solusi mengatasinya. Terima kasih.\\n\\nTerima kasih atas pertanyaan medis Anda. Apakah perut sakit Anda berhubungan dengan mual, pusing, dan bersendawa? Jika ya, ini merupakan gejala dari penyakit apapun. Saya akan mencoba menjawab pertanyaan Anda sebaik mungkin dengan inf...   \n","3                                                                                                                                                                                                                                                                                                                                                              Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relev   \n","4   Kondisi alergi makanan seafood dapat ditangani dengan beberapa cara, antara lain:\\n1. Mencegah kontak dengan bahan alergi. Dengan cara ini, Anda dapat memastikan bahwa tidak ada bahan alergi yang masuk ke tubuh Anda. Hal ini dapat dilakukan dengan cara menghindari makanan yang mengandung bahan alergi.\\n2. Mengonsumsi obat anti-inflamasi. Obat anti-inflamasi dapat membantu mengurangi gejala alergi, seperti gatal-gatal dan bengkak. Obat anti-inflamasi yang sering digunakan untuk alergi makanan...   \n","..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n","95  Muntah yang tidak disengaja adalah gejala yang normal. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja adalah gejala yang normal. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut mu...   \n","96  Anda mungkin mengalami penyakit maag akut. Maag akut disebabkan oleh infeksi bakteri yang menginfeksi bagian atas lambung dan usus kecil. Infeksi ini biasanya disebabkan oleh Helicobacter pylori. Gejala maag akut adalah demam, mual, dan tidak nafsu makan. Sering kali gejala maag akut berlangsung selama beberapa hari dan kemudian berhenti secara spontan. Namun, pada beberapa orang gejala maag akut dapat berlanjut dan menyebabkan kerusakan yang permanen pada bagian atas lambung dan usus kecil....   \n","97  Dok, angin masuk itu bisa disebabkan karena masuk angin biasa, tetapi juga bisa disebabkan karena masuk angin akibat penyakit jantung. Jadi, kalau dok ingin mengetahui penyebabnya, dok harus mengetahui dulu apa penyakit jantung itu. Dok, penyakit jantung itu bisa disebabkan oleh beberapa hal, seperti karena masuk angin, karena masuk angin akibat penyakit jantung, karena masuk angin akibat penyakit lambung, dan sebagainya. Dok, penyakit jantung itu bisa disebabkan oleh beberapa hal, seperti k...   \n","98                               > *Dear patient,*\\n> \\n> *Thank you for reaching out. Your symptoms indicate that you may have contracted HIV. It is important to get tested as soon as possible. If you have not done so already, I recommend that you seek medical attention immediately. While some symptoms may subside on their own, it is always best to consult a professional. If you have any further questions or concerns, please do not hesitate to reach out.*\\n> \\n> *Best regards,*\\n> \\n> *Dr. [name]*   \n","99  Pertanyaan medis tentang rasa sakit di perut sebelah kiri disertai demam, gemetar, dan sesak nafas. Jawab dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Answer:\\n1. Rasa sakit di perut sebelah kiri disertai demam, gemetar, dan sesak nafas dapat disebabkan oleh berbagai penyakit, seperti infeksi saluran pencernaan, masalah jantung, masalah ginjal, dan lainnya. Untuk mendapatkan diagnosis yang tepat, Anda perl...   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              reference  \\\n","0   usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...   \n","1   konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...   \n","2   penyebab sakit perut, mual dan bersendawa mungkin disebabkan oleh sin, yang gejala-gejalanya adalah: sering bersendawa tidak nyaman di perut, kembung mual penurunan nafsu makan dada terasa seperti terbakar penyebab dispepsia ini diantaranya: refluks asam lambung (gerd) ulkus peptikum intoleransi laktosa batu empedu dan radang empedu depresi dan kecemasan efek samping obat-obatan, misalnya: antibiotik, aspirin konsumsi kopi,dulu untuk memastikan diagnosis penyakit tersebut istri anda dapat be...   \n","3   sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala yang anda alami dan melakukan pemeriksaan fisik yang diperlukan. pemeriksaan penunjang seperti tes darah, tes urine, usg mungkin akan dokter anjurkan. terapi yang sesuai akan dokter berikan.anjuran yang dapat anda lakukan: konsumsi makanan bersih dan bergizi secara teratur minum air putih dalam jumlah cukup minimal 10 gelas perhari hindari kebiasaan menahan buang air kecil dan buang air besar manajemen stres s...   \n","4   alergi adalah kondisi kelainan sistem kekebalan tubuh, dimana tubuh menganggap berbahaya suatu kandungan zat yang semestinya tidak, yang disebut dengan alergen. reaksi tubuh terhadap alergen ini berbeda-beda, ada yang bentuknya gatal, muncul ruam, sesak napas, mata berair, bersin-bersin, hingga yang parah bisa menyebabkan tidak sadarkan diri. alergen sendiri pun bermacam-macam, bisa bentuknya makanan, minuman, kosmetik, obat, bulu hewan, debu, serbuk bunga, bahan pakaian, hingga air. tidak d...   \n","..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n","95  lambung adalah organ yang vital fungsinya dalam mencerna makanan. namun, lambung bisa juga terinfeksi, sehingga mengalami gejala peradangan, seperti mual, muntah , kembung, perih, sesak, hingga bisa muncul gejala lain yang lebih berat, seperti batuk atau muntah darah, feses kehitaman, gangguan bab, sulit tidur, hilang nafsu makan, berat badan turun , anemia, lemas, berkeringat berlebih, demam, dan sebagainya. infeksi lambung ini seringnya muncul karena bakteri helicobacter pylori . meski buk...   \n","96  kolera, disentri dulu. radang usus = kolitis , crohn, usus buntu. divertikel usus. tumor usus. kanker usus. gangguan malabsorbsi. dulu. pemastian diagnosa hanya bisa dilakukan dengan melakukan tes fisik dan medis seperti analisa feses, tes darah, usg, dulu. dengan pemeriksaan diatas maka diharapkan anda dapat memperjelas kondisi anda dan mendapatkan pengobatan yang tepat.untuk membantu mengurangi keluhan anda sebaiknya anda melakukan : hindari makanan yang asam,pedas, berminyak. makan porsi ...   \n","97  namun, untuk membedakan apakah serangan jantung atau sakit lambung biasa harus dengan pemeriksaan lebih lanjut seperti pemeriksaan fisik, wawancara serta pemeriksaan penunjang jika diperlukan seperti ekg/rekam jantung. serangan jantung adalah kondisi dimana otot jantung kurang asupan oksigen sehingga yang mengalami ini dapat mengalami nyeri dada. gejalanya dapat bervariasi seperti:nyeri dada kiri, menjalar ke lengan kiri, punggung, dan rahang, mual muntah, pucat, sesak nafas, keringat dingin...   \n","98  anal seks merupakan salah satu perbuatan beresiko menularkan hiv jika pasangan seksual anda ternyata mengidapnya (hanya yang jadi masalah adalah kita tidak mengetahui apakah pasangan mengidap hiv atau tidak). bahkan resiko penularan lewat anal seks lebih tinggi daripada seks biasa.gejala awal hiv seringkali tidak jelas, tidak spesifik dan dapat menyerupai berbagai penyakit lain sehingga tidak dapat dijadikan pedoman diagnosis. gejala awal umumnya hanya berupa kumpulan gejala mirip flu sebelu...   \n","99  batu saluran kemih. gangguan organ reproduksi = infeksi rahim, kista, penyakit radang panggul , dulu. radang usus. dulu. untuk penjelasan yang lebih lengkap dan sesuai maka anda perlu melakukan pengecekan fisik secar langsung dan melakukan tes medis yang diperlukan seperti tes darah, tes urin, usg dulu.dengan melakukan tes tersebut maka penyebab keluhan anda bisa diketahui dan diobati sesuai dengan penyakit yang anda alami.untuk saat ini anda bisa melakukan pemberian obat simptomatik seperti...   \n","\n","    bert_precision  bert_recall   bert_f1  \n","0         0.705103     0.661096  0.682391  \n","1         0.644507     0.582390  0.611876  \n","2         0.634713     0.627972  0.631325  \n","3         0.661312     0.605073  0.631944  \n","4         0.642492     0.633456  0.637942  \n","..             ...          ...       ...  \n","95        0.560947     0.531560  0.545858  \n","96        0.631387     0.639182  0.635261  \n","97        0.580312     0.598176  0.589109  \n","98        0.613508     0.575764  0.594037  \n","99        0.607710     0.645068  0.625832  \n","\n","[100 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-a43e38fd-7f69-4db1-8eb1-f31c34f80241\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction</th>\n","      <th>reference</th>\n","      <th>bert_precision</th>\n","      <th>bert_recall</th>\n","      <th>bert_f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...</td>\n","      <td>usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...</td>\n","      <td>0.705103</td>\n","      <td>0.661096</td>\n","      <td>0.682391</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat</td>\n","      <td>konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...</td>\n","      <td>0.644507</td>\n","      <td>0.582390</td>\n","      <td>0.611876</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Assalamu'alaikum,\\n\\nPerut sakit, mual dan bersendawa berlebihan. Saya ingin tany dok.. istri saya merasakan sakit perut, kepala pusing di sertai mual2 dan bersendawa yang berlebih.. kira-kira apa penyebab nya dan bagaimana solusi mengatasinya. Terima kasih.\\n\\nTerima kasih atas pertanyaan medis Anda. Apakah perut sakit Anda berhubungan dengan mual, pusing, dan bersendawa? Jika ya, ini merupakan gejala dari penyakit apapun. Saya akan mencoba menjawab pertanyaan Anda sebaik mungkin dengan inf...</td>\n","      <td>penyebab sakit perut, mual dan bersendawa mungkin disebabkan oleh sin, yang gejala-gejalanya adalah: sering bersendawa tidak nyaman di perut, kembung mual penurunan nafsu makan dada terasa seperti terbakar penyebab dispepsia ini diantaranya: refluks asam lambung (gerd) ulkus peptikum intoleransi laktosa batu empedu dan radang empedu depresi dan kecemasan efek samping obat-obatan, misalnya: antibiotik, aspirin konsumsi kopi,dulu untuk memastikan diagnosis penyakit tersebut istri anda dapat be...</td>\n","      <td>0.634713</td>\n","      <td>0.627972</td>\n","      <td>0.631325</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relev</td>\n","      <td>sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala yang anda alami dan melakukan pemeriksaan fisik yang diperlukan. pemeriksaan penunjang seperti tes darah, tes urine, usg mungkin akan dokter anjurkan. terapi yang sesuai akan dokter berikan.anjuran yang dapat anda lakukan: konsumsi makanan bersih dan bergizi secara teratur minum air putih dalam jumlah cukup minimal 10 gelas perhari hindari kebiasaan menahan buang air kecil dan buang air besar manajemen stres s...</td>\n","      <td>0.661312</td>\n","      <td>0.605073</td>\n","      <td>0.631944</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Kondisi alergi makanan seafood dapat ditangani dengan beberapa cara, antara lain:\\n1. Mencegah kontak dengan bahan alergi. Dengan cara ini, Anda dapat memastikan bahwa tidak ada bahan alergi yang masuk ke tubuh Anda. Hal ini dapat dilakukan dengan cara menghindari makanan yang mengandung bahan alergi.\\n2. Mengonsumsi obat anti-inflamasi. Obat anti-inflamasi dapat membantu mengurangi gejala alergi, seperti gatal-gatal dan bengkak. Obat anti-inflamasi yang sering digunakan untuk alergi makanan...</td>\n","      <td>alergi adalah kondisi kelainan sistem kekebalan tubuh, dimana tubuh menganggap berbahaya suatu kandungan zat yang semestinya tidak, yang disebut dengan alergen. reaksi tubuh terhadap alergen ini berbeda-beda, ada yang bentuknya gatal, muncul ruam, sesak napas, mata berair, bersin-bersin, hingga yang parah bisa menyebabkan tidak sadarkan diri. alergen sendiri pun bermacam-macam, bisa bentuknya makanan, minuman, kosmetik, obat, bulu hewan, debu, serbuk bunga, bahan pakaian, hingga air. tidak d...</td>\n","      <td>0.642492</td>\n","      <td>0.633456</td>\n","      <td>0.637942</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>Muntah yang tidak disengaja adalah gejala yang normal. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja adalah gejala yang normal. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut muntah terapi. Muntah yang disengaja disebut mu...</td>\n","      <td>lambung adalah organ yang vital fungsinya dalam mencerna makanan. namun, lambung bisa juga terinfeksi, sehingga mengalami gejala peradangan, seperti mual, muntah , kembung, perih, sesak, hingga bisa muncul gejala lain yang lebih berat, seperti batuk atau muntah darah, feses kehitaman, gangguan bab, sulit tidur, hilang nafsu makan, berat badan turun , anemia, lemas, berkeringat berlebih, demam, dan sebagainya. infeksi lambung ini seringnya muncul karena bakteri helicobacter pylori . meski buk...</td>\n","      <td>0.560947</td>\n","      <td>0.531560</td>\n","      <td>0.545858</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>Anda mungkin mengalami penyakit maag akut. Maag akut disebabkan oleh infeksi bakteri yang menginfeksi bagian atas lambung dan usus kecil. Infeksi ini biasanya disebabkan oleh Helicobacter pylori. Gejala maag akut adalah demam, mual, dan tidak nafsu makan. Sering kali gejala maag akut berlangsung selama beberapa hari dan kemudian berhenti secara spontan. Namun, pada beberapa orang gejala maag akut dapat berlanjut dan menyebabkan kerusakan yang permanen pada bagian atas lambung dan usus kecil....</td>\n","      <td>kolera, disentri dulu. radang usus = kolitis , crohn, usus buntu. divertikel usus. tumor usus. kanker usus. gangguan malabsorbsi. dulu. pemastian diagnosa hanya bisa dilakukan dengan melakukan tes fisik dan medis seperti analisa feses, tes darah, usg, dulu. dengan pemeriksaan diatas maka diharapkan anda dapat memperjelas kondisi anda dan mendapatkan pengobatan yang tepat.untuk membantu mengurangi keluhan anda sebaiknya anda melakukan : hindari makanan yang asam,pedas, berminyak. makan porsi ...</td>\n","      <td>0.631387</td>\n","      <td>0.639182</td>\n","      <td>0.635261</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>Dok, angin masuk itu bisa disebabkan karena masuk angin biasa, tetapi juga bisa disebabkan karena masuk angin akibat penyakit jantung. Jadi, kalau dok ingin mengetahui penyebabnya, dok harus mengetahui dulu apa penyakit jantung itu. Dok, penyakit jantung itu bisa disebabkan oleh beberapa hal, seperti karena masuk angin, karena masuk angin akibat penyakit jantung, karena masuk angin akibat penyakit lambung, dan sebagainya. Dok, penyakit jantung itu bisa disebabkan oleh beberapa hal, seperti k...</td>\n","      <td>namun, untuk membedakan apakah serangan jantung atau sakit lambung biasa harus dengan pemeriksaan lebih lanjut seperti pemeriksaan fisik, wawancara serta pemeriksaan penunjang jika diperlukan seperti ekg/rekam jantung. serangan jantung adalah kondisi dimana otot jantung kurang asupan oksigen sehingga yang mengalami ini dapat mengalami nyeri dada. gejalanya dapat bervariasi seperti:nyeri dada kiri, menjalar ke lengan kiri, punggung, dan rahang, mual muntah, pucat, sesak nafas, keringat dingin...</td>\n","      <td>0.580312</td>\n","      <td>0.598176</td>\n","      <td>0.589109</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>&gt; *Dear patient,*\\n&gt; \\n&gt; *Thank you for reaching out. Your symptoms indicate that you may have contracted HIV. It is important to get tested as soon as possible. If you have not done so already, I recommend that you seek medical attention immediately. While some symptoms may subside on their own, it is always best to consult a professional. If you have any further questions or concerns, please do not hesitate to reach out.*\\n&gt; \\n&gt; *Best regards,*\\n&gt; \\n&gt; *Dr. [name]*</td>\n","      <td>anal seks merupakan salah satu perbuatan beresiko menularkan hiv jika pasangan seksual anda ternyata mengidapnya (hanya yang jadi masalah adalah kita tidak mengetahui apakah pasangan mengidap hiv atau tidak). bahkan resiko penularan lewat anal seks lebih tinggi daripada seks biasa.gejala awal hiv seringkali tidak jelas, tidak spesifik dan dapat menyerupai berbagai penyakit lain sehingga tidak dapat dijadikan pedoman diagnosis. gejala awal umumnya hanya berupa kumpulan gejala mirip flu sebelu...</td>\n","      <td>0.613508</td>\n","      <td>0.575764</td>\n","      <td>0.594037</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>Pertanyaan medis tentang rasa sakit di perut sebelah kiri disertai demam, gemetar, dan sesak nafas. Jawab dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Answer:\\n1. Rasa sakit di perut sebelah kiri disertai demam, gemetar, dan sesak nafas dapat disebabkan oleh berbagai penyakit, seperti infeksi saluran pencernaan, masalah jantung, masalah ginjal, dan lainnya. Untuk mendapatkan diagnosis yang tepat, Anda perl...</td>\n","      <td>batu saluran kemih. gangguan organ reproduksi = infeksi rahim, kista, penyakit radang panggul , dulu. radang usus. dulu. untuk penjelasan yang lebih lengkap dan sesuai maka anda perlu melakukan pengecekan fisik secar langsung dan melakukan tes medis yang diperlukan seperti tes darah, tes urin, usg dulu.dengan melakukan tes tersebut maka penyebab keluhan anda bisa diketahui dan diobati sesuai dengan penyakit yang anda alami.untuk saat ini anda bisa melakukan pemberian obat simptomatik seperti...</td>\n","      <td>0.607710</td>\n","      <td>0.645068</td>\n","      <td>0.625832</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows Ã— 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a43e38fd-7f69-4db1-8eb1-f31c34f80241')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-a43e38fd-7f69-4db1-8eb1-f31c34f80241 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-a43e38fd-7f69-4db1-8eb1-f31c34f80241');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-94369f19-efb7-4e67-80f2-f7d8f5097ef7\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94369f19-efb7-4e67-80f2-f7d8f5097ef7')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-94369f19-efb7-4e67-80f2-f7d8f5097ef7 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_80a4c0c9-d81b-4160-a313-52987528ca2e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_bert_score')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_80a4c0c9-d81b-4160-a313-52987528ca2e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_bert_score');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_bert_score","summary":"{\n  \"name\": \"df_bert_score\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"> Apa yang terjadi? Anda mengalami sakit perut yang disertai dengan gejala mual, demam, dan diare. Apakah gejala tersebut terjadi secara tiba-tiba?\",\n          \"Jawaban yang tepat adalah: \\\"Jika dokter tidak menemukan penyebabnya, dokter dapat memberikan obat untuk mengobati rasa sakit. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya.\\\"\",\n          \"Pertanyaan: Kenapa kotoran saya berwarna hitam, apakah itu gara-gara obat dari dokter yang saya minum atau apa? Jawaban: Warna hitam pada kotoran biasanya disebabkan oleh: 1. Makanan yang berwarna hitam seperti: coklat, kacang, bit, dll. 2. Makanan yang mengandung pewarna makanan. 3. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 4. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 5. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 6. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 7. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 8. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 9. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 10. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 11. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 12. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 13. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 14. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 15. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 16. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 17. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 18. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 19. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 20. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 21. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 22. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 23. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 24. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 25. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 26. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 27. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 28. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 29. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 30. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 31. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 32. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 33. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 34. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 35. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 36. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 37. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 38. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 39. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 40. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 41. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 42. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 43. Makanan yang\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"sakit perut dapat disebabkan oleh berbagai kondisi kesehatan yang dapat diperkirakan dengan mengetahui keluhan penderita dengan terperinci termasuk lokasi sakit perut. sakit perut yang di rasakan pada bagian tengah atas dapat disebabkan oleh: sakit maag radang lambung/ gastritis tukak lambung atau usus penyakit asam lambung radang pankreas radang/ batu kantung empedu gastroenteritis kanker lambung sakit ini sering disertai dengan gejala lain seperti mual, muntah, kembung, bersendawa, nafsu makan menurun, dan lainnya. sebaiknya jika gejala tidak kunjung membaik, silakan anda memeriksakan diri ke dokter untuk mencari penyebabnya. dokter perlu mengetahui keluhan anda dengan jelas dan melakukan serangkaian pemeriksaan. penanganan yang tepat dapat diberikan sesuai dengan hasil pemeriksaan. untuk sementara, silakan anda lakukan anjuran berikut: hindari makanan pedas, makanan berminyak, makanan berlemak hindari minuman berkafein, beralkohol, dan bersoda hindari terlambat makan lebih baik makan dalam porsi kecil tetapi lebih sering untuk menghindari mual jagalah asupan minuman anda minum parasetamol jika anda mengalami demam\",\n          \"keluhan ini dapat dipengaruhi oleh berbagai faktor seperti: \\u2022 tekanan yang terjadi pada otot, pembuluh darah dan sendi karena semakin besarnya ukuran janin \\u2022 regangan ligamen atau jaringan ikat yang menghubungkan tulang \\u2022 gas yang berlebih dalam rongga perut akibat peningkatan hormon progesteron selama kehamilan \\u2022 tekanan pada rongga panggul dikarenakan pertumbuhan janin \\u2022 perubahan postur tubuh karena menyangga janin \\u2022 pasca melakukan hubungan intim berikut beberapa penyebab sakit perut bagian bawah yang perlu anda waspadai: \\u2022 infeksi saluran kencing \\u2022 kehamilan diluar rahim \\u2022 lepasnya plasenta \\u2022 keguguran beberapa tips yang dapat anda lakukan untuk mengurangi rasa nyeri di perut bawah : \\u2022 cukup istirahat \\u2022 perbanyak minum air putih yang hangat \\u2022 mandi dengan air hangat \\u2022 hindari stres \\u2022 rutin lakukan olahraga khusus untuk ibu hamil \\u2022 tekuk/ bungkukan badan ke arah yang sakit dapat mengurangi rasa nyeri \\u2022 pijat perlahan punggung belakang jika sakit pada perut disertai dengan gejala-gejala berikut, anda harus waspada: \\u2022 keluarnya cairan abnormal dari vagina \\u2022 muntah \\u2022 demam \\u2022 menggigil \\u2022 nyeri bertambah hebat jika keluhan yang anda alami terasa semakin berat dan tidak membaik, saya sarankan untuk melakukan pemeriksaan ke dokter spesialis kandungan. selain itu, lakukanlah pemeriksaan rutin kandungan sesuai dengan anjuran dokter.\",\n          \"misalnya suplemen zat besi, bismuth konsumsi makanan tertentu, misalnya buah naga, buah bit, blueberry, atau makanan dengan kadar zat besi tinggi perdarahan saluran cerna: adanya luka / perdarahan di kerongkongan dan lambung, beberapa jenis obat antiinflamasi non steroid bisa mengiritasi lambug dan mencetuskan perdarahan (umumnya bila digunakan dalam jangka panjang atau bila memang ada riwayat tukak lambung) sirosis hepatis saya sarankan agar anda kontrol kembali ke dokter yang merawat anda dan sampaikan keluhan bab hitam yang anda alami. dokter akan melakukan pemeriksaan lebih lanjut untuk memastikan penyebab bab hitamnya apakah berhubungan dengan obat yang dikonsumsi atau ada penyakit lainnya. bila diperlukan dokter dapat melakukan tes feses, tes darah, endoskopi, dan usg untuk memastikannya. selanjutnya dokter dapat memberikan anda penanganan yang lebih tepat ya. beberapa tips yang bisa anda lakukan: perbanyak minum air putih hindari konsumsi buah bit, blueberry, atau buah naga untuk sementara waktu hindari suplemen zat besi dulu untuk melihat apakah ada perubahan pada feses setelah suplemen zat besi dihentikan, tetapi sebaiknya dikonsultasikan dulu dengan dokter anda hindari maknaan yang terlalu pedas, asam, atau bergas tinggi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05262344136802366,\n        \"min\": 0.5078062415122986,\n        \"max\": 0.7384459376335144,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.7073043584823608,\n          0.6505187749862671,\n          0.5562364459037781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040826036369222614,\n        \"min\": 0.3988509774208069,\n        \"max\": 0.6999833583831787,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6095816493034363,\n          0.5725404024124146,\n          0.5740377902984619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0400895290549729,\n        \"min\": 0.4966076910495758,\n        \"max\": 0.6894900798797607,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6548171639442444,\n          0.6090437769889832,\n          0.5649968981742859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["df_scores = pd.DataFrame(data_new)\n","df_scores = df_scores * 100\n","df_scores = pd.concat([df_bert_score, df_scores], axis=1)\n","df_scores.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":962},"id":"LlCYWfSEMK3k","outputId":"53946482-3384-46c7-df9c-58af437b5680"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            prediction  \\\n","0  Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...   \n","1                                                                                                                                                                                                                                                                                                                       Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             reference  \\\n","0  usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...   \n","1  konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...   \n","\n","   bert_precision  bert_recall   bert_f1      bleu1     bleu2     bleu3  \\\n","0        0.705103     0.661096  0.682391  17.169811  6.495710  2.518932   \n","1        0.644507     0.582390  0.611876   0.774941  0.248743  0.172068   \n","\n","      bleu4     rouge1    rouge2     rougeL  rougeLSum  \n","0  1.319653  19.973369  3.471295  11.717710  13.581891  \n","1  0.144252   4.705882  0.000000   4.705882   4.705882  "],"text/html":["\n","  <div id=\"df-b3e5fad4-5c69-4f8d-aee9-bd8159b4dbc6\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>prediction</th>\n","      <th>reference</th>\n","      <th>bert_precision</th>\n","      <th>bert_recall</th>\n","      <th>bert_f1</th>\n","      <th>bleu1</th>\n","      <th>bleu2</th>\n","      <th>bleu3</th>\n","      <th>bleu4</th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLSum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...</td>\n","      <td>usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...</td>\n","      <td>0.705103</td>\n","      <td>0.661096</td>\n","      <td>0.682391</td>\n","      <td>17.169811</td>\n","      <td>6.495710</td>\n","      <td>2.518932</td>\n","      <td>1.319653</td>\n","      <td>19.973369</td>\n","      <td>3.471295</td>\n","      <td>11.717710</td>\n","      <td>13.581891</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat</td>\n","      <td>konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...</td>\n","      <td>0.644507</td>\n","      <td>0.582390</td>\n","      <td>0.611876</td>\n","      <td>0.774941</td>\n","      <td>0.248743</td>\n","      <td>0.172068</td>\n","      <td>0.144252</td>\n","      <td>4.705882</td>\n","      <td>0.000000</td>\n","      <td>4.705882</td>\n","      <td>4.705882</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3e5fad4-5c69-4f8d-aee9-bd8159b4dbc6')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b3e5fad4-5c69-4f8d-aee9-bd8159b4dbc6 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b3e5fad4-5c69-4f8d-aee9-bd8159b4dbc6');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-3c9b61dd-48a6-4716-a096-f8b02e43f70f\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c9b61dd-48a6-4716-a096-f8b02e43f70f')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-3c9b61dd-48a6-4716-a096-f8b02e43f70f button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_scores","summary":"{\n  \"name\": \"df_scores\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"> Apa yang terjadi? Anda mengalami sakit perut yang disertai dengan gejala mual, demam, dan diare. Apakah gejala tersebut terjadi secara tiba-tiba?\",\n          \"Jawaban yang tepat adalah: \\\"Jika dokter tidak menemukan penyebabnya, dokter dapat memberikan obat untuk mengobati rasa sakit. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya.\\\"\",\n          \"Pertanyaan: Kenapa kotoran saya berwarna hitam, apakah itu gara-gara obat dari dokter yang saya minum atau apa? Jawaban: Warna hitam pada kotoran biasanya disebabkan oleh: 1. Makanan yang berwarna hitam seperti: coklat, kacang, bit, dll. 2. Makanan yang mengandung pewarna makanan. 3. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 4. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 5. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 6. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 7. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 8. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 9. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 10. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 11. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 12. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 13. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 14. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 15. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 16. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 17. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 18. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 19. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 20. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 21. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 22. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 23. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 24. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 25. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 26. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 27. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 28. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 29. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 30. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 31. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 32. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 33. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 34. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 35. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 36. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 37. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 38. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 39. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 40. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 41. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 42. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 43. Makanan yang\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"sakit perut dapat disebabkan oleh berbagai kondisi kesehatan yang dapat diperkirakan dengan mengetahui keluhan penderita dengan terperinci termasuk lokasi sakit perut. sakit perut yang di rasakan pada bagian tengah atas dapat disebabkan oleh: sakit maag radang lambung/ gastritis tukak lambung atau usus penyakit asam lambung radang pankreas radang/ batu kantung empedu gastroenteritis kanker lambung sakit ini sering disertai dengan gejala lain seperti mual, muntah, kembung, bersendawa, nafsu makan menurun, dan lainnya. sebaiknya jika gejala tidak kunjung membaik, silakan anda memeriksakan diri ke dokter untuk mencari penyebabnya. dokter perlu mengetahui keluhan anda dengan jelas dan melakukan serangkaian pemeriksaan. penanganan yang tepat dapat diberikan sesuai dengan hasil pemeriksaan. untuk sementara, silakan anda lakukan anjuran berikut: hindari makanan pedas, makanan berminyak, makanan berlemak hindari minuman berkafein, beralkohol, dan bersoda hindari terlambat makan lebih baik makan dalam porsi kecil tetapi lebih sering untuk menghindari mual jagalah asupan minuman anda minum parasetamol jika anda mengalami demam\",\n          \"keluhan ini dapat dipengaruhi oleh berbagai faktor seperti: \\u2022 tekanan yang terjadi pada otot, pembuluh darah dan sendi karena semakin besarnya ukuran janin \\u2022 regangan ligamen atau jaringan ikat yang menghubungkan tulang \\u2022 gas yang berlebih dalam rongga perut akibat peningkatan hormon progesteron selama kehamilan \\u2022 tekanan pada rongga panggul dikarenakan pertumbuhan janin \\u2022 perubahan postur tubuh karena menyangga janin \\u2022 pasca melakukan hubungan intim berikut beberapa penyebab sakit perut bagian bawah yang perlu anda waspadai: \\u2022 infeksi saluran kencing \\u2022 kehamilan diluar rahim \\u2022 lepasnya plasenta \\u2022 keguguran beberapa tips yang dapat anda lakukan untuk mengurangi rasa nyeri di perut bawah : \\u2022 cukup istirahat \\u2022 perbanyak minum air putih yang hangat \\u2022 mandi dengan air hangat \\u2022 hindari stres \\u2022 rutin lakukan olahraga khusus untuk ibu hamil \\u2022 tekuk/ bungkukan badan ke arah yang sakit dapat mengurangi rasa nyeri \\u2022 pijat perlahan punggung belakang jika sakit pada perut disertai dengan gejala-gejala berikut, anda harus waspada: \\u2022 keluarnya cairan abnormal dari vagina \\u2022 muntah \\u2022 demam \\u2022 menggigil \\u2022 nyeri bertambah hebat jika keluhan yang anda alami terasa semakin berat dan tidak membaik, saya sarankan untuk melakukan pemeriksaan ke dokter spesialis kandungan. selain itu, lakukanlah pemeriksaan rutin kandungan sesuai dengan anjuran dokter.\",\n          \"misalnya suplemen zat besi, bismuth konsumsi makanan tertentu, misalnya buah naga, buah bit, blueberry, atau makanan dengan kadar zat besi tinggi perdarahan saluran cerna: adanya luka / perdarahan di kerongkongan dan lambung, beberapa jenis obat antiinflamasi non steroid bisa mengiritasi lambug dan mencetuskan perdarahan (umumnya bila digunakan dalam jangka panjang atau bila memang ada riwayat tukak lambung) sirosis hepatis saya sarankan agar anda kontrol kembali ke dokter yang merawat anda dan sampaikan keluhan bab hitam yang anda alami. dokter akan melakukan pemeriksaan lebih lanjut untuk memastikan penyebab bab hitamnya apakah berhubungan dengan obat yang dikonsumsi atau ada penyakit lainnya. bila diperlukan dokter dapat melakukan tes feses, tes darah, endoskopi, dan usg untuk memastikannya. selanjutnya dokter dapat memberikan anda penanganan yang lebih tepat ya. beberapa tips yang bisa anda lakukan: perbanyak minum air putih hindari konsumsi buah bit, blueberry, atau buah naga untuk sementara waktu hindari suplemen zat besi dulu untuk melihat apakah ada perubahan pada feses setelah suplemen zat besi dihentikan, tetapi sebaiknya dikonsultasikan dulu dengan dokter anda hindari maknaan yang terlalu pedas, asam, atau bergas tinggi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05262344136802366,\n        \"min\": 0.5078062415122986,\n        \"max\": 0.7384459376335144,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.7073043584823608,\n          0.6505187749862671,\n          0.5562364459037781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040826036369222614,\n        \"min\": 0.3988509774208069,\n        \"max\": 0.6999833583831787,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6095816493034363,\n          0.5725404024124146,\n          0.5740377902984619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0400895290549729,\n        \"min\": 0.4966076910495758,\n        \"max\": 0.6894900798797607,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6548171639442444,\n          0.6090437769889832,\n          0.5649968981742859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.197602986482862,\n        \"min\": 1.8061780691633183e-108,\n        \"max\": 31.49473169707721,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.27588285679036784,\n          1.791846879161655,\n          5.194805194805195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6971039983328793,\n        \"min\": 2.554321521471615e-108,\n        \"max\": 14.356631118562198,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.18582788190484212,\n          0.3947548824859249,\n          1.701978707642031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3845012292326475,\n        \"min\": 2.867128967031743e-108,\n        \"max\": 6.793067808985579,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.12436861782897857,\n          0.23996474333300263,\n          0.8140379523232995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8984994332546303,\n        \"min\": 3.0376173273386198e-108,\n        \"max\": 4.229773840953415,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.07807082963307807,\n          0.18802147042092196,\n          0.5632384471321883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.61400955863719,\n        \"min\": 0.0,\n        \"max\": 29.971181556195965,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          11.920529801324502,\n          3.8910505836575875,\n          14.5985401459854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.416233269347849,\n        \"min\": 0.0,\n        \"max\": 5.847953216374269,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          2.04778156996587,\n          4.132231404958678,\n          1.1278195488721803\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5681269649697493,\n        \"min\": 0.0,\n        \"max\": 16.748768472906402,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          11.5606936416185,\n          6.091370558375634,\n          8.121827411167512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLSum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.56585215402798,\n        \"min\": 0.0,\n        \"max\": 16.748768472906402,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          7.28476821192053,\n          2.3346303501945527,\n          7.2992700729927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["### Contoh Hasil Rata Rata Tiap metrik untuk Base Model"],"metadata":{"id":"n-iWNWqVQ1oQ"}},{"cell_type":"code","source":["# Calculate the mean of the numerical columns only\n","numerical_cols = ['bert_precision', 'bert_recall', 'bert_f1', 'bleu1', 'bleu2', 'bleu3', 'bleu4', 'rouge1', 'rouge2', 'rougeL', 'rougeLSum']\n","mean_scores = df_scores[numerical_cols].mean()\n","\n","print(\"\\nRata-rata Skor:\")\n","mean_scores"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":465},"id":"E8cDKqYuBmOO","outputId":"1b3a7b90-041b-4565-8c58-c7bf79f01b00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Rata-rata Skor:\n"]},{"output_type":"execute_result","data":{"text/plain":["bert_precision     0.628678\n","bert_recall        0.600173\n","bert_f1            0.613041\n","bleu1              8.522933\n","bleu2              2.880937\n","bleu3              1.473571\n","bleu4              0.980875\n","rouge1            12.311867\n","rouge2             1.299153\n","rougeL             7.692550\n","rougeLSum          7.344694\n","dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>bert_precision</th>\n","      <td>0.628678</td>\n","    </tr>\n","    <tr>\n","      <th>bert_recall</th>\n","      <td>0.600173</td>\n","    </tr>\n","    <tr>\n","      <th>bert_f1</th>\n","      <td>0.613041</td>\n","    </tr>\n","    <tr>\n","      <th>bleu1</th>\n","      <td>8.522933</td>\n","    </tr>\n","    <tr>\n","      <th>bleu2</th>\n","      <td>2.880937</td>\n","    </tr>\n","    <tr>\n","      <th>bleu3</th>\n","      <td>1.473571</td>\n","    </tr>\n","    <tr>\n","      <th>bleu4</th>\n","      <td>0.980875</td>\n","    </tr>\n","    <tr>\n","      <th>rouge1</th>\n","      <td>12.311867</td>\n","    </tr>\n","    <tr>\n","      <th>rouge2</th>\n","      <td>1.299153</td>\n","    </tr>\n","    <tr>\n","      <th>rougeL</th>\n","      <td>7.692550</td>\n","    </tr>\n","    <tr>\n","      <th>rougeLSum</th>\n","      <td>7.344694</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["### Menyimpan Hasil Evaluasi"],"metadata":{"id":"Jq3jDmyIRC9n"}},{"cell_type":"code","source":["import os\n","os.makedirs('Hasil Eval revisi')\n","mean_scores.to_csv('Hasil Eval revisi/eval_basemodel_4_mean.csv')"],"metadata":{"id":"ae5fhMweO7q4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_scores = pd.concat([base_4[['input']], df_scores], axis=1)\n","df_scores.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"aXncCajiZkGe","outputId":"41098677-8e15-402c-995c-2d393b3dce2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 input  \\\n","0  Solusi atasi sakit maag yang tak kunjung sembuh. Saya memiliki keluhan selama 2 minggu belakangan ada masalah di pencernaan. Saya sudah berobat klinik 2 kali tapi diagnosanya sama yaitu saya menderita maag. Oleh dokter yang menangani, saya hanya diberi antasida, omeprazole, dan ranitidin. Saya sudah habiskan obatnya, pola makan pun saya jaga dengan tidak mengkonsumsi makanan pedas, asam, dan kafein namun sampai saat ini tidak ada perubahan. Selama 2 minggu saya sakit berat badan saya turun 1...   \n","1                                                                                                                                                                                                                                                                                                                                                                           solusi untuk mengatasi konstipasi. dok kalo bab feses saya enggak keras, cair tapi usus saya enggak mau untuk ngeluarinnya. kenapa ya dok?   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            prediction  \\\n","0  Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...   \n","1                                                                                                                                                                                                                                                                                                                       Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             reference  \\\n","0  usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...   \n","1  konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...   \n","\n","   bert_precision  bert_recall   bert_f1      bleu1     bleu2     bleu3  \\\n","0        0.705103     0.661096  0.682391  17.169811  6.495710  2.518932   \n","1        0.644507     0.582390  0.611876   0.774941  0.248743  0.172068   \n","\n","      bleu4     rouge1    rouge2     rougeL  rougeLSum  \n","0  1.319653  19.973369  3.471295  11.717710  13.581891  \n","1  0.144252   4.705882  0.000000   4.705882   4.705882  "],"text/html":["\n","  <div id=\"df-32f1e17e-5e48-4faf-afd1-62d5cedc0df2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>prediction</th>\n","      <th>reference</th>\n","      <th>bert_precision</th>\n","      <th>bert_recall</th>\n","      <th>bert_f1</th>\n","      <th>bleu1</th>\n","      <th>bleu2</th>\n","      <th>bleu3</th>\n","      <th>bleu4</th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLSum</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Solusi atasi sakit maag yang tak kunjung sembuh. Saya memiliki keluhan selama 2 minggu belakangan ada masalah di pencernaan. Saya sudah berobat klinik 2 kali tapi diagnosanya sama yaitu saya menderita maag. Oleh dokter yang menangani, saya hanya diberi antasida, omeprazole, dan ranitidin. Saya sudah habiskan obatnya, pola makan pun saya jaga dengan tidak mengkonsumsi makanan pedas, asam, dan kafein namun sampai saat ini tidak ada perubahan. Selama 2 minggu saya sakit berat badan saya turun 1...</td>\n","      <td>Maaf, dokter tidak tersedia pada hari ini. Berikut ini adalah informasi untuk menjawab pertanyaan anda.\\n\\nMaag adalah penyakit yang terjadi akibat luka pada perut. Maag terjadi ketika luka di perut mengalami infeksi dan menyebabkan perdarahan. Maag terjadi akibat infeksi virus atau bakteri. Maag juga dapat terjadi akibat kondisi lain seperti kanker, cedera perut, atau infeksi yang disebabkan oleh bakteri.\\n\\nGejala maag yang sering muncul adalah sakit perut, muntah, dan mual. Gejala-gejala ...</td>\n","      <td>usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...</td>\n","      <td>0.705103</td>\n","      <td>0.661096</td>\n","      <td>0.682391</td>\n","      <td>17.169811</td>\n","      <td>6.495710</td>\n","      <td>2.518932</td>\n","      <td>1.319653</td>\n","      <td>19.973369</td>\n","      <td>3.471295</td>\n","      <td>11.717710</td>\n","      <td>13.581891</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>solusi untuk mengatasi konstipasi. dok kalo bab feses saya enggak keras, cair tapi usus saya enggak mau untuk ngeluarinnya. kenapa ya dok?</td>\n","      <td>Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\\n\\n### Input:\\nsolusi untuk mengat</td>\n","      <td>konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...</td>\n","      <td>0.644507</td>\n","      <td>0.582390</td>\n","      <td>0.611876</td>\n","      <td>0.774941</td>\n","      <td>0.248743</td>\n","      <td>0.172068</td>\n","      <td>0.144252</td>\n","      <td>4.705882</td>\n","      <td>0.000000</td>\n","      <td>4.705882</td>\n","      <td>4.705882</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32f1e17e-5e48-4faf-afd1-62d5cedc0df2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-32f1e17e-5e48-4faf-afd1-62d5cedc0df2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-32f1e17e-5e48-4faf-afd1-62d5cedc0df2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-91f16be9-7d97-481a-9a73-d3283c5a0a83\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-91f16be9-7d97-481a-9a73-d3283c5a0a83')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-91f16be9-7d97-481a-9a73-d3283c5a0a83 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_scores","summary":"{\n  \"name\": \"df_scores\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Mengapa perut sesekali perih?. Perut bagian tengah sesekali perih dan dalam satu hari itu sering merasakannya. Gejala nya saya Mual, diare feses Cair, Pusing, dan Demam. saya ingin tahu, ini gejala penyakit apa dan disebabkan oleh apa. Mohon jawabannya dok.. Terimakasih. \\ud83d\\ude0a\",\n          \"Sakit perut bagian bawah saat hamil. Pagi dok..saya ibu 1 anak dan sekarang saya sedang hamil 5 bulan anak kedua.. Saya ingin bertanya dok..bagian perut bawah saya sakit sekali dok saya raba2 ada seperti benjolan di sebelah kiri bwah perut saya..tapi janin dalam perut saya sangat aktif setiap janin bergerak sakit banget rasanya sudah 2 hari saya merasakan sakit ini... Bahayakah dok sakit di saat hamil ini..\",\n          \"Penyebab BAB berwarna hitam. Malam dok...saya mau bertanya kenapa kotoran saya berwarna hitam, apakah itu gara-gara obat dari dokter yang saya minum atau apa mohon jawabannya dokBy; Hamdika\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"> Apa yang terjadi? Anda mengalami sakit perut yang disertai dengan gejala mual, demam, dan diare. Apakah gejala tersebut terjadi secara tiba-tiba?\",\n          \"Jawaban yang tepat adalah: \\\"Jika dokter tidak menemukan penyebabnya, dokter dapat memberikan obat untuk mengobati rasa sakit. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya. Jika dokter menemukan penyebabnya, dokter dapat memberikan obat yang tepat untuk mengobati penyebabnya.\\\"\",\n          \"Pertanyaan: Kenapa kotoran saya berwarna hitam, apakah itu gara-gara obat dari dokter yang saya minum atau apa? Jawaban: Warna hitam pada kotoran biasanya disebabkan oleh: 1. Makanan yang berwarna hitam seperti: coklat, kacang, bit, dll. 2. Makanan yang mengandung pewarna makanan. 3. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 4. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 5. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 6. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 7. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 8. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 9. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 10. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 11. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 12. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 13. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 14. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 15. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 16. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 17. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 18. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 19. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 20. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 21. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 22. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 23. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 24. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 25. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 26. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 27. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 28. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 29. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 30. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 31. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 32. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 33. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 34. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 35. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 36. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 37. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 38. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 39. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 40. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 41. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 42. Makanan yang mengandung pewarna makanan yang berupa bahan kimia. 43. Makanan yang\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"sakit perut dapat disebabkan oleh berbagai kondisi kesehatan yang dapat diperkirakan dengan mengetahui keluhan penderita dengan terperinci termasuk lokasi sakit perut. sakit perut yang di rasakan pada bagian tengah atas dapat disebabkan oleh: sakit maag radang lambung/ gastritis tukak lambung atau usus penyakit asam lambung radang pankreas radang/ batu kantung empedu gastroenteritis kanker lambung sakit ini sering disertai dengan gejala lain seperti mual, muntah, kembung, bersendawa, nafsu makan menurun, dan lainnya. sebaiknya jika gejala tidak kunjung membaik, silakan anda memeriksakan diri ke dokter untuk mencari penyebabnya. dokter perlu mengetahui keluhan anda dengan jelas dan melakukan serangkaian pemeriksaan. penanganan yang tepat dapat diberikan sesuai dengan hasil pemeriksaan. untuk sementara, silakan anda lakukan anjuran berikut: hindari makanan pedas, makanan berminyak, makanan berlemak hindari minuman berkafein, beralkohol, dan bersoda hindari terlambat makan lebih baik makan dalam porsi kecil tetapi lebih sering untuk menghindari mual jagalah asupan minuman anda minum parasetamol jika anda mengalami demam\",\n          \"keluhan ini dapat dipengaruhi oleh berbagai faktor seperti: \\u2022 tekanan yang terjadi pada otot, pembuluh darah dan sendi karena semakin besarnya ukuran janin \\u2022 regangan ligamen atau jaringan ikat yang menghubungkan tulang \\u2022 gas yang berlebih dalam rongga perut akibat peningkatan hormon progesteron selama kehamilan \\u2022 tekanan pada rongga panggul dikarenakan pertumbuhan janin \\u2022 perubahan postur tubuh karena menyangga janin \\u2022 pasca melakukan hubungan intim berikut beberapa penyebab sakit perut bagian bawah yang perlu anda waspadai: \\u2022 infeksi saluran kencing \\u2022 kehamilan diluar rahim \\u2022 lepasnya plasenta \\u2022 keguguran beberapa tips yang dapat anda lakukan untuk mengurangi rasa nyeri di perut bawah : \\u2022 cukup istirahat \\u2022 perbanyak minum air putih yang hangat \\u2022 mandi dengan air hangat \\u2022 hindari stres \\u2022 rutin lakukan olahraga khusus untuk ibu hamil \\u2022 tekuk/ bungkukan badan ke arah yang sakit dapat mengurangi rasa nyeri \\u2022 pijat perlahan punggung belakang jika sakit pada perut disertai dengan gejala-gejala berikut, anda harus waspada: \\u2022 keluarnya cairan abnormal dari vagina \\u2022 muntah \\u2022 demam \\u2022 menggigil \\u2022 nyeri bertambah hebat jika keluhan yang anda alami terasa semakin berat dan tidak membaik, saya sarankan untuk melakukan pemeriksaan ke dokter spesialis kandungan. selain itu, lakukanlah pemeriksaan rutin kandungan sesuai dengan anjuran dokter.\",\n          \"misalnya suplemen zat besi, bismuth konsumsi makanan tertentu, misalnya buah naga, buah bit, blueberry, atau makanan dengan kadar zat besi tinggi perdarahan saluran cerna: adanya luka / perdarahan di kerongkongan dan lambung, beberapa jenis obat antiinflamasi non steroid bisa mengiritasi lambug dan mencetuskan perdarahan (umumnya bila digunakan dalam jangka panjang atau bila memang ada riwayat tukak lambung) sirosis hepatis saya sarankan agar anda kontrol kembali ke dokter yang merawat anda dan sampaikan keluhan bab hitam yang anda alami. dokter akan melakukan pemeriksaan lebih lanjut untuk memastikan penyebab bab hitamnya apakah berhubungan dengan obat yang dikonsumsi atau ada penyakit lainnya. bila diperlukan dokter dapat melakukan tes feses, tes darah, endoskopi, dan usg untuk memastikannya. selanjutnya dokter dapat memberikan anda penanganan yang lebih tepat ya. beberapa tips yang bisa anda lakukan: perbanyak minum air putih hindari konsumsi buah bit, blueberry, atau buah naga untuk sementara waktu hindari suplemen zat besi dulu untuk melihat apakah ada perubahan pada feses setelah suplemen zat besi dihentikan, tetapi sebaiknya dikonsultasikan dulu dengan dokter anda hindari maknaan yang terlalu pedas, asam, atau bergas tinggi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05262344136802366,\n        \"min\": 0.5078062415122986,\n        \"max\": 0.7384459376335144,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.7073043584823608,\n          0.6505187749862671,\n          0.5562364459037781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040826036369222614,\n        \"min\": 0.3988509774208069,\n        \"max\": 0.6999833583831787,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6095816493034363,\n          0.5725404024124146,\n          0.5740377902984619\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0400895290549729,\n        \"min\": 0.4966076910495758,\n        \"max\": 0.6894900798797607,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.6548171639442444,\n          0.6090437769889832,\n          0.5649968981742859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.197602986482862,\n        \"min\": 1.8061780691633183e-108,\n        \"max\": 31.49473169707721,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.27588285679036784,\n          1.791846879161655,\n          5.194805194805195\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6971039983328793,\n        \"min\": 2.554321521471615e-108,\n        \"max\": 14.356631118562198,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.18582788190484212,\n          0.3947548824859249,\n          1.701978707642031\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3845012292326475,\n        \"min\": 2.867128967031743e-108,\n        \"max\": 6.793067808985579,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.12436861782897857,\n          0.23996474333300263,\n          0.8140379523232995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8984994332546303,\n        \"min\": 3.0376173273386198e-108,\n        \"max\": 4.229773840953415,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          0.07807082963307807,\n          0.18802147042092196,\n          0.5632384471321883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.61400955863719,\n        \"min\": 0.0,\n        \"max\": 29.971181556195965,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          11.920529801324502,\n          3.8910505836575875,\n          14.5985401459854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.416233269347849,\n        \"min\": 0.0,\n        \"max\": 5.847953216374269,\n        \"num_unique_values\": 67,\n        \"samples\": [\n          2.04778156996587,\n          4.132231404958678,\n          1.1278195488721803\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5681269649697493,\n        \"min\": 0.0,\n        \"max\": 16.748768472906402,\n        \"num_unique_values\": 96,\n        \"samples\": [\n          11.5606936416185,\n          6.091370558375634,\n          8.121827411167512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLSum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.56585215402798,\n        \"min\": 0.0,\n        \"max\": 16.748768472906402,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          7.28476821192053,\n          2.3346303501945527,\n          7.2992700729927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df_scores.to_csv('Hasil Eval revisi/eval_basemodel_4.csv')"],"metadata":{"id":"oY67qG_dO139"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##   Evaluasi Fine Tune Model\n","\n","Pemilihan Model sesuai dengan Model Fine Tune yang mau dievaluasi"],"metadata":{"id":"LCyRgdxVRIrf"}},{"cell_type":"markdown","source":["Pada bagian ini, contoh  dilakukan pemuatan adapter LoRA yang sudah di-fine-tuning dari Hugging Face **(\"farwew/DoctorsAnswerTextDataset-in-IndonesianUnsloth-llama-3-8b-bnb-4bit\")** menggunakan `PeftModel.from_pretrained`.\n","\n","Adapter ini dimuat di atas model dasar (model) yang sebelumnya sudah ada di memori (sudah di load sebelumnya).\n","\n","Proses ini menggabungkan penyesuaian bobot yang telah dilatih (adapter LoRA) dengan model dasar, sehingga model siap untuk melakukan inferensi dengan performa yang ditingkatkan sesuai hasil fine-tuning."],"metadata":{"id":"h78G-DBoSZ4E"}},{"cell_type":"code","source":["model = PeftModel.from_pretrained(model, \"farwew/DoctorsAnswerTextDataset-in-IndonesianUnsloth-llama-3-8b-bnb-4bit\")"],"metadata":{"id":"sOXMqga5i5-E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sama seperti sebelumnay proses nya kita melakukan inferensi dan menyimpan hasil output dari model"],"metadata":{"id":"VJm8FpUvS_kg"}},{"cell_type":"code","source":["generated_outputs = []\n","reference_outputs = []\n","all_inputs = []  # Untuk menyimpan input\n","all_instructions = []  # Untuk menyimpan instruction\n","\n","batch_size = 1\n","MAX_DISPLAY = 10\n","displayed = 0\n","\n","# === TIMESTAMP UNTUK NAMA FILE === #\n","timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n","output_dir = f\"evaluation_results_{timestamp}\"\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T01:53:17.893685Z","iopub.execute_input":"2025-05-25T01:53:17.893945Z","iopub.status.idle":"2025-05-25T01:53:19.331329Z","shell.execute_reply.started":"2025-05-25T01:53:17.893929Z","shell.execute_reply":"2025-05-25T01:53:19.330481Z"},"id":"rNK0xD8gMvoW"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Proses inferensi Fine Tune Model"],"metadata":{"id":"QZxcQJ4-TTxP"}},{"cell_type":"code","source":["num = 1\n","for example in tqdm(stratified_dataset, desc=\"Evaluating Base Model\"):\n","    # Gunakan prompt yang hanya menerima input (karena instruksi tetap)\n","    prompt = alpaca_prompt.format(example[\"input\"], \"\")  # output dikosongkan untuk inferensi\n","\n","    # Tokenisasi dan pindahkan ke GPU\n","    input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","    # Inference (tanpa perhitungan gradien)\n","    with torch.no_grad():\n","        output = model.generate(\n","            **input_ids,\n","            max_new_tokens=1024,\n","            do_sample=True,\n","            top_p=0.9,\n","            temperature=0.7\n","        )\n","\n","    # Decode output dan ekstrak bagian response-nya\n","    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n","    response = decoded.split(\"### Response:\")[-1].strip()\n","\n","    # Cetak sampel jika masih kurang dari 10\n","    if num < 10:\n","        print(prompt)\n","        print()\n","        print('response:', response)\n","        print('-' * 80)\n","\n","    # Simpan hasil untuk evaluasi\n","    generated_outputs.append(response)\n","    reference_outputs.append(example[\"output\"])\n","    all_instructions.append(\"Jawab pertanyaan medis berikut dengan bahasa yang mudah dipahami. Pastikan respons mencakup: penjelasan kondisi, informasi penting, dan saran yang relevan.\")  # atau bisa juga diabaikan jika instruksi selalu sama\n","    all_inputs.append(example[\"input\"])\n","    num += 1"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T01:57:00.544094Z","iopub.execute_input":"2025-05-25T01:57:00.544388Z"},"id":"MJvGpiyYMvoY"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### menyimpan hasil output dari model"],"metadata":{"id":"X5MRrw2nT4cl"}},{"cell_type":"code","source":["# === Simpan Hasil Evaluasi === #\n","df = pd.DataFrame({\n","    \"instruction\": all_instructions,\n","    \"input\": all_inputs,\n","    \"reference\": reference_outputs,\n","    \"generated\": generated_outputs,\n","})\n","\n","df.to_csv(f\"fine_tuned_outputs.csv\", index=False)"],"metadata":{"trusted":true,"id":"ZayW2euOMvoZ"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["### Evaluasi Kunatitatif untuk Fine Tune  Model"],"metadata":{"id":"UT10MlOXUHmA"}},{"cell_type":"code","source":["def evaluate_generation_scores(data):\n","    # Buang baris yang memiliki NaN pada kolom generated atau reference\n","    df_clean = data.dropna(subset=['generated', 'reference']).copy()\n","\n","    preds = df_clean['generated'].tolist()\n","    refs = df_clean['reference'].tolist()\n","\n","    # Pastikan references berbentuk list of list untuk BLEU\n","    refs_for_bleu = [[ref] for ref in refs]\n","\n","    # Hitung BLEU dan ROUGE per baris\n","    bleu_scores = compute_bleu_per_row(preds, refs_for_bleu)\n","    rouge_scores = compute_rouge_per_row(preds, refs)\n","\n","    # Hitung BERTScore per baris\n","    bert_scores = compute_bertscore_per_row(preds, refs_for_bleu)\n","\n","    # Siapkan dictionary untuk skor\n","    data_new = {}\n","\n","    for n in range(1, 5):\n","        data_new[f'bleu{n}'] = [score[f'bleu{n}'] for score in bleu_scores]\n","\n","    data_new['rouge1'] = [score['rouge1'] for score in rouge_scores]\n","    data_new['rouge2'] = [score['rouge2'] for score in rouge_scores]\n","    data_new['rougeL'] = [score['rougeL'] for score in rouge_scores]\n","    data_new['rougeLSum'] = [score['rougeLSum'] for score in rouge_scores]\n","\n","    # Tambahkan BERTScore per row\n","    data_new['bert_precision'] = [score['bert_precision'] for score in bert_scores]\n","    data_new['bert_recall'] = [score['bert_recall'] for score in bert_scores]\n","    data_new['bert_f1'] = [score['bert_f1'] for score in bert_scores]\n","\n","    # Konversi ke DataFrame dan skalakan ke persen\n","    df_scores = pd.DataFrame(data_new)\n","    df_scores = df_scores * 100\n","\n","    # Tambahkan kolom input, reference, dan generated\n","    df_scores['input'] = df_clean['input'].values\n","    df_scores['reference'] = df_clean['reference'].values\n","    df_scores['generated'] = df_clean['generated'].values\n","\n","    # Hitung rata-rata skor\n","    mean_scores = df_scores.drop(columns=['input', 'reference', 'generated']).mean()\n","\n","    return df_scores, mean_scores\n"],"metadata":{"id":"ExTQr3kQQzlW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ft_model = pd.read_csv('fine_tuned_outputs.csv')"],"metadata":{"id":"sVCcicPORLkr","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ft, mean_ft = evaluate_generation_scores(ft_model)"],"metadata":{"id":"UquFmzs7RWYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_ft.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7dYtIxKWYhIn","outputId":"7795abc0-ce03-4654-8d23-ffcc6b7afd04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       bleu1      bleu2      bleu3      bleu4     rouge1     rouge2  \\\n","0  34.997256  16.489537   7.171295   3.347295  34.394904   6.823028   \n","1  54.430380  37.239244  25.657258  17.182931  54.861111  24.475524   \n","\n","      rougeL  rougeLSum  bert_precision  bert_recall    bert_f1  \\\n","0  14.012739  14.012739       74.620163    72.101730  73.339337   \n","1  43.055556  43.055556       79.042411    78.676975  78.859270   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 input  \\\n","0  Solusi atasi sakit maag yang tak kunjung sembuh. Saya memiliki keluhan selama 2 minggu belakangan ada masalah di pencernaan. Saya sudah berobat klinik 2 kali tapi diagnosanya sama yaitu saya menderita maag. Oleh dokter yang menangani, saya hanya diberi antasida, omeprazole, dan ranitidin. Saya sudah habiskan obatnya, pola makan pun saya jaga dengan tidak mengkonsumsi makanan pedas, asam, dan kafein namun sampai saat ini tidak ada perubahan. Selama 2 minggu saya sakit berat badan saya turun 1...   \n","1                                                                                                                                                                                                                                                                                                                                                                           solusi untuk mengatasi konstipasi. dok kalo bab feses saya enggak keras, cair tapi usus saya enggak mau untuk ngeluarinnya. kenapa ya dok?   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             reference  \\\n","0  usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...   \n","1  konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             generated  \n","0  maag atau biasa disebut sebagai gastritis adalah suatu penyakit yang disebabkan oleh adanya peradangan pada dinding lambung. gastritis terjadi karena lapisan lambung mengalami iritasi, peradangan, atau pengikisan oleh asam lambung yang diproduksi oleh sel-sel dalam lambung. gastritis dapat disebabkan oleh beberapa faktor berikut: pola makan yang buruk, seperti terlambat makan, makan makanan yang pedas, asam, berlemak, atau yang menghasilkan banyak gas, seperti kol, kacang-kacangan, minuman b...  \n","1  konstipasi dapat disebabkan oleh beberapa hal berikut ini: kebiasaan mengabaikan keinginan untuk buang air besar kurang minum kurang konsumsi serat kurang aktif dan jarang berolahraga penurunan berat badan yang mendadak efek samping obat-obatan tertentu penyakit medis tertentu seperti penyakit crohn, penyumbatan usus, diabetes, gangguan tiroid, kanker usus, dsb. untuk memastikan penyebab dari konstipasi yang anda alami, maka sebaiknya anda memeriksakan diri secara langsung ke dokter. dokter ...  "],"text/html":["\n","  <div id=\"df-ebb48836-f598-4113-b520-f51a5c1929c5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bleu1</th>\n","      <th>bleu2</th>\n","      <th>bleu3</th>\n","      <th>bleu4</th>\n","      <th>rouge1</th>\n","      <th>rouge2</th>\n","      <th>rougeL</th>\n","      <th>rougeLSum</th>\n","      <th>bert_precision</th>\n","      <th>bert_recall</th>\n","      <th>bert_f1</th>\n","      <th>input</th>\n","      <th>reference</th>\n","      <th>generated</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>34.997256</td>\n","      <td>16.489537</td>\n","      <td>7.171295</td>\n","      <td>3.347295</td>\n","      <td>34.394904</td>\n","      <td>6.823028</td>\n","      <td>14.012739</td>\n","      <td>14.012739</td>\n","      <td>74.620163</td>\n","      <td>72.101730</td>\n","      <td>73.339337</td>\n","      <td>Solusi atasi sakit maag yang tak kunjung sembuh. Saya memiliki keluhan selama 2 minggu belakangan ada masalah di pencernaan. Saya sudah berobat klinik 2 kali tapi diagnosanya sama yaitu saya menderita maag. Oleh dokter yang menangani, saya hanya diberi antasida, omeprazole, dan ranitidin. Saya sudah habiskan obatnya, pola makan pun saya jaga dengan tidak mengkonsumsi makanan pedas, asam, dan kafein namun sampai saat ini tidak ada perubahan. Selama 2 minggu saya sakit berat badan saya turun 1...</td>\n","      <td>usus halus ataupun kerongkongan yang dapat disebabkan kondisi berikut : faktor psikis, yakni kondisi stres emosional akibat pengunaan obat antinyeri non steroid (nsaid) akibat perlukaan pada lambung (tukak lambung/peptik) infeksi bakteri helicobacter pylori (gastritis) dsb sakit maag yang kronis atau berlangsung berat dapat menyebabkan perlukaan pada lambung dan sebaliknya. pada perlukaan yang berat dapat terjadi perforasi (pecahnya) jaringan lambung sehingga menimbulkan gejala batuk/muntah ...</td>\n","      <td>maag atau biasa disebut sebagai gastritis adalah suatu penyakit yang disebabkan oleh adanya peradangan pada dinding lambung. gastritis terjadi karena lapisan lambung mengalami iritasi, peradangan, atau pengikisan oleh asam lambung yang diproduksi oleh sel-sel dalam lambung. gastritis dapat disebabkan oleh beberapa faktor berikut: pola makan yang buruk, seperti terlambat makan, makan makanan yang pedas, asam, berlemak, atau yang menghasilkan banyak gas, seperti kol, kacang-kacangan, minuman b...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>54.430380</td>\n","      <td>37.239244</td>\n","      <td>25.657258</td>\n","      <td>17.182931</td>\n","      <td>54.861111</td>\n","      <td>24.475524</td>\n","      <td>43.055556</td>\n","      <td>43.055556</td>\n","      <td>79.042411</td>\n","      <td>78.676975</td>\n","      <td>78.859270</td>\n","      <td>solusi untuk mengatasi konstipasi. dok kalo bab feses saya enggak keras, cair tapi usus saya enggak mau untuk ngeluarinnya. kenapa ya dok?</td>\n","      <td>konstipasi adalah keadaan tidak dapat buang air besar secara teratur atau tidak dapat buang air besar sama sekali. konstipasi dapat disebabkan oleh: kurang mimun kurang konsumsi serat kurang aktif bergerak dan berolahraga kelebihan atau kekurangan berat badan kebiasaan menunda buang air besar cemas atau depresi penyumbatan usus gangguan saraf usus efek samping obat-obatan tertentu dsb. sebaiknya anda berkonsultasi dengan dokter di mana dokter akan menganalisis gejala dan melakukan pemeriksaa...</td>\n","      <td>konstipasi dapat disebabkan oleh beberapa hal berikut ini: kebiasaan mengabaikan keinginan untuk buang air besar kurang minum kurang konsumsi serat kurang aktif dan jarang berolahraga penurunan berat badan yang mendadak efek samping obat-obatan tertentu penyakit medis tertentu seperti penyakit crohn, penyumbatan usus, diabetes, gangguan tiroid, kanker usus, dsb. untuk memastikan penyebab dari konstipasi yang anda alami, maka sebaiknya anda memeriksakan diri secara langsung ke dokter. dokter ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb48836-f598-4113-b520-f51a5c1929c5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ebb48836-f598-4113-b520-f51a5c1929c5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ebb48836-f598-4113-b520-f51a5c1929c5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-89ce934f-8b12-46fd-a39b-494de48873f1\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89ce934f-8b12-46fd-a39b-494de48873f1')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-89ce934f-8b12-46fd-a39b-494de48873f1 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df_ft","summary":"{\n  \"name\": \"df_ft\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"bleu1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.968566134873019,\n        \"min\": 0.007107408693200009,\n        \"max\": 54.43037974683544,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          30.0,\n          12.015770546931359,\n          18.68711883904713\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.112251859829748,\n        \"min\": 0.0021837863882259957,\n        \"max\": 37.23924364746548,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          15.22038868295523,\n          6.740484233291558,\n          9.654253118466546\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.9306006121968062,\n        \"min\": 0.0014929808009424117,\n        \"max\": 25.657257642624582,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          7.10827013475463,\n          4.630897533992321,\n          5.12000816389009\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bleu4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.6347289114187875,\n        \"min\": 0.0012471205880058573,\n        \"max\": 17.182931099588355,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          4.0888121738642,\n          3.237163174977576,\n          3.1436781652117163\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.085273397242979,\n        \"min\": 5.957446808510637,\n        \"max\": 54.861111111111114,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          33.2409972299169,\n          29.77099236641222,\n          31.29770992366412\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rouge2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.8422487342009064,\n        \"min\": 0.0,\n        \"max\": 24.475524475524477,\n        \"num_unique_values\": 95,\n        \"samples\": [\n          6.923076923076923,\n          6.081081081081081,\n          5.592105263157894\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.0316859723728875,\n        \"min\": 4.25531914893617,\n        \"max\": 43.05555555555555,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          14.420062695924765,\n          12.269938650306749,\n          12.707182320441987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rougeLSum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.0316859723728875,\n        \"min\": 4.25531914893617,\n        \"max\": 43.05555555555555,\n        \"num_unique_values\": 99,\n        \"samples\": [\n          14.420062695924765,\n          12.269938650306749,\n          12.707182320441987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.348670764253824,\n        \"min\": 56.37620687484741,\n        \"max\": 79.0424108505249,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          72.41985201835632,\n          70.61737775802612,\n          76.4076292514801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.5872303340231175,\n        \"min\": 58.38192701339722,\n        \"max\": 78.67697477340698,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          73.03786873817444,\n          65.40659666061401,\n          68.10213923454285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.9859041877062946,\n        \"min\": 57.85486102104187,\n        \"max\": 78.85926961898804,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          72.72754907608032,\n          67.91217923164368,\n          72.01620936393738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Mengapa perut sesekali perih?. Perut bagian tengah sesekali perih dan dalam satu hari itu sering merasakannya. Gejala nya saya Mual, diare feses Cair, Pusing, dan Demam. saya ingin tahu, ini gejala penyakit apa dan disebabkan oleh apa. Mohon jawabannya dok.. Terimakasih. \\ud83d\\ude0a\",\n          \"Sakit perut bagian bawah saat hamil. Pagi dok..saya ibu 1 anak dan sekarang saya sedang hamil 5 bulan anak kedua.. Saya ingin bertanya dok..bagian perut bawah saya sakit sekali dok saya raba2 ada seperti benjolan di sebelah kiri bwah perut saya..tapi janin dalam perut saya sangat aktif setiap janin bergerak sakit banget rasanya sudah 2 hari saya merasakan sakit ini... Bahayakah dok sakit di saat hamil ini..\",\n          \"Penyebab BAB berwarna hitam. Malam dok...saya mau bertanya kenapa kotoran saya berwarna hitam, apakah itu gara-gara obat dari dokter yang saya minum atau apa mohon jawabannya dokBy; Hamdika\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"sakit perut dapat disebabkan oleh berbagai kondisi kesehatan yang dapat diperkirakan dengan mengetahui keluhan penderita dengan terperinci termasuk lokasi sakit perut. sakit perut yang di rasakan pada bagian tengah atas dapat disebabkan oleh: sakit maag radang lambung/ gastritis tukak lambung atau usus penyakit asam lambung radang pankreas radang/ batu kantung empedu gastroenteritis kanker lambung sakit ini sering disertai dengan gejala lain seperti mual, muntah, kembung, bersendawa, nafsu makan menurun, dan lainnya. sebaiknya jika gejala tidak kunjung membaik, silakan anda memeriksakan diri ke dokter untuk mencari penyebabnya. dokter perlu mengetahui keluhan anda dengan jelas dan melakukan serangkaian pemeriksaan. penanganan yang tepat dapat diberikan sesuai dengan hasil pemeriksaan. untuk sementara, silakan anda lakukan anjuran berikut: hindari makanan pedas, makanan berminyak, makanan berlemak hindari minuman berkafein, beralkohol, dan bersoda hindari terlambat makan lebih baik makan dalam porsi kecil tetapi lebih sering untuk menghindari mual jagalah asupan minuman anda minum parasetamol jika anda mengalami demam\",\n          \"keluhan ini dapat dipengaruhi oleh berbagai faktor seperti: \\u2022 tekanan yang terjadi pada otot, pembuluh darah dan sendi karena semakin besarnya ukuran janin \\u2022 regangan ligamen atau jaringan ikat yang menghubungkan tulang \\u2022 gas yang berlebih dalam rongga perut akibat peningkatan hormon progesteron selama kehamilan \\u2022 tekanan pada rongga panggul dikarenakan pertumbuhan janin \\u2022 perubahan postur tubuh karena menyangga janin \\u2022 pasca melakukan hubungan intim berikut beberapa penyebab sakit perut bagian bawah yang perlu anda waspadai: \\u2022 infeksi saluran kencing \\u2022 kehamilan diluar rahim \\u2022 lepasnya plasenta \\u2022 keguguran beberapa tips yang dapat anda lakukan untuk mengurangi rasa nyeri di perut bawah : \\u2022 cukup istirahat \\u2022 perbanyak minum air putih yang hangat \\u2022 mandi dengan air hangat \\u2022 hindari stres \\u2022 rutin lakukan olahraga khusus untuk ibu hamil \\u2022 tekuk/ bungkukan badan ke arah yang sakit dapat mengurangi rasa nyeri \\u2022 pijat perlahan punggung belakang jika sakit pada perut disertai dengan gejala-gejala berikut, anda harus waspada: \\u2022 keluarnya cairan abnormal dari vagina \\u2022 muntah \\u2022 demam \\u2022 menggigil \\u2022 nyeri bertambah hebat jika keluhan yang anda alami terasa semakin berat dan tidak membaik, saya sarankan untuk melakukan pemeriksaan ke dokter spesialis kandungan. selain itu, lakukanlah pemeriksaan rutin kandungan sesuai dengan anjuran dokter.\",\n          \"misalnya suplemen zat besi, bismuth konsumsi makanan tertentu, misalnya buah naga, buah bit, blueberry, atau makanan dengan kadar zat besi tinggi perdarahan saluran cerna: adanya luka / perdarahan di kerongkongan dan lambung, beberapa jenis obat antiinflamasi non steroid bisa mengiritasi lambug dan mencetuskan perdarahan (umumnya bila digunakan dalam jangka panjang atau bila memang ada riwayat tukak lambung) sirosis hepatis saya sarankan agar anda kontrol kembali ke dokter yang merawat anda dan sampaikan keluhan bab hitam yang anda alami. dokter akan melakukan pemeriksaan lebih lanjut untuk memastikan penyebab bab hitamnya apakah berhubungan dengan obat yang dikonsumsi atau ada penyakit lainnya. bila diperlukan dokter dapat melakukan tes feses, tes darah, endoskopi, dan usg untuk memastikannya. selanjutnya dokter dapat memberikan anda penanganan yang lebih tepat ya. beberapa tips yang bisa anda lakukan: perbanyak minum air putih hindari konsumsi buah bit, blueberry, atau buah naga untuk sementara waktu hindari suplemen zat besi dulu untuk melihat apakah ada perubahan pada feses setelah suplemen zat besi dihentikan, tetapi sebaiknya dikonsultasikan dulu dengan dokter anda hindari maknaan yang terlalu pedas, asam, atau bergas tinggi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"perut yang perih, diare, mual, pusing, dan demam memang bisa menandakan anda mengalami infeksi saluran pencernaan. diare bisa terjadi karena virus, bakteri, atau parasit. infeksi ini bisa menular melalui makanan dan minuman yang terkontaminasi. selain infeksi, diare juga bisa muncul karena efek samping obat, intoleransi atau malabsorpsi makanan, radang usus, keracunan makanan, sin usus, radang usus buntu, kanker usus, gangguan imunitas, dan sebagainya. demam yang muncul bisa terjadi karena infeksi, namun bisa juga karena efek samping obat, gangguan autoimun, gangguan hormon, dan sebagainya. tidak jarang, keluhan-keluhan anda ini muncul berkaitan dengan infeksi virus corona ( covid-19 ). infeksi ini bisa memicu demam, mual, muntah, diare, pusing, nyeri kepala, nyeri otot, dan keluhan lainnya. untuk memastikan, sebaiknya anda memeriksakan langsung keluhan anda ke dokter atau dokter spesialis penyakit dalam ya.. jika diperlukan, dokter akan melakukan pemeriksaan darah, feses, atau juga usg. sementara ini, anda bisa lakukan dulu: minum obat paracetamol yang dijual bebas supaya demam mereda makan makanan yang sehat dan bersih, lebih baik makan porsi kecil namun sering batasi dulu makanan yang pedas, berminyak, berlemak, dan mengandung banyak gas jangan minum minuman yang berkafein, bersoda, atau mengandung alkohol tidak sembarangan minum obat atau jamu jaga selalu kebersihan tangan anda dan lingkungan sekitar anda minum lebih banyak air putih jangan stres\",\n          \"dokter akan menanyakan riwayat keluhan yang anda alami dan melakukan pemeriksaan fisik. tes penunjang seperti tes darah, usg dapat dokter anjurkan. terapi yang sesuai akan dokter berikan. anjuran yang dapat anda lakukan: hindari menekan atau mengurut bagian yang sakit konsumsi makanan yang bergizi dan bersih secara teratur minum air putih dalam jumlah cukup minimal dua liter setiap hari hindari kebiasaan menahan buang air kecil dan buang air besar hindari mengangkat beban berat artikel yang dapat anda baca: sakit perut bagian bawah\",\n          \"hal ini dapat disebabkan karena perdarahan pada saluran cerna. jika bab berwarna hitam dapat disebabkan karena : perdarahan lambung perdarahan kerongkongan varises esofagus perdarahan usus kecil perdarahan usus besar perdarahan saluran empedu perdarahan hati atau pankreas untuk mengetahui dengan pasti penyebab bab berwarna hitam, diperlukan pemeriksaan lebih lanjut oleh dokter. mungkin diperlukan pemeriksaan darah, endoskopi, kolonoskopi, pemeriksaan feses, dan lain-lain. jika anda memang mengonsumsi obat dari dokter, sebaiknya anda konsultasikan kembali dengan dokter yang menangani anda untuk memastikan apakah obat tersebut dapat menyebabkan bab berwarna hitam.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":26}]},{"cell_type":"markdown","source":["### Contoh hasil rata rata tiap metrik Evaluasi untuk Fine Tune Model"],"metadata":{"id":"FvNgifVeUYDM"}},{"cell_type":"code","source":["mean_ft"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN8w1NaWYrBw","outputId":"f1ba7ea6-1606-4cd4-f35d-7a8dcab518c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["bleu1             26.152145\n","bleu2             12.577292\n","bleu3              6.848691\n","bleu4              4.149928\n","rouge1            30.238819\n","rouge2             6.806361\n","rougeL            15.668782\n","rougeLSum         15.668782\n","bert_precision    69.596678\n","bert_recall       69.194938\n","bert_f1           69.348408\n","dtype: float64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>bleu1</th>\n","      <td>26.152145</td>\n","    </tr>\n","    <tr>\n","      <th>bleu2</th>\n","      <td>12.577292</td>\n","    </tr>\n","    <tr>\n","      <th>bleu3</th>\n","      <td>6.848691</td>\n","    </tr>\n","    <tr>\n","      <th>bleu4</th>\n","      <td>4.149928</td>\n","    </tr>\n","    <tr>\n","      <th>rouge1</th>\n","      <td>30.238819</td>\n","    </tr>\n","    <tr>\n","      <th>rouge2</th>\n","      <td>6.806361</td>\n","    </tr>\n","    <tr>\n","      <th>rougeL</th>\n","      <td>15.668782</td>\n","    </tr>\n","    <tr>\n","      <th>rougeLSum</th>\n","      <td>15.668782</td>\n","    </tr>\n","    <tr>\n","      <th>bert_precision</th>\n","      <td>69.596678</td>\n","    </tr>\n","    <tr>\n","      <th>bert_recall</th>\n","      <td>69.194938</td>\n","    </tr>\n","    <tr>\n","      <th>bert_f1</th>\n","      <td>69.348408</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> float64</label>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["### Menyimpan Hasil Evaluasi"],"metadata":{"id":"G2-EXua3UigJ"}},{"cell_type":"code","source":["ft_model_4.to_csv('Hasil Eval revisi/eval_ft_model_4.csv')"],"metadata":{"id":"4s9UqeXhane3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mean_ft.to_csv('Hasil Eval revisi/eval_ft_model_4_mean.csv')"],"metadata":{"id":"0a0aqLX8at38"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/Hasil_Eval_revisi-4.zip /content/Hasil\\ Eval\\ revisi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCmi9_itazUd","outputId":"c0b030ec-a65e-4df2-8425-cab85a1fe07f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content/Hasil Eval revisi/ (stored 0%)\n","  adding: content/Hasil Eval revisi/eval_ft_model_4_mean.csv (deflated 40%)\n","  adding: content/Hasil Eval revisi/eval_basemodel_4_mean.csv (deflated 38%)\n","  adding: content/Hasil Eval revisi/eval_basemodel_4.csv (deflated 74%)\n","  adding: content/Hasil Eval revisi/eval_ft_model_4.csv (deflated 73%)\n"]}]},{"cell_type":"markdown","source":["# Evaluasi Menggunakan LLM as Judges ðŸ¤–"],"metadata":{"id":"1WpkghGJVyqQ"}},{"cell_type":"markdown","source":["## <img src=\"https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/opik-logo.svg\" width=\"250\"/>"],"metadata":{"id":"Mm9tmTpAzztM"}},{"cell_type":"markdown","source":["Untuk mengevaluasi kualitas jawaban dari model, kami menggunakan pendekatan **LLM-as-a-Judge**, di mana model bahasa besar (LLM) digunakan untuk menilai kualitas output secara semantik, bukan hanya berdasarkan kemiripan kata. Pendekatan ini memberikan evaluasi yang lebih dekat dengan penilaian manusia, terutama dalam konteks tugas pemahaman bahasa alami yang kompleks seperti tanya jawab medis.\n","\n","Dalam penelitian ini, kami menggunakan platform **[Opik](https://www.comet.com/site/products/opik/)** dari **Comet**, yaitu framework evaluasi open-source yang mendukung integrasi dengan berbagai metrik penilaian berbasis LLM. Kami memilih Opik karena:\n","\n","* Mendukung **evaluasi otomatis berbasis semantik**,\n","* Mampu menghasilkan **skor numerik dan penilaian kualitatif**"],"metadata":{"id":"MaqkQm0XXTZQ"}},{"cell_type":"markdown","source":["### âœ… Metrik Evaluasi yang Digunakan\n","\n","Berikut adalah empat metrik utama yang digunakan untuk menilai jawaban model:\n","\n","1. **Hallucination**\n","   Menilai apakah jawaban mengandung **informasi yang tidak akurat atau tidak berdasarkan input**. Skor tinggi menunjukkan fakta yang sesuai dan tidak mengada-ada (*non-hallucinated*).\n","\n","2. **Answer Relevance**\n","   Mengukur sejauh mana jawaban yang diberikan **relevan dan sesuai dengan pertanyaan**. Metrik ini penting untuk mengetahui apakah model memahami konteks dengan benar.\n","\n","3. **Usefulness**\n","   Mengevaluasi apakah jawaban yang dihasilkan **memberikan nilai tambah atau membantu pengguna**, terutama dalam konteks praktis atau medis.\n","\n","4. **Moderation**\n","   Menilai apakah jawaban **mengandung konten yang berbahaya, tidak pantas, atau melanggar etika**. Skor tinggi menunjukkan bahwa jawaban aman dan layak ditampilkan ke publik.\n"],"metadata":{"id":"yqyDDW4aXnq4"}},{"cell_type":"markdown","source":["### ðŸ“Š Output Penilaian\n","\n","Setiap metrik menghasilkan **skor dalam rentang 0â€“10**, di mana:\n","\n","* Skor **lebih tinggi** menunjukkan kualitas yang lebih baik (misalnya relevansi tinggi, tidak halu, bermanfaat, dan aman).\n","* Sistem juga dapat memberikan **penjelasan kualitatif** sebagai justifikasi atas skor yang diberikan.\n","\n","---\n","\n"],"metadata":{"id":"lVoYEuSMX2Sf"}},{"cell_type":"markdown","source":["### Contoh promt yang digunakan untuk Evaluasi"],"metadata":{"id":"ECXzfZNQZWmA"}},{"cell_type":"markdown","source":["#### Hallucination\n","```\n","You are an expert judge tasked with evaluating the faithfulness of an AI-generated answer to the given context. Analyze the provided INPUT, CONTEXT, and OUTPUT to determine if the OUTPUT contains any hallucinations or unfaithful information.\n","\n","Guidelines:\n","\n","1. The OUTPUT must not introduce new information beyond what's provided in the CONTEXT.\n","2. The OUTPUT must not contradict any information given in the CONTEXT.\n","3. The OUTPUT should not contradict well-established facts or general knowledge.\n","4. Ignore the INPUT when evaluating faithfulness; it's provided for context only.\n","5. Consider partial hallucinations where some information is correct but other parts are not.\n","6. Pay close attention to the subject of statements. Ensure that attributes, actions, or dates are correctly associated with the right entities (e.g., a person vs. a TV show they star in).\n","7. Be vigilant for subtle misattributions or conflations of information, even if the date or other details are correct.\n","8. Check that the OUTPUT doesn't oversimplify or generalize information in a way that changes its meaning or accuracy.\n","\n","Analyze the text thoroughly and assign a hallucination score between 0 and 1, where:\n","\n","- 0.0: The OUTPUT is entirely faithful to the CONTEXT\n","- 1.0: The OUTPUT is entirely unfaithful to the CONTEXT\n","\n","{examples_str}\n","\n","INPUT (for context only, not to be used for faithfulness evaluation):\n","{input}\n","\n","CONTEXT:\n","{context}\n","\n","OUTPUT:\n","{output}\n","\n","It is crucial that you provide your answer in the following JSON format:\n","{{\n","    \"score\": <your score between 0.0 and 1.0>,\n","    \"reason\": [\"reason 1\", \"reason 2\"]\n","}}\n","Reasons amount is not restricted. Output must be JSON format only.\n","```"],"metadata":{"id":"hL8skE9maIIM"}},{"cell_type":"markdown","source":["ðŸ”— Untuk informasi lebih lengkap tentang masing-masing metrik\n","\n","* [Hallucination](https://www.comet.com/docs/opik/evaluation/metrics/hallucination)\n","* [Answer Relevance](https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance)\n","* [Usefulness](https://www.comet.com/docs/opik/evaluation/metrics/usefulness)\n","* [Moderation](https://www.comet.com/docs/opik/evaluation/metrics/moderation)\n","\n","---"],"metadata":{"id":"SEWnJ--cajPJ"}},{"cell_type":"markdown","source":["### LLM as a Judges untuk model  (Base & Fine Tune)"],"metadata":{"id":"fC9ZI9eXWW1E"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W2RoJE0Fze2G","outputId":"2b994cfe-4222-43c6-fec1-fb28466445f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m885.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m565.2/565.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m727.1/727.1 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install opik openai comet_ml litellm --quiet"]},{"cell_type":"code","source":["import opik\n","from opik import Opik, track\n","from opik.evaluation import evaluate\n","from opik.evaluation.metrics import (Hallucination, AnswerRelevance, Moderation, Usefulness)\n","from opik.integrations.openai import track_openai\n","import openai\n","import os\n","from datetime import datetime\n","from getpass import getpass\n","import litellm\n","\n","# Define project name to enable tracing\n","os.environ[\"OPIK_PROJECT_NAME\"] = \"Eval LLM NLP\""],"metadata":{"id":"DgsM03Idz2wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata"],"metadata":{"id":"icOBBlEh0GZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# opik configs | set di secret colab\n","if \"OPIK_API_KEY\" not in os.environ:\n","    os.environ[\"OPIK_API_KEY\"] = userdata.get('OPIK_API_KEY')"],"metadata":{"id":"dwmtAEP10Gti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["workspace = 'final-projek-nlp'"],"metadata":{"id":"7BXoErhk0NIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opik.configure(workspace= workspace)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iv0JESE70I0v","outputId":"51c168b8-0ff2-4e25-8887-feb0d26c0ea7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["OPIK: Opik is already configured. You can check the settings by viewing the config file at /root/.opik.config\n"]}]},{"cell_type":"code","source":["client = Opik()"],"metadata":{"id":"EUoR_zKs0iYP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.environ['OPENROUTER_API_KEY'] = userdata.get('OPENROUTER_API_KEY')"],"metadata":{"id":"Zm_X2rcl0isD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### LLM Client"],"metadata":{"id":"Ts5AceEMW6L3"}},{"cell_type":"code","source":["class LLMClient:\n","    def __init__(self, client_type: str = \"openai\", model: str = \"gpt-4\"):\n","        self.client_type = client_type\n","        self.model = model\n","\n","        if self.client_type == \"openai\":\n","            self.client = track_openai(openai.OpenAI())\n","        else:  # LiteLLM via OpenRouter\n","            self.client = track_openai(\n","                openai.OpenAI(\n","                    base_url=\"https://openrouter.ai/api/v1\",\n","                    api_key=os.environ[\"OPENROUTER_API_KEY\"]\n","                )\n","            )\n","\n","    def _get_litellm_response(self, query: str, system: str = \"You are a helpful assistant.\"):\n","        messages = [\n","            {\"role\": \"system\", \"content\": system},\n","            {\"role\": \"user\", \"content\": query}\n","        ]\n","        response = litellm.completion(model=self.model, messages=messages)\n","        return response.choices[0].message[\"content\"]\n","\n","    def _get_openai_response(self, query: str, system: str = \"You are a helpful assistant.\", **kwargs):\n","        messages = [\n","            {\"role\": \"system\", \"content\": system},\n","            {\"role\": \"user\", \"content\": query}\n","        ]\n","        response = self.client.chat.completions.create(\n","            model=self.model,\n","            messages=messages,\n","            **kwargs\n","        )\n","        return response.choices[0].message.content\n","\n","    def query(self, query: str, system: str = \"You are a helpful assistant.\", **kwargs):\n","        if self.client_type == 'openai':\n","            return self._get_openai_response(query, system, **kwargs)\n","        else:\n","            return self._get_litellm_response(query, system)"],"metadata":{"id":"cvKLqw-60rcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# To set clinet\n","MODEL= 'openrouter/deepseek/deepseek-r1' # model bebas milih selama ada di OpenRouter\n","llm_client = LLMClient(model=MODEL, client_type='litellm')"],"metadata":{"id":"_8isMyos0ye6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm_client.query('Pagi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"HKqyVDW8QYi7","outputId":"fc52cc4a-cc59-4a5d-f297-7f66e399fde4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Selamat pagi! Ada yang bisa saya bantu hari ini?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["list-dataset"],"metadata":{"id":"1GLvZvSY2Lo4"}},{"cell_type":"markdown","source":["[link dataset opik](https://www.comet.com/opik/final-projek-nlp/datasets)"],"metadata":{"id":"l3nrdwwFXn8E"}},{"cell_type":"markdown","source":["#### Dataset\n","Ini adalah dataset beris hasil ouput dari model base dan fine tune. Masing Masing dataset ini akan diberikan kepada LLM untuk penilaini"],"metadata":{"id":"7k2vOmwcYvu4"}},{"cell_type":"code","source":["list_dataset = ['Model-1 Base | unsloth/mistral-7b-v0.3',\n"," 'Model-1 ft | unsloth/mistral-7b-v0.3',\n"," 'Model-2 Base | unsloth/mistral-7b-v0.3',\n"," 'Model-2 ft | unsloth/mistral-7b-v0.3',\n"," 'Model-3 Base | unsloth/mistral-7b-instruct-v0.2-bnb-4bit',\n"," 'Model-3 ft | unsloth/mistral-7b-instruct-v0.2-bnb-4bit',\n"," 'Model-4 Base | unsloth/llama-3-8b-bnb-4bit',\n"," 'Model-4 ft | unsloth/llama-3-8b-bnb-4bit',\n"," 'Model-5 Base | GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct',\n"," 'Model-5 ft | GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct',\n"," 'Model-6 Base | GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct',\n"," 'Model-6 ft | GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct',\n"," 'Model-7 Base | Yellow-AI-NLP/komodo-7b-base',\n"," 'Model-7 ft | Yellow-AI-NLP/komodo-7b-base',\n"," 'Model-8 Base | Yellow-AI-NLP/komodo-7b-base',\n"," 'Model-8 ft | Yellow-AI-NLP/komodo-7b-base']"],"metadata":{"id":"y9az1RoN2M8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create or get the dataset\n","# contoh disini karena untuk model 1\n","dataset = client.get_or_create_dataset(name=\"Model-1 Base | unsloth/mistral-7b-v0.3\")"],"metadata":{"id":"a-rHon3T0zES"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Membuat  custom model"],"metadata":{"id":"lKOcEVFmXwny"}},{"cell_type":"code","source":["from opik.evaluation.models import OpikBaseModel\n","from typing import List, Dict, Any\n","\n","class CustomModel(OpikBaseModel):\n","    def __init__(self, model_name: str = \"gpt-4\", client_type: str = \"openai\"):\n","        super().__init__(model_name)\n","        self.client = LLMClient(client_type=client_type, model=model_name)\n","\n","    def generate_provider_response(self, messages: List[Dict[str, Any]], **kwargs: Any) -> str:\n","        if not messages or messages[-1][\"role\"] != \"user\":\n","            raise ValueError(\"Last message must be from user.\")\n","        system_message = messages[0][\"content\"] if messages[0][\"role\"] == \"system\" else \"You are a helpful assistant.\"\n","        user_message = messages[-1][\"content\"]\n","        return self.client.query(user_message, system=system_message, **kwargs)\n","\n","    def generate_string(self, input: str, **kwargs: Any) -> str:\n","        return self.client.query(input, **kwargs)"],"metadata":{"id":"waligIY33MP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def simple_evaluation_task(item):\n","    return {\n","        \"input\": item[\"input\"],\n","        \"output\": item[\"prediction\"],\n","        \"context\": item[\"reference\"]  # reference jadi context untuk hallucination check misal\n","    }"],"metadata":{"id":"PZ3xeEkd3My1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model Custom untuk evaluasi\n","MODEL = 'openrouter/deepseek/deepseek-r1:free'\n","custom_model = CustomModel(model_name=MODEL, client_type=\"litellm\")"],"metadata":{"id":"zXG8kcZ03Svd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from opik.evaluation.metrics import (Hallucination, AnswerRelevance, Moderation, Usefulness)"],"metadata":{"id":"szuRm2KW4qd9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Hallucination metric\n","hallucination_metric = Hallucination(model=custom_model)\n","AnswerRelevanceMetric = AnswerRelevance(model=custom_model)\n","ModerationMetric = Moderation(model=custom_model)\n","UsefulnessMetric = Usefulness(model=custom_model)"],"metadata":{"id":"e2JqNeXr4E1b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Nama eksperimen\n","experiment_name = f\"{list_dataset[0]} | {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')} | model as judges evaluation: {MODEL}\"\n","experiment_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"FhyUlUlR5Aa4","outputId":"63df41da-8ea7-49f3-b6f0-c7bd49d65e36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Model-1 Base | unsloth/mistral-7b-v0.3 | 2025-05-31_10-09-42 | model as judges evaluation: openrouter/deepseek/deepseek-r1:free'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["# Run evaluation\n","evaluation = evaluate(\n","    experiment_name=experiment_name,\n","    dataset=dataset,\n","    task=simple_evaluation_task,\n","    scoring_metrics=[hallucination_metric, AnswerRelevanceMetric, ModerationMetric, UsefulnessMetric],\n","    experiment_config={\"model\": MODEL,\n","                       \"dataset\" : dataset.name},\n","    task_threads=10,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d104b9ddd845488f9adf66ee2fc4d392","d0406b028c2248549526c5472d3e79c6","685a89fb03e648e18fc0ead76fc5dbd5","e77d727c58f54a99bff29e9ec499cf8c","e2cb4a0a5baf46ddaf9c8433c53db864","ea093126ed644386a6212df8a8ed087e","02e9405a6e674a97b7c2ebf54c88a41f","d6b9bc7f99e14187b8f85424eb48be3d","8b45779bb97d478ba495c34e02277a64","bea5aabb0cc142d595e554554394129d","d2c8307ac52f4025abfa4f90865c5f6f"]},"collapsed":true,"id":"4vdhmVnh5HwF","outputId":"fad97c28-a597-4419-e788-43d972ff9ba0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluation:   0%|          | 0/139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d104b9ddd845488f9adf66ee2fc4d392"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to parse model output: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 129, in score\n","    return parser.parse_model_output(content=model_output, name=self.name)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 24, in parse_model_output\n","    raise exceptions.MetricComputationError(\n","opik.exceptions.MetricComputationError: Failed to calculate answer relevance score\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662200000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to parse model output: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 95, in score\n","    return parser.parse_model_output(content=model_output, name=self.name)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/parser.py\", line 26, in parse_model_output\n","    raise exceptions.MetricComputationError(\n","opik.exceptions.MetricComputationError: Failed hallucination detection\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662260000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to parse model output: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 22, in _extract_presumably_json_dict_or_raise\n","    return json.loads(json_string)\n","           ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/__init__.py\", line 346, in loads\n","    return _default_decoder.decode(s)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 337, in decode\n","    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.11/json/decoder.py\", line 355, in raw_decode\n","    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n","json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 11, in parse_model_output\n","    dict_content = parsing_helpers.extract_json_content_or_raise(content)\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 10, in extract_json_content_or_raise\n","    return _extract_presumably_json_dict_or_raise(content)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/parsing_helpers.py\", line 24, in _extract_presumably_json_dict_or_raise\n","    raise exceptions.JSONParsingError(\n","opik.exceptions.JSONParsingError: Failed to extract presumably JSON dictionary: Expecting value: line 1 column 1 (char 0)\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 129, in score\n","    return parser.parse_model_output(content=model_output, name=self.name)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/parser.py\", line 24, in parse_model_output\n","    raise exceptions.MetricComputationError(\n","opik.exceptions.MetricComputationError: Failed to calculate answer relevance score\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric hallucination_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/hallucination/metric.py\", line 91, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric answer_relevance_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/answer_relevance/metric.py\", line 126, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n","\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric moderation_metric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/moderation/metric.py\", line 78, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n","OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2145, in exception_type\n","    raise RateLimitError(\n","litellm.exceptions.RateLimitError: litellm.RateLimitError: RateLimitError: OpenrouterException - {\"error\":{\"message\":\"Rate limit exceeded: free-models-per-min. \",\"code\":429,\"metadata\":{\"headers\":{\"X-RateLimit-Limit\":\"20\",\"X-RateLimit-Remaining\":\"0\",\"X-RateLimit-Reset\":\"1748662320000\"},\"provider_name\":null}},\"user_id\":\"user_2p1Pw7VZBtsBz0IdBJCDdpiiL16\"}\n","OPIK: LLM provider rate limit error detected. We recommend reducing the amount of parallel requests by setting `task_threads` evaluation parameter to a smaller number\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/evaluation_tasks_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(evaluation_tasks, workers, verbose)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         test_results = [\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtest_result_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/evaluation_tasks_executor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         test_results = [\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mtest_result_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-5956c2febb97>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m evaluation = evaluate(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msimple_evaluation_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/evaluator.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, task, scoring_metrics, experiment_name, project_name, experiment_config, verbose, nb_samples, task_threads, prompt, prompts, scoring_key_mapping, dataset_item_ids)\u001b[0m\n\u001b[1;32m     92\u001b[0m     )\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     return _evaluate_task(\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/evaluator.py\u001b[0m in \u001b[0;36m_evaluate_task\u001b[0;34m(client, experiment, dataset, task, scoring_metrics, project_name, verbose, nb_samples, task_threads, scoring_key_mapping, dataset_item_ids)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mscoring_key_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring_key_mapping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         )\n\u001b[0;32m--> 135\u001b[0;31m         test_results = evaluation_engine.evaluate_llm_tasks(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mdataset_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\u001b[0m in \u001b[0;36mevaluate_llm_tasks\u001b[0;34m(self, dataset_, task, nb_samples, dataset_item_ids)\u001b[0m\n\u001b[1;32m    174\u001b[0m         ]\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         test_results = evaluation_tasks_executor.execute(\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mevaluation_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/evaluation_tasks_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(evaluation_tasks, workers, verbose)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         test_result_futures = [\n\u001b[1;32m     29\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_task\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevaluation_task\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# Nama eksperimen\n","\n","MODEL = 'openrouter/openai/gpt-4o-mini'\n","custom_model = CustomModel(model_name=MODEL, client_type=\"litellm\")\n","\n","experiment_name = f\"{list_dataset[0]} | {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')} | model as judges evaluation: {MODEL}\"\n","experiment_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"kZtlLAnDbcos","outputId":"2ab41880-f89d-408f-a776-e03e3e710fc6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Model-1 Base | unsloth/mistral-7b-v0.3 | 2025-05-31_03-42-25 | model as judges evaluation: openrouter/openai/gpt-4o-mini'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","source":["#### Function for evaluation"],"metadata":{"id":"ClimI4NN0KJ_"}},{"cell_type":"code","source":["from datetime import datetime\n","\n","def run_evaluation(model_name, dataset,no_dataset, thread, sample= None):\n","    custom_model = CustomModel(model_name=model_name, client_type=\"litellm\")\n","\n","    # Metrik evaluasi\n","    hallucination = Hallucination(model=custom_model)\n","    relevance = AnswerRelevance(model=custom_model)\n","    moderation = Moderation(model=custom_model)\n","    usefulness = Usefulness(model=custom_model)\n","\n","    # Nama eksperimen\n","    experiment_name = f\"{list_dataset[no_dataset]} | {datetime.now().strftime('%Y-%m-%d_%H-%M-%S')} | model as judges evaluation: {model_name}\"\n","\n","    # Jalankan evaluasi\n","    evaluation = evaluate(\n","        experiment_name=experiment_name,\n","        dataset=dataset,\n","        task=simple_evaluation_task,\n","        scoring_metrics=[hallucination, relevance, moderation, usefulness],\n","        experiment_config={\"model\": model_name, \"dataset\": dataset.name},\n","        task_threads=thread,\n","        nb_samples=sample\n","    )\n","\n","    return evaluation"],"metadata":{"id":"RNclcXeygQPR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Evaluasi dengan LLM as judges\n","\n","Berikut adalah satu contoh penerapannya"],"metadata":{"id":"8O0u3UxqxGlj"}},{"cell_type":"markdown","source":["####  Base"],"metadata":{"id":"POTw9cy5vaYW"}},{"cell_type":"code","source":["MODEL = 'openrouter/openai/gpt-4o-mini'\n","dataset_no = 0 # index\n","task_thread = 4\n","sample = None\n","dataset = client.get_or_create_dataset(name=list_dataset[dataset_no])\n","result = run_evaluation(MODEL, dataset, dataset_no, task_thread, sample=sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261,"referenced_widgets":["4a1a11805c6c46429156045e77d9a6e8","7499ad6d96ef477aaaa5c37e3d13db20","7ba5d1a92969426991d45530202ad424","c29f0cced4734558bd9c234fb4de2043","0187071be4f94727925d2d07a360fc9d","7c10e4e60c5a434ba2decad2e5a30f09","836f20e3643545baa3af82e0a6ccb5a9","71a39dcae0cb48e3a095a39c335555ae","bdfa53cb79fd49b0b539af65f074651f","34fa9642fa6648b3bd2de5d9dd00f154","8308a9461dcc42e4a6d24e96a27e7a21"]},"id":"ax4A7pnAgh6-","outputId":"d8fd0cd2-6e19-47fe-db33-be4f135c96f7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluation:   0%|          | 0/139 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a1a11805c6c46429156045e77d9a6e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["â•­â”€ Model-1 Base | unsloth/mistral-7b-v0.3 (139 samples) â”€â•®\n","â”‚                                                        â”‚\n","â”‚ \u001b[1mTotal time:       \u001b[0m 00:04:49                            â”‚\n","â”‚ \u001b[1mNumber of samples:\u001b[0m 139                                 â”‚\n","â”‚                                                        â”‚\n","â”‚ \u001b[1;32mhallucination_metric: 0.7525 (avg)\u001b[0m                     â”‚\n","â”‚ \u001b[1;32manswer_relevance_metric: 0.4665 (avg)\u001b[0m                  â”‚\n","â”‚ \u001b[1;32mmoderation_metric: 0.0230 (avg)\u001b[0m                        â”‚\n","â”‚ \u001b[1;32mUsefulnessMetric: 0.2561 (avg)\u001b[0m                         â”‚\n","â”‚                                                        â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€ Model-1 Base | unsloth/mistral-7b-v0.3 (139 samples) â”€â•®\n","â”‚                                                        â”‚\n","â”‚ <span style=\"font-weight: bold\">Total time:       </span> 00:04:49                            â”‚\n","â”‚ <span style=\"font-weight: bold\">Number of samples:</span> 139                                 â”‚\n","â”‚                                                        â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">hallucination_metric: 0.7525 (avg)</span>                     â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">answer_relevance_metric: 0.4665 (avg)</span>                  â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">moderation_metric: 0.0230 (avg)</span>                        â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">UsefulnessMetric: 0.2561 (avg)</span>                         â”‚\n","â”‚                                                        â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Uploading results to Opik \u001b[33m...\u001b[0m \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["View the results \u001b]8;id=422756;https://www.comet.com/opik/api/v1/session/redirect/experiments/?experiment_id=01972484-ad58-7f93-87b0-5c405db20ba5&dataset_id=019723cb-8132-7b6c-8a09-5e865fd216c6&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/api/v1/session/redirect/experiments/?experiment_id=01972484-ad58-7f93-87b0-5c405db20ba5&dataset_id=019723cb-8132-7b6c-8a09-5e865fd216c6&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\" target=\"_blank\">in your Opik dashboard</a>.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["####  FT"],"metadata":{"id":"Fj7Clh7mkpOB"}},{"cell_type":"code","source":["MODEL = 'openrouter/openai/gpt-4o-mini'\n","dataset_no = 1 # index\n","task_thread = 4\n","sample = None\n","dataset = client.get_or_create_dataset(name=list_dataset[dataset_no])\n","result = run_evaluation(MODEL, dataset, dataset_no, task_thread, sample=sample)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["3dbfeea9f13d46929862420652999b17","06a90c6c8b5e4153abf4b6c4e4f24e1c","e956672642e54fefa31be8b4c6ecf839","ffc1d54e95e44aea9a323a2ed29f8976","a0adc22938a04c8fa26e8c0330aaf1d0","514cc126d9b143f89123a60c16ebb4d2","b148b6b2425c4251923057676135f803","cecdd04f9b7a4d96acfd8a5a1026c233","0bf6b793a162483fa0c7f38aae129685","e9dfd14099da42f0b72484050525079f","f7c7bc2666ee4b61ad34bef0cca56fd3"]},"id":"eVSKHZ1ukRRy","outputId":"7b7b0b19-c7c8-4150-8f1f-46681421ee04"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluation:   0%|          | 0/148 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dbfeea9f13d46929862420652999b17"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["OPIK: Failed to compute metric UsefulnessMetric. Score result will be marked as failed.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 159, in _make_common_sync_call\n","    response = sync_httpx_client.post(\n","               ^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 694, in post\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/http_handler.py\", line 676, in post\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.11/dist-packages/httpx/_models.py\", line 829, in raise_for_status\n","    raise HTTPStatusError(message, request=request, response=self)\n","httpx.HTTPStatusError: Server error '500 Internal Server Error' for url 'https://openrouter.ai/api/v1/chat/completions'\n","For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 2383, in completion\n","    response = base_llm_http_handler.completion(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 447, in completion\n","    response = self._make_common_sync_call(\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 184, in _make_common_sync_call\n","    raise self._handle_error(e=e, provider_config=provider_config)\n","          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/llms/custom_httpx/llm_http_handler.py\", line 2048, in _handle_error\n","    raise provider_config.get_error_class(\n","litellm.llms.openrouter.common_utils.OpenRouterException: {\"error\":{\"message\":\"Internal Server Error\",\"code\":500}}\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/engine/engine.py\", line 58, in _evaluate_test_case\n","    result = metric.score(**score_kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 314, in wrapper\n","    raise func_exception\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/decorator/base_track_decorator.py\", line 287, in wrapper\n","    result = func(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/opik/evaluation/metrics/llm_judges/usefulness/metric.py\", line 80, in score\n","    model_output = self._model.generate_string(\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-14-92475b59c1a9>\", line 17, in generate_string\n","    return self.client.query(input, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 40, in query\n","    return self._get_litellm_response(query, system)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<ipython-input-9-ec59a9114300>\", line 21, in _get_litellm_response\n","    response = litellm.completion(model=self.model, messages=messages)\n","               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1283, in wrapper\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/utils.py\", line 1161, in wrapper\n","    result = original_function(*args, **kwargs)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/main.py\", line 3241, in completion\n","    raise exception_type(\n","          ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2239, in exception_type\n","    raise e\n","  File \"/usr/local/lib/python3.11/dist-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2172, in exception_type\n","    raise APIError(\n","litellm.exceptions.APIError: litellm.APIError: APIError: OpenrouterException - {\"error\":{\"message\":\"Internal Server Error\",\"code\":500}}\n"]},{"output_type":"stream","name":"stdout","text":["\n","\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n","LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n","\n"]},{"output_type":"display_data","data":{"text/plain":["â•­â”€ Model-1 ft | unsloth/mistral-7b-v0.3 (148 samples) â”€â•®\n","â”‚                                                      â”‚\n","â”‚ \u001b[1mTotal time:       \u001b[0m 00:05:58                          â”‚\n","â”‚ \u001b[1mNumber of samples:\u001b[0m 148                               â”‚\n","â”‚                                                      â”‚\n","â”‚ \u001b[1;32mhallucination_metric: 0.5020 (avg)\u001b[0m                   â”‚\n","â”‚ \u001b[1;32manswer_relevance_metric: 0.8291 (avg)\u001b[0m                â”‚\n","â”‚ \u001b[1;32mmoderation_metric: 0.0020 (avg)\u001b[0m                      â”‚\n","â”‚ \u001b[1;32mUsefulnessMetric: 0.6871 (avg)\u001b[0m\u001b[31m - 1 failed\u001b[0m            â”‚\n","â”‚                                                      â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â•­â”€ Model-1 ft | unsloth/mistral-7b-v0.3 (148 samples) â”€â•®\n","â”‚                                                      â”‚\n","â”‚ <span style=\"font-weight: bold\">Total time:       </span> 00:05:58                          â”‚\n","â”‚ <span style=\"font-weight: bold\">Number of samples:</span> 148                               â”‚\n","â”‚                                                      â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">hallucination_metric: 0.5020 (avg)</span>                   â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">answer_relevance_metric: 0.8291 (avg)</span>                â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">moderation_metric: 0.0020 (avg)</span>                      â”‚\n","â”‚ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">UsefulnessMetric: 0.6871 (avg)</span><span style=\"color: #800000; text-decoration-color: #800000\"> - 1 failed</span>            â”‚\n","â”‚                                                      â”‚\n","â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Uploading results to Opik \u001b[33m...\u001b[0m \n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["View the results \u001b]8;id=188937;https://www.comet.com/opik/api/v1/session/redirect/experiments/?experiment_id=019724a7-da3c-7662-9d3f-882ddfb4b6ec&dataset_id=019723cb-82d2-751c-86cb-ef9e0213ec6b&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/api/v1/session/redirect/experiments/?experiment_id=019724a7-da3c-7662-9d3f-882ddfb4b6ec&dataset_id=019723cb-82d2-751c-86cb-ef9e0213ec6b&path=aHR0cHM6Ly93d3cuY29tZXQuY29tL29waWsvYXBpLw==\" target=\"_blank\">in your Opik dashboard</a>.\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Hasil dan kesimpulan"],"metadata":{"id":"91jN7-Pva3Yn"}},{"cell_type":"markdown","source":["## Tabel Metrik Kuantitatif"],"metadata":{"id":"d64tRnutdFYw"}},{"cell_type":"markdown","source":["|Model                                                        |bert_precision|bert_recall |bert_f1     |bleu1      |bleu2      |bleu3      |bleu4       |rouge1     |rouge2     |rougeL     |rougeLSum  |\n","|-------------------------------------------------------------|--------------|------------|------------|-----------|-----------|-----------|------------|-----------|-----------|-----------|-----------|\n","|Base Model 1 &#124; mistral-7b-v0.3                               |0.6211690002  |0.5893319779|0.6037431226|8.294900332|2.776794579|1.418423648|0.9493882534|11.42368319|1.42253989 |7.027056194|6.924935837|\n","|Finetuning Model Base 1 &#124; mistral-7b-v0.3                    |68.89656134   |68.59254551 |68.69144057 |26.40711447|12.6368507 |6.892742053|4.184926041 |30.29405405|6.696875565|15.46129952|15.46129952|\n","|Base Model 3 &#124; mistral-7b-instruct-v0.2-bnb-4bit             |0.6516675359  |0.6312426523|0.640989964 |12.96068764|4.302880714|2.145769235|1.413014908 |13.84793309|1.864717171|7.20778839 |7.849656376|\n","|Finetuning Model Base 3 &#124; mistral-7b-instruct-v0.2-bnb-4bit  |69.34224242   |69.16117907 |69.21357286 |27.09274326|13.04775774|7.174045826|4.48545549  |31.16239553|6.961255206|16.03152406|16.03152406|\n","|Base Model 4 &#124; llama-3-8b-bnb-4bit                           |0.6286781257  |0.6001730639|0.6130409542|8.522933346|2.880937301|1.473571158|0.9808751212|12.31186716|1.2991525  |7.692549568|7.344693805|\n","|Finetuning Model Base 4 &#124; llama-3-8b-bnb-4bit                |69.59667808   |69.19493806 |69.34840757 |26.15214464|12.57729233|6.848690689|4.149928476 |30.23881864|6.806361297|15.66878166|15.66878166|\n","|Base Model 5 &#124; llama3-8b-cpt-sahabatai-v1-instruct           |0.6811708496  |0.6525815765|0.6661404854|18.57281043|7.586095203|3.901354007|2.448177036 |25.70774977|4.680530871|13.40721771|16.23012061|\n","|Finetuning Model Base 5 &#124; llama3-8b-cpt-sahabatai-v1-instruct|69.75471719   |67.46975004 |68.56779786 |23.16172868|11.11923387|6.203401582|3.837907526 |27.61096927|6.217842509|14.46797133|14.68457661|\n","|Base Model 6 &#124; gemma2-9b-cpt-sahabatai-v1-instruct           |0.6815175981  |0.6697744528|0.6752528519|22.63963186|9.460875114|4.627718059|2.704908716 |29.47293451|5.410137253|14.84449991|18.23299866|\n","|Finetuning Model Base 6 &#124; gemma2-9b-cpt-sahabatai-v1-instruct|69.13028073   |69.10689962 |69.08257461 |27.26944609|13.11725512|7.260492495|4.473363274 |32.10991846|7.441202873|15.99050032|15.99050032|\n","|Base Model 7 &#124; Yellow-AI-NLP/komodo-7b-base                  |0.6343380072  |0.6379869936|0.6354655033|15.79090906|6.193109824|3.071179484|1.874798565 |20.21779641|3.355581782|10.55275484|13.15026689|\n","|Finetuning Model Base 7 &#124; Yellow-AI-NLP/komodo-7b-base       |68.5384351    |68.22293395 |68.32389957 |24.44578573|11.25720268|6.068727944|3.769305614 |29.04151225|6.365640991|15.21155278|15.21155278|\n","|Base Model 8 &#124; Yellow-AI-NLP/komodo-7b-base                  |0.6343380072  |0.6379869936|0.6354655033|15.79090906|6.193109824|3.071179484|1.874798565 |20.21779641|3.355581782|10.55275484|13.15026689|\n","|Finetuning Model Base 8 &#124; Yellow-AI-NLP/komodo-7b-base       |69.75249445   |69.73712081 |69.6947636  |28.3674836 |13.87887454|7.906611648|5.103033641 |32.21540203|7.605137453|16.79883638|16.79883638|\n","|Max                                                          |69.75471719   |69.73712081 |69.6947636  |28.3674836 |13.87887454|7.906611648|5.103033641 |32.21540203|7.605137453|16.79883638|18.23299866|\n"],"metadata":{"id":"eOe7qO-NbQQK"}},{"cell_type":"markdown","source":["## Tabel Hasil Metrik LLM as a Judges"],"metadata":{"id":"gbOwcI_Zddbz"}},{"cell_type":"markdown","source":["|No                                                           |Nama Model  |Tipe        |Hallucination (avg)|Answer Relevance (avg)|Moderation (avg)|Usefulness (avg)|Catatan Kegagalan Metrik|\n","|-------------------------------------------------------------|------------|------------|-------------------|----------------------|----------------|----------------|------------------------|\n","|1                                                            |unsloth/mistral-7b-v0.3|Base        |7,525              |4,665                 |0,0230          |2,561           |Halusinas tinggi, Answer Relevance rendah, usefulness rendah|\n","|1                                                            |unsloth/mistral-7b-v0.3|ft          |5,020              |8,291                 |0.020           |6,871           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n","|3                                                            |unsloth/mistral-7b-instruct-v0.2-bnb-4bit|Base        |7,069              |7,718                 |0.0010          |6,257           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n","|3                                                            |unsloth/mistral-7b-instruct-v0.2-bnb-4bit|ft          |4,870              |8,265                 |0,0080          |7,051           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n","|4                                                            |unsloth/llama-3-8b-bnb-4bit|Base        |7,510              |5,640                 |0,0180          |3,400           |Halusinas tinggi, Answer Relevance rendah, usefulness rendah|\n","|4                                                            |unsloth/llama-3-8b-bnb-4bit|ft          |4,820              |8,320                 |0,0050          |6,990           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n","|5                                                            |GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct|Base        |4,171              |8,543                 |0,0019          |7,327           |Moderation: 1 gagal, Usefulness: 1 gagal|\n","|5                                                            |GoToCompany/llama3-8b-cpt-sahabatai-v1-instruct|ft          |4,950              |8,147                 |0               |6,408           |Hallucination: 2 gagal, Relevance: 1 gagal, Moderation: 1 gagal|\n","|6                                                            |GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct|Base        |3,284              |8,860                 |0               |7,931           |Relevance: 2 gagal, Usefulness: 1 gagal|\n","|6                                                            |GoToCompany/gemma2-9b-cpt-sahabatai-v1-instruct|ft          |5,120              |8,505                 |0,0120          |7,260           |-                       |\n","|7                                                            |Yellow-AI-NLP/komodo-7b-base|Base        |6,365              |7,218                 |0,0136          |4,904           |Relevance: 1 gagal, Moderation: 1 gagal|\n","|7                                                            |Yellow-AI-NLP/komodo-7b-base|ft          |5,770              |8,215                 |0,0070          |6,800           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n","|8                                                            |Yellow-AI-NLP/komodo-7b-base|Base        |6,433              |7,250                 |0,0117          |4,788           |Relevance: 1 gagal, Moderation: 1 gagal|\n","|8                                                            |Yellow-AI-NLP/komodo-7b-base|ft          |4,667              |8,318                 |0,0020          |7,080           |- Halusianasi menurun- Answer Relevance  dan usefulness naik|\n"],"metadata":{"id":"axWxwNUwdi0Y"}},{"cell_type":"markdown","source":["##Kesimpulan\n","\n","* Penelitian ini  mengembangkan **chatbot kesehatan berbahasa Indonesia** yang berfokus pada sistem pencernaan, dengan pendekatan fine-tuning QLoRA terhadap 7 model LLM berbeda.\n","* Dataset yang digunakan berasal dari **Medical QA Indonesia** yang telah difilter khusus untuk domain pencernaan.\n","* Fine-tuning dengan QLoRA terbukti meningkatkan performa model, terutama dalam aspek **Answer Relevance**, **Usefulness**, dan **BERTScore F1**.\n","* Evaluasi kuantitatif (BLEU, ROUGE) menunjukkan peningkatan kemiripan jawaban terhadap referensi.\n","* Tidak semua model mengalami perbaikan; beberapa justru menunjukkan **peningkatan halusinasi** setelah fine-tuning (contoh: Model 4 dan 5).\n","* Model **komodo-7b-base** yang telah di-fine-tune menunjukkan **kinerja paling seimbang**, dengan tingkat relevansi dan usefulness tinggi serta halusinasi rendah, menjadikannya kandidat terbaik dalam penelitian ini.\n","\n","---\n"],"metadata":{"id":"V04U1BOed-MC"}},{"cell_type":"code","source":[],"metadata":{"id":"-jeF1hQIefA5"},"execution_count":null,"outputs":[]}]}